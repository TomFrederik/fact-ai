config:
  batch_size: 64
  eta: 0.5
  lr: 0.1
dataset_type: tabular
hidden_units:
- 64
- 32
num_features: 10
opt_kwargs:
  initial_accumulator_value: 0.1
optimizer: !!python/name:torch.optim.adagrad.Adagrad ''
