adv_hidden: []
config:
  batch_size: 32
  eta: 0.5
  lr: 0.01
include_labels: true
num_features: 447
opt_kwargs: {}
optimizer: !!python/name:torch.optim.adagrad.Adagrad ''
pretrain_steps: 250
prim_hidden:
- 64
- 32
