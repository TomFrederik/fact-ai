Cuda available? False
2021-03-17 23:05:36,867	INFO services.py:1173 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
2021-03-17 23:05:40,922	WARNING function_runner.py:540 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.
== Status ==
Memory usage on this node: 7.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 1/180 (1 RUNNING)
+--------------------+----------+-------+--------------+-------+-------+----------+
| Trial name         | status   | loc   |   batch_size |   eta |    lr |   sec_lr |
|--------------------+----------+-------+--------------+-------+-------+----------|
| _inner_e98d6_00000 | RUNNING  |       |           32 |     0 | 0.001 |    0.001 |
+--------------------+----------+-------+--------------+-------+-------+----------+


[2m[36m(pid=21740)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 32
[2m[36m(pid=21740)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21740)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21740)[0m GPU available: False, used: False
[2m[36m(pid=21740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m 
[2m[36m(pid=21740)[0m   | Name      | Type              | Params
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 12.0 K    Trainable params
[2m[36m(pid=21740)[0m 0         Non-trainable params
[2m[36m(pid=21740)[0m 12.0 K    Total params
[2m[36m(pid=21740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21720)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 512
[2m[36m(pid=21720)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21720)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21729)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 128
[2m[36m(pid=21720)[0m GPU available: False, used: False
[2m[36m(pid=21720)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21729)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21729)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21729)[0m GPU available: False, used: False
[2m[36m(pid=21729)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21720)[0m 
[2m[36m(pid=21720)[0m   | Name      | Type              | Params
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21720)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21720)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 12.0 K    Trainable params
[2m[36m(pid=21720)[0m 0         Non-trainable params
[2m[36m(pid=21720)[0m 12.0 K    Total params
[2m[36m(pid=21731)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 64
[2m[36m(pid=21720)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21720)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21729)[0m 
[2m[36m(pid=21729)[0m   | Name      | Type              | Params
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21729)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21729)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 12.0 K    Trainable params
[2m[36m(pid=21729)[0m 0         Non-trainable params
[2m[36m(pid=21729)[0m 12.0 K    Total params
[2m[36m(pid=21729)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21729)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21731)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21731)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21731)[0m GPU available: False, used: False
[2m[36m(pid=21731)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21731)[0m 
[2m[36m(pid=21731)[0m   | Name      | Type              | Params
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21731)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21731)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 12.0 K    Trainable params
[2m[36m(pid=21731)[0m 0         Non-trainable params
[2m[36m(pid=21731)[0m 12.0 K    Total params
[2m[36m(pid=21731)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21731)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21719)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 32
[2m[36m(pid=21719)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21719)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21719)[0m GPU available: False, used: False
[2m[36m(pid=21719)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21719)[0m 
[2m[36m(pid=21719)[0m   | Name      | Type              | Params
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21719)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21719)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 12.0 K    Trainable params
[2m[36m(pid=21719)[0m 0         Non-trainable params
[2m[36m(pid=21719)[0m 12.0 K    Total params
[2m[36m(pid=21719)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21719)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21695)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 256
[2m[36m(pid=21740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21695)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21695)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21695)[0m GPU available: False, used: False
[2m[36m(pid=21695)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21724)[0m Starting run with seed 0 - lr 1 - sec_lr 0.001 - bs 32
[2m[36m(pid=21695)[0m 
[2m[36m(pid=21695)[0m   | Name      | Type              | Params
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21695)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21695)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 12.0 K    Trainable params
[2m[36m(pid=21695)[0m 0         Non-trainable params
[2m[36m(pid=21695)[0m 12.0 K    Total params
[2m[36m(pid=21695)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21695)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21724)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21724)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21724)[0m GPU available: False, used: False
[2m[36m(pid=21724)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21724)[0m 
[2m[36m(pid=21724)[0m   | Name      | Type              | Params
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21724)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21724)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 12.0 K    Trainable params
[2m[36m(pid=21724)[0m 0         Non-trainable params
[2m[36m(pid=21724)[0m 12.0 K    Total params
[2m[36m(pid=21724)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21724)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21720)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21720)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21729)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21729)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m Starting run with seed 0 - lr 1 - sec_lr 0.001 - bs 64
[2m[36m(pid=21691)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 64
[2m[36m(pid=21731)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21731)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21739)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21691)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21691)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21739)[0m GPU available: False, used: False
[2m[36m(pid=21739)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m Starting run with seed 0 - lr 1 - sec_lr 0.001 - bs 256
[2m[36m(pid=21691)[0m GPU available: False, used: False
[2m[36m(pid=21691)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21696)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21717)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 512
[2m[36m(pid=21696)[0m GPU available: False, used: False
[2m[36m(pid=21696)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21717)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21704)[0m Starting run with seed 0 - lr 1 - sec_lr 0.001 - bs 512
[2m[36m(pid=21720)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21720)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21729)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21729)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21731)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21731)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m 
[2m[36m(pid=21739)[0m   | Name      | Type              | Params
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21739)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21739)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 12.0 K    Trainable params
[2m[36m(pid=21739)[0m 0         Non-trainable params
[2m[36m(pid=21739)[0m 12.0 K    Total params
[2m[36m(pid=21739)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21739)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21691)[0m 
[2m[36m(pid=21691)[0m   | Name      | Type              | Params
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21691)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21691)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 12.0 K    Trainable params
[2m[36m(pid=21691)[0m 0         Non-trainable params
[2m[36m(pid=21691)[0m 12.0 K    Total params
[2m[36m(pid=21691)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21691)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21704)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21704)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21717)[0m GPU available: False, used: False
[2m[36m(pid=21717)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 128
[2m[36m(pid=21719)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21719)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21696)[0m 
[2m[36m(pid=21696)[0m   | Name      | Type              | Params
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21696)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21696)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 12.0 K    Trainable params
[2m[36m(pid=21696)[0m 0         Non-trainable params
[2m[36m(pid=21696)[0m 12.0 K    Total params
[2m[36m(pid=21696)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21696)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21704)[0m GPU available: False, used: False
[2m[36m(pid=21704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21726)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21693)[0m Starting run with seed 0 - lr 2 - sec_lr 0.001 - bs 512
[2m[36m(pid=21741)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 256
[2m[36m(pid=21726)[0m GPU available: False, used: False
[2m[36m(pid=21726)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21693)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21741)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21741)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21741)[0m GPU available: False, used: False
[2m[36m(pid=21741)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m 
[2m[36m(pid=21717)[0m   | Name      | Type              | Params
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21717)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21717)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 12.0 K    Trainable params
[2m[36m(pid=21717)[0m 0         Non-trainable params
[2m[36m(pid=21717)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m GPU available: False, used: False
[2m[36m(pid=21693)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21717)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21704)[0m 
[2m[36m(pid=21704)[0m   | Name      | Type              | Params
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 12.0 K    Trainable params
[2m[36m(pid=21704)[0m 0         Non-trainable params
[2m[36m(pid=21704)[0m 12.0 K    Total params
[2m[36m(pid=21704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21726)[0m 
[2m[36m(pid=21726)[0m   | Name      | Type              | Params
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21726)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21726)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 12.0 K    Trainable params
[2m[36m(pid=21726)[0m 0         Non-trainable params
[2m[36m(pid=21726)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21726)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21693)[0m 
[2m[36m(pid=21693)[0m   | Name      | Type              | Params
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21693)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21693)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 12.0 K    Trainable params
[2m[36m(pid=21693)[0m 0         Non-trainable params
[2m[36m(pid=21693)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21693)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21741)[0m 
[2m[36m(pid=21741)[0m   | Name      | Type              | Params
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21741)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21741)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 12.0 K    Trainable params
[2m[36m(pid=21741)[0m 0         Non-trainable params
[2m[36m(pid=21741)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21741)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21711)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 64
[2m[36m(pid=21719)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21719)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21711)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21711)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21695)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21695)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21711)[0m GPU available: False, used: False
[2m[36m(pid=21711)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21700)[0m Starting run with seed 0 - lr 2 - sec_lr 0.001 - bs 32
[2m[36m(pid=21734)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 256
[2m[36m(pid=21700)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21700)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21734)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21734)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21707)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 512
[2m[36m(pid=21711)[0m 
[2m[36m(pid=21711)[0m   | Name      | Type              | Params
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21711)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21711)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 12.0 K    Trainable params
[2m[36m(pid=21711)[0m 0         Non-trainable params
[2m[36m(pid=21711)[0m 12.0 K    Total params
[2m[36m(pid=21711)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21711)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m GPU available: False, used: False
[2m[36m(pid=21700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21707)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21737)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 32
[2m[36m(pid=21734)[0m GPU available: False, used: False
[2m[36m(pid=21734)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m GPU available: False, used: False
[2m[36m(pid=21707)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21737)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21722)[0m Starting run with seed 0 - lr 2 - sec_lr 0.001 - bs 64
[2m[36m(pid=21736)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 128
[2m[36m(pid=21734)[0m 
[2m[36m(pid=21734)[0m   | Name      | Type              | Params
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21734)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21734)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 12.0 K    Trainable params
[2m[36m(pid=21734)[0m 0         Non-trainable params
[2m[36m(pid=21734)[0m 12.0 K    Total params
[2m[36m(pid=21737)[0m GPU available: False, used: False
[2m[36m(pid=21737)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21722)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21722)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21736)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21736)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21695)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21695)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m 
[2m[36m(pid=21700)[0m   | Name      | Type              | Params
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 12.0 K    Trainable params
[2m[36m(pid=21700)[0m 0         Non-trainable params
[2m[36m(pid=21700)[0m 12.0 K    Total params
[2m[36m(pid=21700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21734)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21734)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21707)[0m 
[2m[36m(pid=21707)[0m   | Name      | Type              | Params
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21707)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21707)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 12.0 K    Trainable params
[2m[36m(pid=21707)[0m 0         Non-trainable params
[2m[36m(pid=21707)[0m 12.0 K    Total params
[2m[36m(pid=21707)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21707)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21722)[0m GPU available: False, used: False
[2m[36m(pid=21722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21736)[0m GPU available: False, used: False
[2m[36m(pid=21736)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m 
[2m[36m(pid=21737)[0m   | Name      | Type              | Params
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21737)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21737)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 12.0 K    Trainable params
[2m[36m(pid=21737)[0m 0         Non-trainable params
[2m[36m(pid=21737)[0m 12.0 K    Total params
[2m[36m(pid=21724)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21724)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21737)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21737)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21722)[0m 
[2m[36m(pid=21722)[0m   | Name      | Type              | Params
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 12.0 K    Trainable params
[2m[36m(pid=21722)[0m 0         Non-trainable params
[2m[36m(pid=21722)[0m 12.0 K    Total params
[2m[36m(pid=21722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21736)[0m 
[2m[36m(pid=21736)[0m   | Name      | Type              | Params
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21736)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21736)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 12.0 K    Trainable params
[2m[36m(pid=21736)[0m 0         Non-trainable params
[2m[36m(pid=21736)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21736)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21724)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21724)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21691)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21691)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21739)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21689)[0m Starting run with seed 0 - lr 2 - sec_lr 0.001 - bs 256
[2m[36m(pid=21696)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21696)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21726)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21726)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21689)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21689)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21689)[0m GPU available: False, used: False
[2m[36m(pid=21689)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21691)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21691)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21717)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21717)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21689)[0m 
[2m[36m(pid=21689)[0m   | Name      | Type              | Params
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21689)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21689)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 12.0 K    Trainable params
[2m[36m(pid=21689)[0m 0         Non-trainable params
[2m[36m(pid=21689)[0m 12.0 K    Total params
[2m[36m(pid=21689)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21689)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21739)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21696)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21696)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21693)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21693)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21741)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21741)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21726)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21726)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21683)[0m Starting run with seed 0 - lr 2 - sec_lr 0.001 - bs 128
[2m[36m(pid=21683)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21683)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21652)[0m Starting run with seed 0 - lr 5 - sec_lr 0.001 - bs 32
[2m[36m(pid=21704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21711)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21711)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21652)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21652)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21717)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21717)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21683)[0m GPU available: False, used: False
[2m[36m(pid=21683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m Starting run with seed 0 - lr 1 - sec_lr 0.001 - bs 128
[2m[36m(pid=21652)[0m GPU available: False, used: False
[2m[36m(pid=21652)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21715)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21741)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21741)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21734)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21734)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21683)[0m 
[2m[36m(pid=21683)[0m   | Name      | Type              | Params
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 12.0 K    Trainable params
[2m[36m(pid=21683)[0m 0         Non-trainable params
[2m[36m(pid=21683)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m GPU available: False, used: False
[2m[36m(pid=21715)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21693)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21707)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21707)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21652)[0m 
[2m[36m(pid=21652)[0m   | Name      | Type              | Params
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21652)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21652)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 12.0 K    Trainable params
[2m[36m(pid=21652)[0m 0         Non-trainable params
[2m[36m(pid=21652)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21652)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21737)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21737)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m 
[2m[36m(pid=21715)[0m   | Name      | Type              | Params
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21715)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21715)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 12.0 K    Trainable params
[2m[36m(pid=21715)[0m 0         Non-trainable params
[2m[36m(pid=21715)[0m 12.0 K    Total params
[2m[36m(pid=21711)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21711)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21715)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21734)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21734)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21736)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21736)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21707)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21707)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21737)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21737)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21736)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21736)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21689)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21689)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21689)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21689)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21652)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21652)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21715)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21652)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21652)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21715)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21704)[0m time to fit was 80.19346356391907
[2m[36m(pid=21704)[0m GPU available: False, used: False
[2m[36m(pid=21704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21704)[0m 
[2m[36m(pid=21704)[0m   | Name      | Type              | Params
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 12.0 K    Trainable params
[2m[36m(pid=21704)[0m 0         Non-trainable params
[2m[36m(pid=21704)[0m 12.0 K    Total params
[2m[36m(pid=21689)[0m time to fit was 82.930184841156
[2m[36m(pid=21689)[0m GPU available: False, used: False
[2m[36m(pid=21689)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21689)[0m 
[2m[36m(pid=21689)[0m   | Name      | Type              | Params
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21689)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21689)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 12.0 K    Trainable params
[2m[36m(pid=21689)[0m 0         Non-trainable params
[2m[36m(pid=21689)[0m 12.0 K    Total params
[2m[36m(pid=21707)[0m time to fit was 93.76334047317505
[2m[36m(pid=21707)[0m GPU available: False, used: False
[2m[36m(pid=21707)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m 
[2m[36m(pid=21707)[0m   | Name      | Type              | Params
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21707)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21707)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 12.0 K    Trainable params
[2m[36m(pid=21707)[0m 0         Non-trainable params
[2m[36m(pid=21707)[0m 12.0 K    Total params
[2m[36m(pid=21696)[0m time to fit was 124.97946333885193
[2m[36m(pid=21696)[0m GPU available: False, used: False
[2m[36m(pid=21696)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m 
[2m[36m(pid=21696)[0m   | Name      | Type              | Params
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21696)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21696)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 12.0 K    Trainable params
[2m[36m(pid=21696)[0m 0         Non-trainable params
[2m[36m(pid=21696)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m time to fit was 142.06809306144714
[2m[36m(pid=21693)[0m GPU available: False, used: False
[2m[36m(pid=21693)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m 
[2m[36m(pid=21693)[0m   | Name      | Type              | Params
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21693)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21693)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 12.0 K    Trainable params
[2m[36m(pid=21693)[0m 0         Non-trainable params
[2m[36m(pid=21693)[0m 12.0 K    Total params
[2m[36m(pid=21734)[0m time to fit was 144.61629247665405
[2m[36m(pid=21734)[0m GPU available: False, used: False
[2m[36m(pid=21734)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21734)[0m 
[2m[36m(pid=21734)[0m   | Name      | Type              | Params
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21734)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21734)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 12.0 K    Trainable params
[2m[36m(pid=21734)[0m 0         Non-trainable params
[2m[36m(pid=21734)[0m 12.0 K    Total params
[2m[36m(pid=21704)[0m time to fit was 100.65441584587097
[2m[36m(pid=21704)[0m GPU available: False, used: False
[2m[36m(pid=21704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21704)[0m 
[2m[36m(pid=21704)[0m   | Name      | Type              | Params
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 12.0 K    Trainable params
[2m[36m(pid=21704)[0m 0         Non-trainable params
[2m[36m(pid=21704)[0m 12.0 K    Total params
[2m[36m(pid=21715)[0m time to fit was 181.47203183174133
[2m[36m(pid=21715)[0m GPU available: False, used: False
[2m[36m(pid=21715)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m 
[2m[36m(pid=21715)[0m   | Name      | Type              | Params
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21715)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21715)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 12.0 K    Trainable params
[2m[36m(pid=21715)[0m 0         Non-trainable params
[2m[36m(pid=21715)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m time to fit was 208.25552248954773
[2m[36m(pid=21726)[0m GPU available: False, used: False
[2m[36m(pid=21726)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m 
[2m[36m(pid=21726)[0m   | Name      | Type              | Params
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21726)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21726)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 12.0 K    Trainable params
[2m[36m(pid=21726)[0m 0         Non-trainable params
[2m[36m(pid=21726)[0m 12.0 K    Total params
[2m[36m(pid=21707)[0m time to fit was 159.65723848342896
[2m[36m(pid=21707)[0m GPU available: False, used: False
[2m[36m(pid=21707)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m 
[2m[36m(pid=21707)[0m   | Name      | Type              | Params
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21707)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21707)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 12.0 K    Trainable params
[2m[36m(pid=21707)[0m 0         Non-trainable params
[2m[36m(pid=21707)[0m 12.0 K    Total params
[2m[36m(pid=21696)[0m time to fit was 150.72894167900085
[2m[36m(pid=21696)[0m GPU available: False, used: False
[2m[36m(pid=21696)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m 
[2m[36m(pid=21696)[0m   | Name      | Type              | Params
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21696)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21696)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 12.0 K    Trainable params
[2m[36m(pid=21696)[0m 0         Non-trainable params
[2m[36m(pid=21696)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m time to fit was 172.70049834251404
[2m[36m(pid=21693)[0m GPU available: False, used: False
[2m[36m(pid=21693)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m 
[2m[36m(pid=21693)[0m   | Name      | Type              | Params
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21693)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21693)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 12.0 K    Trainable params
[2m[36m(pid=21693)[0m 0         Non-trainable params
[2m[36m(pid=21693)[0m 12.0 K    Total params
[2m[36m(pid=21734)[0m time to fit was 173.5325186252594
[2m[36m(pid=21734)[0m GPU available: False, used: False
[2m[36m(pid=21734)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21734)[0m 
[2m[36m(pid=21734)[0m   | Name      | Type              | Params
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21734)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21734)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 12.0 K    Trainable params
[2m[36m(pid=21734)[0m 0         Non-trainable params
[2m[36m(pid=21734)[0m 12.0 K    Total params
[2m[36m(pid=21704)[0m time to fit was 138.69534063339233
[2m[36m(pid=21704)[0m GPU available: False, used: False
[2m[36m(pid=21704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21704)[0m 
[2m[36m(pid=21704)[0m   | Name      | Type              | Params
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 12.0 K    Trainable params
[2m[36m(pid=21704)[0m 0         Non-trainable params
[2m[36m(pid=21704)[0m 12.0 K    Total params
[2m[36m(pid=21689)[0m time to fit was 236.2664670944214
[2m[36m(pid=21689)[0m GPU available: False, used: False
[2m[36m(pid=21689)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21689)[0m 
[2m[36m(pid=21689)[0m   | Name      | Type              | Params
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21689)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21689)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 12.0 K    Trainable params
[2m[36m(pid=21689)[0m 0         Non-trainable params
[2m[36m(pid=21689)[0m 12.0 K    Total params
[2m[36m(pid=21711)[0m time to fit was 331.2316393852234
[2m[36m(pid=21711)[0m GPU available: False, used: False
[2m[36m(pid=21711)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21711)[0m 
[2m[36m(pid=21711)[0m   | Name      | Type              | Params
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21711)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21711)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 12.0 K    Trainable params
[2m[36m(pid=21711)[0m 0         Non-trainable params
[2m[36m(pid=21711)[0m 12.0 K    Total params
[2m[36m(pid=21707)[0m time to fit was 106.84472632408142
[2m[36m(pid=21707)[0m GPU available: False, used: False
[2m[36m(pid=21707)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m 
[2m[36m(pid=21707)[0m   | Name      | Type              | Params
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21707)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21707)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 12.0 K    Trainable params
[2m[36m(pid=21707)[0m 0         Non-trainable params
[2m[36m(pid=21707)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m time to fit was 49.12911796569824
[2m[36m(pid=21693)[0m GPU available: False, used: False
[2m[36m(pid=21693)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m 
[2m[36m(pid=21693)[0m   | Name      | Type              | Params
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21693)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21693)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 12.0 K    Trainable params
[2m[36m(pid=21693)[0m 0         Non-trainable params
[2m[36m(pid=21693)[0m 12.0 K    Total params
[2m[36m(pid=21704)[0m time to fit was 83.5366780757904
[2m[36m(pid=21704)[0m GPU available: False, used: False
[2m[36m(pid=21704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21704)[0m 
[2m[36m(pid=21704)[0m   | Name      | Type              | Params
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21704)[0m ------------------------------------------------
[2m[36m(pid=21704)[0m 12.0 K    Trainable params
[2m[36m(pid=21704)[0m 0         Non-trainable params
[2m[36m(pid=21704)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m time to fit was 406.1326684951782
[2m[36m(pid=21683)[0m GPU available: False, used: False
[2m[36m(pid=21683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21683)[0m 
[2m[36m(pid=21683)[0m   | Name      | Type              | Params
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 12.0 K    Trainable params
[2m[36m(pid=21683)[0m 0         Non-trainable params
[2m[36m(pid=21683)[0m 12.0 K    Total params
[2m[36m(pid=21696)[0m time to fit was 140.26370429992676
[2m[36m(pid=21696)[0m GPU available: False, used: False
[2m[36m(pid=21696)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m 
[2m[36m(pid=21696)[0m   | Name      | Type              | Params
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21696)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21696)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 12.0 K    Trainable params
[2m[36m(pid=21696)[0m 0         Non-trainable params
[2m[36m(pid=21696)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m time to fit was 240.56452441215515
[2m[36m(pid=21726)[0m GPU available: False, used: False
[2m[36m(pid=21726)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m 
[2m[36m(pid=21726)[0m   | Name      | Type              | Params
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21726)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21726)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 12.0 K    Trainable params
[2m[36m(pid=21726)[0m 0         Non-trainable params
[2m[36m(pid=21726)[0m 12.0 K    Total params
[2m[36m(pid=21722)[0m time to fit was 452.37739515304565
[2m[36m(pid=21722)[0m GPU available: False, used: False
[2m[36m(pid=21722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21722)[0m 
[2m[36m(pid=21722)[0m   | Name      | Type              | Params
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 12.0 K    Trainable params
[2m[36m(pid=21722)[0m 0         Non-trainable params
[2m[36m(pid=21722)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m time to fit was 88.89504194259644
[2m[36m(pid=21693)[0m GPU available: False, used: False
[2m[36m(pid=21693)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21693)[0m 
[2m[36m(pid=21693)[0m   | Name      | Type              | Params
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21693)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21693)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21693)[0m ------------------------------------------------
[2m[36m(pid=21693)[0m 12.0 K    Trainable params
[2m[36m(pid=21693)[0m 0         Non-trainable params
[2m[36m(pid=21693)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m time to fit was 454.61198353767395
[2m[36m(pid=21652)[0m GPU available: False, used: False
[2m[36m(pid=21652)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21652)[0m 
[2m[36m(pid=21652)[0m   | Name      | Type              | Params
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21652)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21652)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 12.0 K    Trainable params
[2m[36m(pid=21652)[0m 0         Non-trainable params
[2m[36m(pid=21652)[0m 12.0 K    Total params
[2m[36m(pid=21739)[0m time to fit was 461.9147243499756
[2m[36m(pid=21739)[0m GPU available: False, used: False
[2m[36m(pid=21739)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21739)[0m 
[2m[36m(pid=21739)[0m   | Name      | Type              | Params
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21739)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21739)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 12.0 K    Trainable params
[2m[36m(pid=21739)[0m 0         Non-trainable params
[2m[36m(pid=21739)[0m 12.0 K    Total params
[2m[36m(pid=21715)[0m time to fit was 283.27696084976196
[2m[36m(pid=21715)[0m GPU available: False, used: False
[2m[36m(pid=21715)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m 
[2m[36m(pid=21715)[0m   | Name      | Type              | Params
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21715)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21715)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 12.0 K    Trainable params
[2m[36m(pid=21715)[0m 0         Non-trainable params
[2m[36m(pid=21715)[0m 12.0 K    Total params
[2m[36m(pid=21704)[0m time to fit was 78.31269240379333
Result for _inner_e98d6_00019:
  auc: 0.9137948989868164
  date: 2021-03-17_23-13-49
  done: false
  experiment_id: db9ead36fd3845ae895738024f8be698
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21704
  time_since_restore: 482.8585343360901
  time_this_iter_s: 482.8585343360901
  time_total_s: 482.8585343360901
  timestamp: 1616019229
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00019
  
[2m[36m(pid=21704)[0m Finished run with seed 0 - lr 1 - sec_lr 0.001 - bs 512 - mean val auc: 0.9137948989868164
== Status ==
Memory usage on this node: 10.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00019 with auc=0.9137948989868164 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 27/180 (1 PENDING, 26 RUNNING)
+--------------------+----------+-------+--------------+-------+-------+----------+
| Trial name         | status   | loc   |   batch_size |   eta |    lr |   sec_lr |
|--------------------+----------+-------+--------------+-------+-------+----------|
| _inner_e98d6_00000 | RUNNING  |       |           32 |     0 | 0.001 |    0.001 |
| _inner_e98d6_00001 | RUNNING  |       |           64 |     0 | 0.001 |    0.001 |
| _inner_e98d6_00002 | RUNNING  |       |          128 |     0 | 0.001 |    0.001 |
| _inner_e98d6_00003 | RUNNING  |       |          256 |     0 | 0.001 |    0.001 |
| _inner_e98d6_00004 | RUNNING  |       |          512 |     0 | 0.001 |    0.001 |
| _inner_e98d6_00005 | RUNNING  |       |           32 |     0 | 0.01  |    0.001 |
| _inner_e98d6_00006 | RUNNING  |       |           64 |     0 | 0.01  |    0.001 |
| _inner_e98d6_00007 | RUNNING  |       |          128 |     0 | 0.01  |    0.001 |
| _inner_e98d6_00008 | RUNNING  |       |          256 |     0 | 0.01  |    0.001 |
| _inner_e98d6_00009 | RUNNING  |       |          512 |     0 | 0.01  |    0.001 |
| _inner_e98d6_00010 | RUNNING  |       |           32 |     0 | 0.1   |    0.001 |
| _inner_e98d6_00011 | RUNNING  |       |           64 |     0 | 0.1   |    0.001 |
| _inner_e98d6_00012 | RUNNING  |       |          128 |     0 | 0.1   |    0.001 |
| _inner_e98d6_00013 | RUNNING  |       |          256 |     0 | 0.1   |    0.001 |
| _inner_e98d6_00014 | RUNNING  |       |          512 |     0 | 0.1   |    0.001 |
| _inner_e98d6_00015 | RUNNING  |       |           32 |     0 | 1     |    0.001 |
| _inner_e98d6_00016 | RUNNING  |       |           64 |     0 | 1     |    0.001 |
| _inner_e98d6_00017 | RUNNING  |       |          128 |     0 | 1     |    0.001 |
| _inner_e98d6_00018 | RUNNING  |       |          256 |     0 | 1     |    0.001 |
| _inner_e98d6_00026 | PENDING  |       |           64 |     0 | 5     |    0.001 |
+--------------------+----------+-------+--------------+-------+-------+----------+
... 7 more trials not shown (7 RUNNING)


Result for _inner_e98d6_00019:
  auc: 0.9137948989868164
  date: 2021-03-17_23-13-49
  done: true
  experiment_id: db9ead36fd3845ae895738024f8be698
  experiment_tag: 19_batch_size=512,eta=0.0,lr=1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21704
  time_since_restore: 482.8585343360901
  time_this_iter_s: 482.8585343360901
  time_total_s: 482.8585343360901
  timestamp: 1616019229
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00019
  
[2m[36m(pid=21689)[0m time to fit was 163.4931879043579
[2m[36m(pid=21689)[0m GPU available: False, used: False
[2m[36m(pid=21689)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21689)[0m 
[2m[36m(pid=21689)[0m   | Name      | Type              | Params
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21689)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21689)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 12.0 K    Trainable params
[2m[36m(pid=21689)[0m 0         Non-trainable params
[2m[36m(pid=21689)[0m 12.0 K    Total params
[2m[36m(pid=21717)[0m time to fit was 488.5928764343262
[2m[36m(pid=21717)[0m GPU available: False, used: False
[2m[36m(pid=21717)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m 
[2m[36m(pid=21717)[0m   | Name      | Type              | Params
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21717)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21717)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 12.0 K    Trainable params
[2m[36m(pid=21717)[0m 0         Non-trainable params
[2m[36m(pid=21717)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m Starting run with seed 0 - lr 5 - sec_lr 0.001 - bs 64
[2m[36m(pid=21640)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21640)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21640)[0m GPU available: False, used: False
[2m[36m(pid=21640)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21640)[0m 
[2m[36m(pid=21640)[0m   | Name      | Type              | Params
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21640)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21640)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 12.0 K    Trainable params
[2m[36m(pid=21640)[0m 0         Non-trainable params
[2m[36m(pid=21640)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21640)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21640)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21640)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21640)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21640)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21707)[0m time to fit was 137.72786164283752
[2m[36m(pid=21707)[0m GPU available: False, used: False
[2m[36m(pid=21707)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21707)[0m 
[2m[36m(pid=21707)[0m   | Name      | Type              | Params
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21707)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21707)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21707)[0m ------------------------------------------------
[2m[36m(pid=21707)[0m 12.0 K    Trainable params
[2m[36m(pid=21707)[0m 0         Non-trainable params
[2m[36m(pid=21707)[0m 12.0 K    Total params
[2m[36m(pid=21693)[0m time to fit was 53.64911603927612
Result for _inner_e98d6_00024:
  auc: 0.7604804873466492
  date: 2021-03-17_23-14-15
  done: false
  experiment_id: 0f03e659cbba4747a43c6cc1ca8d1469
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21693
  time_since_restore: 507.8113217353821
  time_this_iter_s: 507.8113217353821
  time_total_s: 507.8113217353821
  timestamp: 1616019255
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00024
  
== Status ==
Memory usage on this node: 10.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00019 with auc=0.9137948989868164 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 28/180 (1 PENDING, 26 RUNNING, 1 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |       |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |       |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00013 | RUNNING    |       |          256 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00014 | RUNNING    |       |          512 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00016 | RUNNING    |       |           64 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00017 | RUNNING    |       |          128 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00027 | PENDING    |       |          128 |     0 | 5     |    0.001 |        |                  |          |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 8 more trials not shown (8 RUNNING)


Result for _inner_e98d6_00024:
  auc: 0.7604804873466492
  date: 2021-03-17_23-14-15
  done: true
  experiment_id: 0f03e659cbba4747a43c6cc1ca8d1469
  experiment_tag: 24_batch_size=512,eta=0.0,lr=2,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21693
  time_since_restore: 507.8113217353821
  time_this_iter_s: 507.8113217353821
  time_total_s: 507.8113217353821
  timestamp: 1616019255
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00024
  [2m[36m(pid=21693)[0m Finished run with seed 0 - lr 2 - sec_lr 0.001 - bs 512 - mean val auc: 0.7604804873466492

[2m[36m(pid=21734)[0m time to fit was 197.61379837989807
[2m[36m(pid=21734)[0m GPU available: False, used: False
[2m[36m(pid=21734)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21643)[0m Starting run with seed 0 - lr 5 - sec_lr 0.001 - bs 128
[2m[36m(pid=21643)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21643)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21643)[0m GPU available: False, used: False
[2m[36m(pid=21643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21734)[0m 
[2m[36m(pid=21734)[0m   | Name      | Type              | Params
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21734)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21734)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 12.0 K    Trainable params
[2m[36m(pid=21734)[0m 0         Non-trainable params
[2m[36m(pid=21734)[0m 12.0 K    Total params
[2m[36m(pid=21643)[0m 
[2m[36m(pid=21643)[0m   | Name      | Type              | Params
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 12.0 K    Trainable params
[2m[36m(pid=21643)[0m 0         Non-trainable params
[2m[36m(pid=21643)[0m 12.0 K    Total params
[2m[36m(pid=21643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21696)[0m time to fit was 130.41782474517822
[2m[36m(pid=21696)[0m GPU available: False, used: False
[2m[36m(pid=21696)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21696)[0m 
[2m[36m(pid=21696)[0m   | Name      | Type              | Params
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21696)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21696)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21696)[0m ------------------------------------------------
[2m[36m(pid=21696)[0m 12.0 K    Trainable params
[2m[36m(pid=21696)[0m 0         Non-trainable params
[2m[36m(pid=21696)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m time to fit was 585.4779109954834
[2m[36m(pid=21736)[0m GPU available: False, used: False
[2m[36m(pid=21736)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21736)[0m 
[2m[36m(pid=21736)[0m   | Name      | Type              | Params
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21736)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21736)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 12.0 K    Trainable params
[2m[36m(pid=21736)[0m 0         Non-trainable params
[2m[36m(pid=21736)[0m 12.0 K    Total params
[2m[36m(pid=21707)[0m time to fit was 92.0124819278717
Result for _inner_e98d6_00014:
  auc: 0.912952721118927
  date: 2021-03-17_23-15-38
  done: false
  experiment_id: 5a666505da5443799e8606fe25729458
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21707
  time_since_restore: 591.2915630340576
  time_this_iter_s: 591.2915630340576
  time_total_s: 591.2915630340576
  timestamp: 1616019338
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00014
  
[2m[36m(pid=21707)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 512 - mean val auc: 0.912952721118927
== Status ==
Memory usage on this node: 10.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00019 with auc=0.9137948989868164 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 29/180 (1 PENDING, 26 RUNNING, 2 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |                     |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |                     |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |                     |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |                     |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |                     |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |                     |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00013 | RUNNING    |                     |          256 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00014 | RUNNING    | 145.101.32.82:21707 |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | RUNNING    |                     |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00016 | RUNNING    |                     |           64 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00028 | PENDING    |                     |          256 |     0 | 5     |    0.001 |        |                  |          |
| _inner_e98d6_00019 | TERMINATED |                     |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00024 | TERMINATED |                     |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 9 more trials not shown (9 RUNNING)


Result for _inner_e98d6_00014:
  auc: 0.912952721118927
  date: 2021-03-17_23-15-38
  done: true
  experiment_id: 5a666505da5443799e8606fe25729458
  experiment_tag: 14_batch_size=512,eta=0.0,lr=0.1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21707
  time_since_restore: 591.2915630340576
  time_this_iter_s: 591.2915630340576
  time_total_s: 591.2915630340576
  timestamp: 1616019338
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00014
  
[2m[36m(pid=21666)[0m Starting run with seed 0 - lr 5 - sec_lr 0.001 - bs 256
[2m[36m(pid=21666)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21666)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21666)[0m GPU available: False, used: False
[2m[36m(pid=21666)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21666)[0m 
[2m[36m(pid=21666)[0m   | Name      | Type              | Params
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21666)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21666)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 12.0 K    Trainable params
[2m[36m(pid=21666)[0m 0         Non-trainable params
[2m[36m(pid=21666)[0m 12.0 K    Total params
[2m[36m(pid=21666)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21666)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21666)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21666)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21666)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21666)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21695)[0m time to fit was 608.8930361270905
[2m[36m(pid=21695)[0m GPU available: False, used: False
[2m[36m(pid=21695)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21695)[0m 
[2m[36m(pid=21695)[0m   | Name      | Type              | Params
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21695)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21695)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 12.0 K    Trainable params
[2m[36m(pid=21695)[0m 0         Non-trainable params
[2m[36m(pid=21695)[0m 12.0 K    Total params
[2m[36m(pid=21719)[0m time to fit was 627.8041574954987
[2m[36m(pid=21719)[0m GPU available: False, used: False
[2m[36m(pid=21719)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21719)[0m 
[2m[36m(pid=21719)[0m   | Name      | Type              | Params
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21719)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21719)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 12.0 K    Trainable params
[2m[36m(pid=21719)[0m 0         Non-trainable params
[2m[36m(pid=21719)[0m 12.0 K    Total params
[2m[36m(pid=21734)[0m time to fit was 120.31929850578308
[2m[36m(pid=21734)[0m GPU available: False, used: False
[2m[36m(pid=21734)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21734)[0m 
[2m[36m(pid=21734)[0m   | Name      | Type              | Params
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21734)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21734)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21734)[0m ------------------------------------------------
[2m[36m(pid=21734)[0m 12.0 K    Trainable params
[2m[36m(pid=21734)[0m 0         Non-trainable params
[2m[36m(pid=21734)[0m 12.0 K    Total params
[2m[36m(pid=21700)[0m time to fit was 638.3490424156189
[2m[36m(pid=21700)[0m GPU available: False, used: False
[2m[36m(pid=21700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21700)[0m 
[2m[36m(pid=21700)[0m   | Name      | Type              | Params
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 12.0 K    Trainable params
[2m[36m(pid=21700)[0m 0         Non-trainable params
[2m[36m(pid=21700)[0m 12.0 K    Total params
[2m[36m(pid=21689)[0m time to fit was 155.00992035865784
[2m[36m(pid=21689)[0m GPU available: False, used: False
[2m[36m(pid=21689)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21689)[0m 
[2m[36m(pid=21689)[0m   | Name      | Type              | Params
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21689)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21689)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21689)[0m ------------------------------------------------
[2m[36m(pid=21689)[0m 12.0 K    Trainable params
[2m[36m(pid=21689)[0m 0         Non-trainable params
[2m[36m(pid=21689)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m time to fit was 233.7650318145752
[2m[36m(pid=21683)[0m GPU available: False, used: False
[2m[36m(pid=21683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21683)[0m 
[2m[36m(pid=21683)[0m   | Name      | Type              | Params
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 12.0 K    Trainable params
[2m[36m(pid=21683)[0m 0         Non-trainable params
[2m[36m(pid=21683)[0m 12.0 K    Total params
[2m[36m(pid=21711)[0m time to fit was 319.1473569869995
[2m[36m(pid=21711)[0m GPU available: False, used: False
[2m[36m(pid=21711)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21711)[0m 
[2m[36m(pid=21711)[0m   | Name      | Type              | Params
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21711)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21711)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 12.0 K    Trainable params
[2m[36m(pid=21711)[0m 0         Non-trainable params
[2m[36m(pid=21711)[0m 12.0 K    Total params
[2m[36m(pid=21643)[0m time to fit was 134.79102730751038
[2m[36m(pid=21643)[0m GPU available: False, used: False
[2m[36m(pid=21643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21643)[0m 
[2m[36m(pid=21643)[0m   | Name      | Type              | Params
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 12.0 K    Trainable params
[2m[36m(pid=21643)[0m 0         Non-trainable params
[2m[36m(pid=21643)[0m 12.0 K    Total params
[2m[36m(pid=21696)[0m time to fit was 109.23049116134644
Result for _inner_e98d6_00018:
  auc: 0.9141204833984375
  date: 2021-03-17_23-16-44
  done: false
  experiment_id: 8ee5aac541e44c47a341d3cfcecf4230
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21696
  time_since_restore: 656.9957327842712
  time_this_iter_s: 656.9957327842712
  time_total_s: 656.9957327842712
  timestamp: 1616019404
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00018
  
[2m[36m(pid=21696)[0m Finished run with seed 0 - lr 1 - sec_lr 0.001 - bs 256 - mean val auc: 0.9141204833984375
== Status ==
Memory usage on this node: 10.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 30/180 (1 PENDING, 26 RUNNING, 3 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |       |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |       |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00013 | RUNNING    |       |          256 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00016 | RUNNING    |       |           64 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00029 | PENDING    |       |          512 |     0 | 5     |    0.001 |        |                  |          |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 10 more trials not shown (10 RUNNING)


Result for _inner_e98d6_00018:
  auc: 0.9141204833984375
  date: 2021-03-17_23-16-44
  done: true
  experiment_id: 8ee5aac541e44c47a341d3cfcecf4230
  experiment_tag: 18_batch_size=256,eta=0.0,lr=1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21696
  time_since_restore: 656.9957327842712
  time_this_iter_s: 656.9957327842712
  time_total_s: 656.9957327842712
  timestamp: 1616019404
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00018
  
[2m[36m(pid=21724)[0m time to fit was 658.5894031524658
[2m[36m(pid=21724)[0m GPU available: False, used: False
[2m[36m(pid=21724)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21724)[0m 
[2m[36m(pid=21724)[0m   | Name      | Type              | Params
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21724)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21724)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 12.0 K    Trainable params
[2m[36m(pid=21724)[0m 0         Non-trainable params
[2m[36m(pid=21724)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m Starting run with seed 0 - lr 5 - sec_lr 0.001 - bs 512
[2m[36m(pid=21676)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21676)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21676)[0m GPU available: False, used: False
[2m[36m(pid=21676)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21676)[0m 
[2m[36m(pid=21676)[0m   | Name      | Type              | Params
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21676)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21676)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 12.0 K    Trainable params
[2m[36m(pid=21676)[0m 0         Non-trainable params
[2m[36m(pid=21676)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21676)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21676)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21676)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21676)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21676)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21715)[0m time to fit was 227.40003657341003
[2m[36m(pid=21715)[0m GPU available: False, used: False
[2m[36m(pid=21715)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m 
[2m[36m(pid=21715)[0m   | Name      | Type              | Params
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21715)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21715)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 12.0 K    Trainable params
[2m[36m(pid=21715)[0m 0         Non-trainable params
[2m[36m(pid=21715)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m time to fit was 254.4357373714447
[2m[36m(pid=21726)[0m GPU available: False, used: False
[2m[36m(pid=21726)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m 
[2m[36m(pid=21726)[0m   | Name      | Type              | Params
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21726)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21726)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 12.0 K    Trainable params
[2m[36m(pid=21726)[0m 0         Non-trainable params
[2m[36m(pid=21726)[0m 12.0 K    Total params
[2m[36m(pid=21666)[0m time to fit was 111.54795575141907
[2m[36m(pid=21666)[0m GPU available: False, used: False
[2m[36m(pid=21666)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21666)[0m 
[2m[36m(pid=21666)[0m   | Name      | Type              | Params
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21666)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21666)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 12.0 K    Trainable params
[2m[36m(pid=21666)[0m 0         Non-trainable params
[2m[36m(pid=21666)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m time to fit was 67.68308734893799
[2m[36m(pid=21676)[0m GPU available: False, used: False
[2m[36m(pid=21676)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21676)[0m 
[2m[36m(pid=21676)[0m   | Name      | Type              | Params
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21676)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21676)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 12.0 K    Trainable params
[2m[36m(pid=21676)[0m 0         Non-trainable params
[2m[36m(pid=21676)[0m 12.0 K    Total params
[2m[36m(pid=21689)[0m time to fit was 140.51023602485657
Result for _inner_e98d6_00023:
  auc: 0.8297206163406372
  date: 2021-03-17_23-18-47
  done: false
  experiment_id: eae3994b91a547f8aea32786298d73c6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21689
  time_since_restore: 779.6491680145264
  time_this_iter_s: 779.6491680145264
  time_total_s: 779.6491680145264
  timestamp: 1616019527
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00023
  
[2m[36m(pid=21689)[0m Finished run with seed 0 - lr 2 - sec_lr 0.001 - bs 256 - mean val auc: 0.8297206163406372
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 31/180 (1 PENDING, 26 RUNNING, 4 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |       |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |       |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00013 | RUNNING    |       |          256 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00030 | PENDING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 11 more trials not shown (11 RUNNING)


Result for _inner_e98d6_00023:
  auc: 0.8297206163406372
  date: 2021-03-17_23-18-47
  done: true
  experiment_id: eae3994b91a547f8aea32786298d73c6
  experiment_tag: 23_batch_size=256,eta=0.0,lr=2,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21689
  time_since_restore: 779.6491680145264
  time_this_iter_s: 779.6491680145264
  time_total_s: 779.6491680145264
  timestamp: 1616019527
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00023
  
[2m[36m(pid=21676)[0m time to fit was 51.74781012535095
[2m[36m(pid=21676)[0m GPU available: False, used: False
[2m[36m(pid=21676)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21676)[0m 
[2m[36m(pid=21676)[0m   | Name      | Type              | Params
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21676)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21676)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 12.0 K    Trainable params
[2m[36m(pid=21676)[0m 0         Non-trainable params
[2m[36m(pid=21676)[0m 12.0 K    Total params
[2m[36m(pid=21734)[0m time to fit was 148.96502470970154
Result for _inner_e98d6_00013:
  auc: 0.9132439851760864
  date: 2021-03-17_23-18-54
  done: false
  experiment_id: aefa2be693f24384a2d010c828257a73
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21734
  time_since_restore: 786.4804861545563
  time_this_iter_s: 786.4804861545563
  time_total_s: 786.4804861545563
  timestamp: 1616019534
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00013
  
[2m[36m(pid=21734)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 256 - mean val auc: 0.9132439851760864
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 32/180 (1 PENDING, 26 RUNNING, 5 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |                     |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |                     |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |                     |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |                     |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |                     |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |                     |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00013 | RUNNING    | 145.101.32.82:21734 |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00031 | PENDING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |                     |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00023 | TERMINATED |                     |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |                     |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 12 more trials not shown (12 RUNNING)


Result for _inner_e98d6_00013:
  auc: 0.9132439851760864
  date: 2021-03-17_23-18-54
  done: true
  experiment_id: aefa2be693f24384a2d010c828257a73
  experiment_tag: 13_batch_size=256,eta=0.0,lr=0.1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21734
  time_since_restore: 786.4804861545563
  time_this_iter_s: 786.4804861545563
  time_total_s: 786.4804861545563
  timestamp: 1616019534
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00013
  
[2m[36m(pid=21658)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 32
[2m[36m(pid=21658)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21658)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21658)[0m GPU available: False, used: False
[2m[36m(pid=21658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21658)[0m 
[2m[36m(pid=21658)[0m   | Name      | Type              | Params
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 12.0 K    Trainable params
[2m[36m(pid=21658)[0m 0         Non-trainable params
[2m[36m(pid=21658)[0m 12.0 K    Total params
[2m[36m(pid=21658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21672)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 64
[2m[36m(pid=21672)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21672)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21672)[0m GPU available: False, used: False
[2m[36m(pid=21672)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21672)[0m 
[2m[36m(pid=21672)[0m   | Name      | Type              | Params
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21672)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21672)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 12.0 K    Trainable params
[2m[36m(pid=21672)[0m 0         Non-trainable params
[2m[36m(pid=21672)[0m 12.0 K    Total params
[2m[36m(pid=21672)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21672)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21672)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21672)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21672)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21672)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21691)[0m time to fit was 805.2398450374603
[2m[36m(pid=21691)[0m GPU available: False, used: False
[2m[36m(pid=21691)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21691)[0m 
[2m[36m(pid=21691)[0m   | Name      | Type              | Params
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21691)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21691)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 12.0 K    Trainable params
[2m[36m(pid=21691)[0m 0         Non-trainable params
[2m[36m(pid=21691)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m time to fit was 47.74109411239624
[2m[36m(pid=21676)[0m GPU available: False, used: False
[2m[36m(pid=21676)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21676)[0m 
[2m[36m(pid=21676)[0m   | Name      | Type              | Params
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21676)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21676)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 12.0 K    Trainable params
[2m[36m(pid=21676)[0m 0         Non-trainable params
[2m[36m(pid=21676)[0m 12.0 K    Total params
[2m[36m(pid=21737)[0m time to fit was 866.6085026264191
[2m[36m(pid=21737)[0m GPU available: False, used: False
[2m[36m(pid=21737)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m 
[2m[36m(pid=21737)[0m   | Name      | Type              | Params
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21737)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21737)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 12.0 K    Trainable params
[2m[36m(pid=21737)[0m 0         Non-trainable params
[2m[36m(pid=21737)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m time to fit was 48.69503569602966
[2m[36m(pid=21676)[0m GPU available: False, used: False
[2m[36m(pid=21676)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21676)[0m 
[2m[36m(pid=21676)[0m   | Name      | Type              | Params
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21676)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21676)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21676)[0m ------------------------------------------------
[2m[36m(pid=21676)[0m 12.0 K    Trainable params
[2m[36m(pid=21676)[0m 0         Non-trainable params
[2m[36m(pid=21676)[0m 12.0 K    Total params
[2m[36m(pid=21715)[0m time to fit was 199.74412083625793
[2m[36m(pid=21715)[0m GPU available: False, used: False
[2m[36m(pid=21715)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21715)[0m 
[2m[36m(pid=21715)[0m   | Name      | Type              | Params
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21715)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21715)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21715)[0m ------------------------------------------------
[2m[36m(pid=21715)[0m 12.0 K    Trainable params
[2m[36m(pid=21715)[0m 0         Non-trainable params
[2m[36m(pid=21715)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m time to fit was 430.66667127609253
[2m[36m(pid=21640)[0m GPU available: False, used: False
[2m[36m(pid=21640)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21640)[0m 
[2m[36m(pid=21640)[0m   | Name      | Type              | Params
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21640)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21640)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 12.0 K    Trainable params
[2m[36m(pid=21640)[0m 0         Non-trainable params
[2m[36m(pid=21640)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m time to fit was 467.0679726600647
[2m[36m(pid=21652)[0m GPU available: False, used: False
[2m[36m(pid=21652)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21652)[0m 
[2m[36m(pid=21652)[0m   | Name      | Type              | Params
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21652)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21652)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 12.0 K    Trainable params
[2m[36m(pid=21652)[0m 0         Non-trainable params
[2m[36m(pid=21652)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m time to fit was 285.6479904651642
[2m[36m(pid=21683)[0m GPU available: False, used: False
[2m[36m(pid=21683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21683)[0m 
[2m[36m(pid=21683)[0m   | Name      | Type              | Params
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 12.0 K    Trainable params
[2m[36m(pid=21683)[0m 0         Non-trainable params
[2m[36m(pid=21683)[0m 12.0 K    Total params
[2m[36m(pid=21722)[0m time to fit was 486.28912901878357
[2m[36m(pid=21717)[0m time to fit was 450.95621728897095
[2m[36m(pid=21722)[0m GPU available: False, used: False
[2m[36m(pid=21722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21722)[0m 
[2m[36m(pid=21722)[0m   | Name      | Type              | Params
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 12.0 K    Trainable params
[2m[36m(pid=21722)[0m 0         Non-trainable params
[2m[36m(pid=21722)[0m 12.0 K    Total params
[2m[36m(pid=21717)[0m GPU available: False, used: False
[2m[36m(pid=21717)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m 
[2m[36m(pid=21717)[0m   | Name      | Type              | Params
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21717)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21717)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 12.0 K    Trainable params
[2m[36m(pid=21717)[0m 0         Non-trainable params
[2m[36m(pid=21717)[0m 12.0 K    Total params
[2m[36m(pid=21739)[0m time to fit was 478.6464035511017
[2m[36m(pid=21739)[0m GPU available: False, used: False
[2m[36m(pid=21739)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21739)[0m 
[2m[36m(pid=21739)[0m   | Name      | Type              | Params
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21739)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21739)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 12.0 K    Trainable params
[2m[36m(pid=21739)[0m 0         Non-trainable params
[2m[36m(pid=21739)[0m 12.0 K    Total params
[2m[36m(pid=21666)[0m time to fit was 229.5252161026001
[2m[36m(pid=21666)[0m GPU available: False, used: False
[2m[36m(pid=21666)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21666)[0m 
[2m[36m(pid=21666)[0m   | Name      | Type              | Params
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21666)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21666)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 12.0 K    Trainable params
[2m[36m(pid=21666)[0m 0         Non-trainable params
[2m[36m(pid=21666)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m time to fit was 273.22886896133423
[2m[36m(pid=21726)[0m GPU available: False, used: False
[2m[36m(pid=21726)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21726)[0m 
[2m[36m(pid=21726)[0m   | Name      | Type              | Params
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21726)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21726)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21726)[0m ------------------------------------------------
[2m[36m(pid=21726)[0m 12.0 K    Trainable params
[2m[36m(pid=21726)[0m 0         Non-trainable params
[2m[36m(pid=21726)[0m 12.0 K    Total params
[2m[36m(pid=21715)[0m time to fit was 162.07849836349487
[2m[36m(pid=21711)[0m time to fit was 405.48890948295593
Result for _inner_e98d6_00017:
  auc: 0.9133331894874572
  date: 2021-03-17_23-23-24
  done: false
  experiment_id: 7d893e7296364621a009c140da6c40ad
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21715
  time_since_restore: 1055.446860074997
  time_this_iter_s: 1055.446860074997
  time_total_s: 1055.446860074997
  timestamp: 1616019804
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00017
  
[2m[36m(pid=21715)[0m Finished run with seed 0 - lr 1 - sec_lr 0.001 - bs 128 - mean val auc: 0.9133331894874572
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 33/180 (1 PENDING, 26 RUNNING, 6 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |       |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00012 | RUNNING    |       |          128 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00032 | PENDING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 13 more trials not shown (13 RUNNING)


Result for _inner_e98d6_00017:
  auc: 0.9133331894874572
  date: 2021-03-17_23-23-24
  done: true
  experiment_id: 7d893e7296364621a009c140da6c40ad
  experiment_tag: 17_batch_size=128,eta=0.0,lr=1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21715
  time_since_restore: 1055.446860074997
  time_this_iter_s: 1055.446860074997
  time_total_s: 1055.446860074997
  timestamp: 1616019804
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00017
  
[2m[36m(pid=21711)[0m GPU available: False, used: False
[2m[36m(pid=21711)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21711)[0m 
[2m[36m(pid=21711)[0m   | Name      | Type              | Params
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21711)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21711)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 12.0 K    Trainable params
[2m[36m(pid=21711)[0m 0         Non-trainable params
[2m[36m(pid=21711)[0m 12.0 K    Total params
[2m[36m(pid=21661)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 128
[2m[36m(pid=21661)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21661)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21661)[0m GPU available: False, used: False
[2m[36m(pid=21661)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21661)[0m 
[2m[36m(pid=21661)[0m   | Name      | Type              | Params
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21661)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21661)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 12.0 K    Trainable params
[2m[36m(pid=21661)[0m 0         Non-trainable params
[2m[36m(pid=21661)[0m 12.0 K    Total params
[2m[36m(pid=21661)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21661)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21661)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21661)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21661)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21661)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m time to fit was 443.74196910858154
[2m[36m(pid=21700)[0m GPU available: False, used: False
[2m[36m(pid=21700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21700)[0m 
[2m[36m(pid=21700)[0m   | Name      | Type              | Params
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 12.0 K    Trainable params
[2m[36m(pid=21700)[0m 0         Non-trainable params
[2m[36m(pid=21700)[0m 12.0 K    Total params
[2m[36m(pid=21676)[0m time to fit was 221.73997926712036
Result for _inner_e98d6_00029:
  auc: 0.6678602457046509
  date: 2021-03-17_23-24-12
  done: false
  experiment_id: 2ab21c3bf55e4b3f87b36dfc4f4adb69
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21676
  time_since_restore: 438.8256182670593
  time_this_iter_s: 438.8256182670593
  time_total_s: 438.8256182670593
  timestamp: 1616019852
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00029
  
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 34/180 (1 PENDING, 26 RUNNING, 7 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00011 | RUNNING    |       |           64 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00033 | PENDING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 14 more trials not shown (14 RUNNING)


Result for _inner_e98d6_00029:
  auc: 0.6678602457046509
  date: 2021-03-17_23-24-12
  done: true
  experiment_id: 2ab21c3bf55e4b3f87b36dfc4f4adb69
  experiment_tag: 29_batch_size=512,eta=0.0,lr=5,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21676
  time_since_restore: 438.8256182670593
  time_this_iter_s: 438.8256182670593
  time_total_s: 438.8256182670593
  timestamp: 1616019852
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00029
  
[2m[36m(pid=21676)[0m Finished run with seed 0 - lr 5 - sec_lr 0.001 - bs 512 - mean val auc: 0.6678602457046509
[2m[36m(pid=21667)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 256
[2m[36m(pid=21667)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21667)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21667)[0m GPU available: False, used: False
[2m[36m(pid=21667)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m 
[2m[36m(pid=21667)[0m   | Name      | Type              | Params
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21667)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21667)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 12.0 K    Trainable params
[2m[36m(pid=21667)[0m 0         Non-trainable params
[2m[36m(pid=21667)[0m 12.0 K    Total params
[2m[36m(pid=21667)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21667)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21667)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21667)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21667)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21667)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21643)[0m time to fit was 495.3357570171356
[2m[36m(pid=21643)[0m GPU available: False, used: False
[2m[36m(pid=21643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21643)[0m 
[2m[36m(pid=21643)[0m   | Name      | Type              | Params
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 12.0 K    Trainable params
[2m[36m(pid=21643)[0m 0         Non-trainable params
[2m[36m(pid=21643)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m time to fit was 232.54615330696106
[2m[36m(pid=21640)[0m GPU available: False, used: False
[2m[36m(pid=21640)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21640)[0m 
[2m[36m(pid=21640)[0m   | Name      | Type              | Params
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21640)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21640)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 12.0 K    Trainable params
[2m[36m(pid=21640)[0m 0         Non-trainable params
[2m[36m(pid=21640)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m time to fit was 235.88314700126648
[2m[36m(pid=21683)[0m GPU available: False, used: False
[2m[36m(pid=21683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21683)[0m 
[2m[36m(pid=21683)[0m   | Name      | Type              | Params
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21683)[0m ------------------------------------------------
[2m[36m(pid=21683)[0m 12.0 K    Trainable params
[2m[36m(pid=21683)[0m 0         Non-trainable params
[2m[36m(pid=21683)[0m 12.0 K    Total params
[2m[36m(pid=21726)[0m time to fit was 245.35218501091003
Result for _inner_e98d6_00012:
  auc: 0.9134580016136169
  date: 2021-03-17_23-26-10
  done: false
  experiment_id: cb40790c4aa64673a778a3b008909400
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21726
  time_since_restore: 1223.296929359436
  time_this_iter_s: 1223.296929359436
  time_total_s: 1223.296929359436
  timestamp: 1616019970
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00012
  
[2m[36m(pid=21726)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 128 - mean val auc: 0.9134580016136169
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 35/180 (1 PENDING, 26 RUNNING, 8 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00034 | PENDING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00029 | TERMINATED |       |          512 |     0 | 5     |    0.001 |      1 |          438.826 | 0.66786  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 15 more trials not shown (15 RUNNING)


Result for _inner_e98d6_00012:
  auc: 0.9134580016136169
  date: 2021-03-17_23-26-10
  done: true
  experiment_id: cb40790c4aa64673a778a3b008909400
  experiment_tag: 12_batch_size=128,eta=0.0,lr=0.1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21726
  time_since_restore: 1223.296929359436
  time_this_iter_s: 1223.296929359436
  time_total_s: 1223.296929359436
  timestamp: 1616019970
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00012
  
[2m[36m(pid=21639)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 512
[2m[36m(pid=21639)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21639)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21639)[0m GPU available: False, used: False
[2m[36m(pid=21639)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21639)[0m 
[2m[36m(pid=21639)[0m   | Name      | Type              | Params
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21639)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21639)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 12.0 K    Trainable params
[2m[36m(pid=21639)[0m 0         Non-trainable params
[2m[36m(pid=21639)[0m 12.0 K    Total params
[2m[36m(pid=21639)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21639)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21639)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21639)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21639)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21639)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21643)[0m time to fit was 124.04579043388367
[2m[36m(pid=21643)[0m GPU available: False, used: False
[2m[36m(pid=21643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21643)[0m 
[2m[36m(pid=21643)[0m   | Name      | Type              | Params
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 12.0 K    Trainable params
[2m[36m(pid=21643)[0m 0         Non-trainable params
[2m[36m(pid=21643)[0m 12.0 K    Total params
[2m[36m(pid=21695)[0m time to fit was 695.5774073600769
[2m[36m(pid=21695)[0m GPU available: False, used: False
[2m[36m(pid=21695)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21695)[0m 
[2m[36m(pid=21695)[0m   | Name      | Type              | Params
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21695)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21695)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 12.0 K    Trainable params
[2m[36m(pid=21695)[0m 0         Non-trainable params
[2m[36m(pid=21695)[0m 12.0 K    Total params
[2m[36m(pid=21683)[0m time to fit was 148.36069416999817
Result for _inner_e98d6_00022:
  auc: 0.8284864306449891
  date: 2021-03-17_23-27-39
  done: false
  experiment_id: cb5b5ce9b4dc47f4b2fd94034d3f281c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21683
  time_since_restore: 1311.1634268760681
  time_this_iter_s: 1311.1634268760681
  time_total_s: 1311.1634268760681
  timestamp: 1616020059
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00022
  
[2m[36m(pid=21683)[0m Finished run with seed 0 - lr 2 - sec_lr 0.001 - bs 128 - mean val auc: 0.8284864306449891
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 36/180 (1 PENDING, 26 RUNNING, 9 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00035 | PENDING    |       |           32 |     0 | 0.01  |    0.01  |        |                  |          |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00029 | TERMINATED |       |          512 |     0 | 5     |    0.001 |      1 |          438.826 | 0.66786  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 16 more trials not shown (16 RUNNING)


Result for _inner_e98d6_00022:
  auc: 0.8284864306449891
  date: 2021-03-17_23-27-39
  done: true
  experiment_id: cb5b5ce9b4dc47f4b2fd94034d3f281c
  experiment_tag: 22_batch_size=128,eta=0.0,lr=2,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21683
  time_since_restore: 1311.1634268760681
  time_this_iter_s: 1311.1634268760681
  time_total_s: 1311.1634268760681
  timestamp: 1616020059
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00022
  
[2m[36m(pid=21719)[0m time to fit was 694.377313375473
[2m[36m(pid=21719)[0m GPU available: False, used: False
[2m[36m(pid=21719)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21719)[0m 
[2m[36m(pid=21719)[0m   | Name      | Type              | Params
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21719)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21719)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 12.0 K    Trainable params
[2m[36m(pid=21719)[0m 0         Non-trainable params
[2m[36m(pid=21719)[0m 12.0 K    Total params
[2m[36m(pid=21627)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 32
[2m[36m(pid=21627)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21627)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21627)[0m GPU available: False, used: False
[2m[36m(pid=21627)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21627)[0m 
[2m[36m(pid=21627)[0m   | Name      | Type              | Params
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21627)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21627)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 12.0 K    Trainable params
[2m[36m(pid=21627)[0m 0         Non-trainable params
[2m[36m(pid=21627)[0m 12.0 K    Total params
[2m[36m(pid=21627)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21627)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21627)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21627)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21627)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21627)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21722)[0m time to fit was 400.87801146507263
[2m[36m(pid=21722)[0m GPU available: False, used: False
[2m[36m(pid=21722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21722)[0m 
[2m[36m(pid=21722)[0m   | Name      | Type              | Params
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 12.0 K    Trainable params
[2m[36m(pid=21722)[0m 0         Non-trainable params
[2m[36m(pid=21722)[0m 12.0 K    Total params
[2m[36m(pid=21724)[0m time to fit was 682.6738867759705
[2m[36m(pid=21724)[0m GPU available: False, used: False
[2m[36m(pid=21724)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21724)[0m 
[2m[36m(pid=21724)[0m   | Name      | Type              | Params
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21724)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21724)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 12.0 K    Trainable params
[2m[36m(pid=21724)[0m 0         Non-trainable params
[2m[36m(pid=21724)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m time to fit was 762.4971342086792
[2m[36m(pid=21736)[0m GPU available: False, used: False
[2m[36m(pid=21736)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21736)[0m 
[2m[36m(pid=21736)[0m   | Name      | Type              | Params
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21736)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21736)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 12.0 K    Trainable params
[2m[36m(pid=21736)[0m 0         Non-trainable params
[2m[36m(pid=21736)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m time to fit was 449.06558752059937
[2m[36m(pid=21652)[0m GPU available: False, used: False
[2m[36m(pid=21652)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21652)[0m 
[2m[36m(pid=21652)[0m   | Name      | Type              | Params
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21652)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21652)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 12.0 K    Trainable params
[2m[36m(pid=21652)[0m 0         Non-trainable params
[2m[36m(pid=21652)[0m 12.0 K    Total params
[2m[36m(pid=21643)[0m time to fit was 126.93391013145447
[2m[36m(pid=21643)[0m GPU available: False, used: False
[2m[36m(pid=21643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21643)[0m 
[2m[36m(pid=21643)[0m   | Name      | Type              | Params
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21643)[0m ------------------------------------------------
[2m[36m(pid=21643)[0m 12.0 K    Trainable params
[2m[36m(pid=21643)[0m 0         Non-trainable params
[2m[36m(pid=21643)[0m 12.0 K    Total params
[2m[36m(pid=21739)[0m time to fit was 509.4670262336731
[2m[36m(pid=21739)[0m GPU available: False, used: False
[2m[36m(pid=21739)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21739)[0m 
[2m[36m(pid=21739)[0m   | Name      | Type              | Params
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21739)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21739)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 12.0 K    Trainable params
[2m[36m(pid=21739)[0m 0         Non-trainable params
[2m[36m(pid=21739)[0m 12.0 K    Total params
[2m[36m(pid=21711)[0m time to fit was 443.65010690689087
[2m[36m(pid=21711)[0m GPU available: False, used: False
[2m[36m(pid=21711)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21711)[0m 
[2m[36m(pid=21711)[0m   | Name      | Type              | Params
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21711)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21711)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21711)[0m ------------------------------------------------
[2m[36m(pid=21711)[0m 12.0 K    Trainable params
[2m[36m(pid=21711)[0m 0         Non-trainable params
[2m[36m(pid=21711)[0m 12.0 K    Total params
[2m[36m(pid=21643)[0m time to fit was 138.63568925857544
Result for _inner_e98d6_00027:
  auc: 0.5765585422515869
  date: 2021-03-17_23-31-25
  done: false
  experiment_id: 9381e21eaa034143bc37cd0c6a1d0871
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21643
  time_since_restore: 1021.0439221858978
  time_this_iter_s: 1021.0439221858978
  time_total_s: 1021.0439221858978
  timestamp: 1616020285
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00027
  
[2m[36m(pid=21643)[0m Finished run with seed 0 - lr 5 - sec_lr 0.001 - bs 128 - mean val auc: 0.5765585422515869
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 37/180 (1 PENDING, 26 RUNNING, 10 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00036 | PENDING    |       |           64 |     0 | 0.01  |    0.01  |        |                  |          |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00029 | TERMINATED |       |          512 |     0 | 5     |    0.001 |      1 |          438.826 | 0.66786  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 17 more trials not shown (16 RUNNING)


Result for _inner_e98d6_00027:
  auc: 0.5765585422515869
  date: 2021-03-17_23-31-25
  done: true
  experiment_id: 9381e21eaa034143bc37cd0c6a1d0871
  experiment_tag: 27_batch_size=128,eta=0.0,lr=5,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21643
  time_since_restore: 1021.0439221858978
  time_this_iter_s: 1021.0439221858978
  time_total_s: 1021.0439221858978
  timestamp: 1616020285
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00027
  
[2m[36m(pid=21630)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 64
[2m[36m(pid=21630)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21630)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21630)[0m GPU available: False, used: False
[2m[36m(pid=21630)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21630)[0m 
[2m[36m(pid=21630)[0m   | Name      | Type              | Params
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21630)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21630)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 12.0 K    Trainable params
[2m[36m(pid=21630)[0m 0         Non-trainable params
[2m[36m(pid=21630)[0m 12.0 K    Total params
[2m[36m(pid=21630)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21630)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21630)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21630)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21630)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21630)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21666)[0m time to fit was 635.1279182434082
[2m[36m(pid=21666)[0m GPU available: False, used: False
[2m[36m(pid=21666)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21666)[0m 
[2m[36m(pid=21666)[0m   | Name      | Type              | Params
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21666)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21666)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 12.0 K    Trainable params
[2m[36m(pid=21666)[0m 0         Non-trainable params
[2m[36m(pid=21666)[0m 12.0 K    Total params
[2m[36m(pid=21717)[0m time to fit was 695.7111468315125
[2m[36m(pid=21717)[0m GPU available: False, used: False
[2m[36m(pid=21717)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m 
[2m[36m(pid=21717)[0m   | Name      | Type              | Params
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21717)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21717)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 12.0 K    Trainable params
[2m[36m(pid=21717)[0m 0         Non-trainable params
[2m[36m(pid=21717)[0m 12.0 K    Total params
[2m[36m(pid=21666)[0m time to fit was 123.83242797851562
[2m[36m(pid=21666)[0m GPU available: False, used: False
[2m[36m(pid=21666)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21666)[0m 
[2m[36m(pid=21666)[0m   | Name      | Type              | Params
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21666)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21666)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21666)[0m ------------------------------------------------
[2m[36m(pid=21666)[0m 12.0 K    Trainable params
[2m[36m(pid=21666)[0m 0         Non-trainable params
[2m[36m(pid=21666)[0m 12.0 K    Total params
[2m[36m(pid=21691)[0m time to fit was 903.5065648555756
[2m[36m(pid=21691)[0m GPU available: False, used: False
[2m[36m(pid=21691)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21691)[0m 
[2m[36m(pid=21691)[0m   | Name      | Type              | Params
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21691)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21691)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 12.0 K    Trainable params
[2m[36m(pid=21691)[0m 0         Non-trainable params
[2m[36m(pid=21691)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m time to fit was 1782.9970378875732
[2m[36m(pid=21741)[0m GPU available: False, used: False
[2m[36m(pid=21741)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21741)[0m 
[2m[36m(pid=21741)[0m   | Name      | Type              | Params
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21741)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21741)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 12.0 K    Trainable params
[2m[36m(pid=21741)[0m 0         Non-trainable params
[2m[36m(pid=21741)[0m 12.0 K    Total params
[2m[36m(pid=21700)[0m time to fit was 719.5005428791046
[2m[36m(pid=21700)[0m GPU available: False, used: False
[2m[36m(pid=21700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21700)[0m 
[2m[36m(pid=21700)[0m   | Name      | Type              | Params
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 12.0 K    Trainable params
[2m[36m(pid=21700)[0m 0         Non-trainable params
[2m[36m(pid=21700)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m time to fit was 433.2179591655731
[2m[36m(pid=21652)[0m GPU available: False, used: False
[2m[36m(pid=21652)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21652)[0m 
[2m[36m(pid=21652)[0m   | Name      | Type              | Params
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21652)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21652)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21652)[0m ------------------------------------------------
[2m[36m(pid=21652)[0m 12.0 K    Trainable params
[2m[36m(pid=21652)[0m 0         Non-trainable params
[2m[36m(pid=21652)[0m 12.0 K    Total params
[2m[36m(pid=21722)[0m time to fit was 486.6518156528473
[2m[36m(pid=21722)[0m GPU available: False, used: False
[2m[36m(pid=21722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21722)[0m 
[2m[36m(pid=21722)[0m   | Name      | Type              | Params
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21722)[0m ------------------------------------------------
[2m[36m(pid=21722)[0m 12.0 K    Trainable params
[2m[36m(pid=21722)[0m 0         Non-trainable params
[2m[36m(pid=21722)[0m 12.0 K    Total params
[2m[36m(pid=21666)[0m time to fit was 129.10942268371582
Result for _inner_e98d6_00028:
  auc: 0.6260372042655945
  date: 2021-03-17_23-36-19
  done: false
  experiment_id: 8f0873e433354530806d7533e3f20015
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21666
  time_since_restore: 1230.5043025016785
  time_this_iter_s: 1230.5043025016785
  time_total_s: 1230.5043025016785
  timestamp: 1616020579
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00028
  
[2m[36m(pid=21666)[0m Finished run with seed 0 - lr 5 - sec_lr 0.001 - bs 256 - mean val auc: 0.6260372042655945
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 38/180 (1 PENDING, 26 RUNNING, 11 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00037 | PENDING    |       |          128 |     0 | 0.01  |    0.01  |        |                  |          |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00027 | TERMINATED |       |          128 |     0 | 5     |    0.001 |      1 |         1021.04  | 0.576559 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 18 more trials not shown (16 RUNNING, 1 TERMINATED)


Result for _inner_e98d6_00028:
  auc: 0.6260372042655945
  date: 2021-03-17_23-36-19
  done: true
  experiment_id: 8f0873e433354530806d7533e3f20015
  experiment_tag: 28_batch_size=256,eta=0.0,lr=5,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21666
  time_since_restore: 1230.5043025016785
  time_this_iter_s: 1230.5043025016785
  time_total_s: 1230.5043025016785
  timestamp: 1616020579
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00028
  
[2m[36m(pid=21632)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 128
[2m[36m(pid=21632)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21632)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21632)[0m GPU available: False, used: False
[2m[36m(pid=21632)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21632)[0m 
[2m[36m(pid=21632)[0m   | Name      | Type              | Params
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21632)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21632)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 12.0 K    Trainable params
[2m[36m(pid=21632)[0m 0         Non-trainable params
[2m[36m(pid=21632)[0m 12.0 K    Total params
[2m[36m(pid=21632)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21632)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21632)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21632)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21632)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21632)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21711)[0m time to fit was 364.19779562950134
Result for _inner_e98d6_00011:
  auc: 0.9138790249824524
  date: 2021-03-17_23-36-52
  done: false
  experiment_id: fecb67d4b48b4d6ba622d1fed1d3b9d1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21711
  time_since_restore: 1865.0729610919952
  time_this_iter_s: 1865.0729610919952
  time_total_s: 1865.0729610919952
  timestamp: 1616020612
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00011
  
[2m[36m(pid=21711)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 64 - mean val auc: 0.9138790249824524
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 39/180 (1 PENDING, 26 RUNNING, 12 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00038 | PENDING    |       |          256 |     0 | 0.01  |    0.01  |        |                  |          |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00027 | TERMINATED |       |          128 |     0 | 5     |    0.001 |      1 |         1021.04  | 0.576559 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 19 more trials not shown (16 RUNNING, 2 TERMINATED)


Result for _inner_e98d6_00011:
  auc: 0.9138790249824524
  date: 2021-03-17_23-36-52
  done: true
  experiment_id: fecb67d4b48b4d6ba622d1fed1d3b9d1
  experiment_tag: 11_batch_size=64,eta=0.0,lr=0.1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21711
  time_since_restore: 1865.0729610919952
  time_this_iter_s: 1865.0729610919952
  time_total_s: 1865.0729610919952
  timestamp: 1616020612
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00011
  
[2m[36m(pid=21695)[0m time to fit was 569.5771236419678
[2m[36m(pid=21695)[0m GPU available: False, used: False
[2m[36m(pid=21695)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 256
[2m[36m(pid=21642)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21642)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21695)[0m 
[2m[36m(pid=21695)[0m   | Name      | Type              | Params
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21695)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21695)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 12.0 K    Trainable params
[2m[36m(pid=21695)[0m 0         Non-trainable params
[2m[36m(pid=21695)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m GPU available: False, used: False
[2m[36m(pid=21642)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m 
[2m[36m(pid=21642)[0m   | Name      | Type              | Params
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21642)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21642)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 12.0 K    Trainable params
[2m[36m(pid=21642)[0m 0         Non-trainable params
[2m[36m(pid=21642)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21642)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21642)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21642)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21642)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21642)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21739)[0m time to fit was 441.07022976875305
[2m[36m(pid=21739)[0m GPU available: False, used: False
[2m[36m(pid=21739)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21739)[0m 
[2m[36m(pid=21739)[0m   | Name      | Type              | Params
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21739)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21739)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21739)[0m ------------------------------------------------
[2m[36m(pid=21739)[0m 12.0 K    Trainable params
[2m[36m(pid=21739)[0m 0         Non-trainable params
[2m[36m(pid=21739)[0m 12.0 K    Total params
[2m[36m(pid=21630)[0m time to fit was 346.66154885292053
[2m[36m(pid=21630)[0m GPU available: False, used: False
[2m[36m(pid=21630)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21630)[0m 
[2m[36m(pid=21630)[0m   | Name      | Type              | Params
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21630)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21630)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 12.0 K    Trainable params
[2m[36m(pid=21630)[0m 0         Non-trainable params
[2m[36m(pid=21630)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m time to fit was 629.228164434433
[2m[36m(pid=21736)[0m GPU available: False, used: False
[2m[36m(pid=21736)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21736)[0m 
[2m[36m(pid=21736)[0m   | Name      | Type              | Params
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21736)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21736)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 12.0 K    Trainable params
[2m[36m(pid=21736)[0m 0         Non-trainable params
[2m[36m(pid=21736)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m time to fit was 829.1047875881195
[2m[36m(pid=21640)[0m GPU available: False, used: False
[2m[36m(pid=21640)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21640)[0m 
[2m[36m(pid=21640)[0m   | Name      | Type              | Params
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21640)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21640)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 12.0 K    Trainable params
[2m[36m(pid=21640)[0m 0         Non-trainable params
[2m[36m(pid=21640)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m time to fit was 154.49990367889404
[2m[36m(pid=21642)[0m GPU available: False, used: False
[2m[36m(pid=21642)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m 
[2m[36m(pid=21642)[0m   | Name      | Type              | Params
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21642)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21642)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 12.0 K    Trainable params
[2m[36m(pid=21642)[0m 0         Non-trainable params
[2m[36m(pid=21642)[0m 12.0 K    Total params
[2m[36m(pid=21719)[0m time to fit was 727.2390389442444
[2m[36m(pid=21719)[0m GPU available: False, used: False
[2m[36m(pid=21719)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21719)[0m 
[2m[36m(pid=21719)[0m   | Name      | Type              | Params
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21719)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21719)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 12.0 K    Trainable params
[2m[36m(pid=21719)[0m 0         Non-trainable params
[2m[36m(pid=21719)[0m 12.0 K    Total params
[2m[36m(pid=21722)[0m time to fit was 232.31139492988586
[2m[36m(pid=21722)[0m Finished run with seed 0 - lr 2 - sec_lr 0.001 - bs 64 - mean val auc: 0.8305836677551269
Result for _inner_e98d6_00021:
  auc: 0.8305836677551269
  date: 2021-03-17_23-40-07
  done: false
  experiment_id: 0ec902b0600941e495ea8ca8c54b98a4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21722
  time_since_restore: 2059.790280818939
  time_this_iter_s: 2059.790280818939
  time_total_s: 2059.790280818939
  timestamp: 1616020807
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00021
  
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 40/180 (1 PENDING, 26 RUNNING, 13 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00039 | PENDING    |       |          512 |     0 | 0.01  |    0.01  |        |                  |          |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 20 more trials not shown (16 RUNNING, 3 TERMINATED)


Result for _inner_e98d6_00021:
  auc: 0.8305836677551269
  date: 2021-03-17_23-40-07
  done: true
  experiment_id: 0ec902b0600941e495ea8ca8c54b98a4
  experiment_tag: 21_batch_size=64,eta=0.0,lr=2,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21722
  time_since_restore: 2059.790280818939
  time_this_iter_s: 2059.790280818939
  time_total_s: 2059.790280818939
  timestamp: 1616020807
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00021
  
[2m[36m(pid=21634)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 512
[2m[36m(pid=21634)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21634)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21634)[0m GPU available: False, used: False
[2m[36m(pid=21634)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21634)[0m 
[2m[36m(pid=21634)[0m   | Name      | Type              | Params
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21634)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21634)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 12.0 K    Trainable params
[2m[36m(pid=21634)[0m 0         Non-trainable params
[2m[36m(pid=21634)[0m 12.0 K    Total params
[2m[36m(pid=21634)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21634)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21634)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21634)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21634)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21634)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21627)[0m time to fit was 749.9601106643677
[2m[36m(pid=21627)[0m GPU available: False, used: False
[2m[36m(pid=21627)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21627)[0m 
[2m[36m(pid=21627)[0m   | Name      | Type              | Params
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21627)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21627)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 12.0 K    Trainable params
[2m[36m(pid=21627)[0m 0         Non-trainable params
[2m[36m(pid=21627)[0m 12.0 K    Total params
[2m[36m(pid=21632)[0m time to fit was 271.41100025177
[2m[36m(pid=21632)[0m GPU available: False, used: False
[2m[36m(pid=21632)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21632)[0m 
[2m[36m(pid=21632)[0m   | Name      | Type              | Params
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21632)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21632)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 12.0 K    Trainable params
[2m[36m(pid=21632)[0m 0         Non-trainable params
[2m[36m(pid=21632)[0m 12.0 K    Total params
[2m[36m(pid=21739)[0m time to fit was 291.4261496067047
Result for _inner_e98d6_00016:
  auc: 0.9133983731269837
  date: 2021-03-17_23-42-10
  done: false
  experiment_id: 2d301c7c16cb42e391ad4d4d0691af75
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21739
  time_since_restore: 2183.8573825359344
  time_this_iter_s: 2183.8573825359344
  time_total_s: 2183.8573825359344
  timestamp: 1616020930
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00016
  
[2m[36m(pid=21739)[0m Finished run with seed 0 - lr 1 - sec_lr 0.001 - bs 64 - mean val auc: 0.9133983731269837
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 41/180 (1 PENDING, 26 RUNNING, 14 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00040 | PENDING    |       |           32 |     0 | 0.1   |    0.01  |        |                  |          |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00021 | TERMINATED |       |           64 |     0 | 2     |    0.001 |      1 |         2059.79  | 0.830584 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 21 more trials not shown (16 RUNNING, 4 TERMINATED)


Result for _inner_e98d6_00016:
  auc: 0.9133983731269837
  date: 2021-03-17_23-42-10
  done: true
  experiment_id: 2d301c7c16cb42e391ad4d4d0691af75
  experiment_tag: 16_batch_size=64,eta=0.0,lr=1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21739
  time_since_restore: 2183.8573825359344
  time_this_iter_s: 2183.8573825359344
  time_total_s: 2183.8573825359344
  timestamp: 1616020930
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00016
  
[2m[36m(pid=21635)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 32
[2m[36m(pid=21635)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21635)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21635)[0m GPU available: False, used: False
[2m[36m(pid=21635)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21635)[0m 
[2m[36m(pid=21635)[0m   | Name      | Type              | Params
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21635)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21635)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 12.0 K    Trainable params
[2m[36m(pid=21635)[0m 0         Non-trainable params
[2m[36m(pid=21635)[0m 12.0 K    Total params
[2m[36m(pid=21635)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21635)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21635)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21635)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21635)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21635)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21642)[0m time to fit was 188.92681336402893
[2m[36m(pid=21642)[0m GPU available: False, used: False
[2m[36m(pid=21642)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m 
[2m[36m(pid=21642)[0m   | Name      | Type              | Params
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21642)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21642)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 12.0 K    Trainable params
[2m[36m(pid=21642)[0m 0         Non-trainable params
[2m[36m(pid=21642)[0m 12.0 K    Total params
[2m[36m(pid=21652)[0m time to fit was 436.6261143684387
Result for _inner_e98d6_00025:
  auc: 0.5150929093360901
  date: 2021-03-17_23-43-10
  done: false
  experiment_id: 82747b29e13c47058be0d71eea1a1a61
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21652
  time_since_restore: 2241.9793684482574
  time_this_iter_s: 2241.9793684482574
  time_total_s: 2241.9793684482574
  timestamp: 1616020990
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00025
  
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 42/180 (1 PENDING, 26 RUNNING, 15 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |       |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    |       |          512 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00041 | PENDING    |       |           64 |     0 | 0.1   |    0.01  |        |                  |          |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00021 | TERMINATED |       |           64 |     0 | 2     |    0.001 |      1 |         2059.79  | 0.830584 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 22 more trials not shown (16 RUNNING, 5 TERMINATED)


Result for _inner_e98d6_00025:
[2m[36m(pid=21652)[0m Finished run with seed 0 - lr 5 - sec_lr 0.001 - bs 32 - mean val auc: 0.5150929093360901
  auc: 0.5150929093360901
  date: 2021-03-17_23-43-10
  done: true
  experiment_id: 82747b29e13c47058be0d71eea1a1a61
  experiment_tag: 25_batch_size=32,eta=0.0,lr=5,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21652
  time_since_restore: 2241.9793684482574
  time_this_iter_s: 2241.9793684482574
  time_total_s: 2241.9793684482574
  timestamp: 1616020990
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00025
  
[2m[36m(pid=21633)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 64
[2m[36m(pid=21633)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21633)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21633)[0m GPU available: False, used: False
[2m[36m(pid=21633)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21633)[0m 
[2m[36m(pid=21633)[0m   | Name      | Type              | Params
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21633)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21633)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 12.0 K    Trainable params
[2m[36m(pid=21633)[0m 0         Non-trainable params
[2m[36m(pid=21633)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21633)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21633)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21633)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21633)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21633)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21724)[0m time to fit was 924.7969591617584
[2m[36m(pid=21724)[0m GPU available: False, used: False
[2m[36m(pid=21724)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21724)[0m 
[2m[36m(pid=21724)[0m   | Name      | Type              | Params
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21724)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21724)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 12.0 K    Trainable params
[2m[36m(pid=21724)[0m 0         Non-trainable params
[2m[36m(pid=21724)[0m 12.0 K    Total params
[2m[36m(pid=21737)[0m time to fit was 1403.6281769275665
[2m[36m(pid=21737)[0m GPU available: False, used: False
[2m[36m(pid=21737)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m 
[2m[36m(pid=21737)[0m   | Name      | Type              | Params
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21737)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21737)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 12.0 K    Trainable params
[2m[36m(pid=21737)[0m 0         Non-trainable params
[2m[36m(pid=21737)[0m 12.0 K    Total params
[2m[36m(pid=21695)[0m time to fit was 398.60780143737793
[2m[36m(pid=21695)[0m GPU available: False, used: False
[2m[36m(pid=21695)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21695)[0m 
[2m[36m(pid=21695)[0m   | Name      | Type              | Params
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21695)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21695)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21695)[0m ------------------------------------------------
[2m[36m(pid=21695)[0m 12.0 K    Trainable params
[2m[36m(pid=21695)[0m 0         Non-trainable params
[2m[36m(pid=21695)[0m 12.0 K    Total params
[2m[36m(pid=21634)[0m time to fit was 232.5132918357849
[2m[36m(pid=21634)[0m GPU available: False, used: False
[2m[36m(pid=21634)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21634)[0m 
[2m[36m(pid=21634)[0m   | Name      | Type              | Params
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21634)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21634)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 12.0 K    Trainable params
[2m[36m(pid=21634)[0m 0         Non-trainable params
[2m[36m(pid=21634)[0m 12.0 K    Total params
[2m[36m(pid=21717)[0m time to fit was 708.8011612892151
[2m[36m(pid=21717)[0m GPU available: False, used: False
[2m[36m(pid=21717)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21717)[0m 
[2m[36m(pid=21717)[0m   | Name      | Type              | Params
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21717)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21717)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21717)[0m ------------------------------------------------
[2m[36m(pid=21717)[0m 12.0 K    Trainable params
[2m[36m(pid=21717)[0m 0         Non-trainable params
[2m[36m(pid=21717)[0m 12.0 K    Total params
[2m[36m(pid=21729)[0m time to fit was 2416.1395695209503
[2m[36m(pid=21729)[0m GPU available: False, used: False
[2m[36m(pid=21729)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21729)[0m 
[2m[36m(pid=21729)[0m   | Name      | Type              | Params
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21729)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21729)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 12.0 K    Trainable params
[2m[36m(pid=21729)[0m 0         Non-trainable params
[2m[36m(pid=21729)[0m 12.0 K    Total params
[2m[36m(pid=21634)[0m time to fit was 128.43074226379395
[2m[36m(pid=21634)[0m GPU available: False, used: False
[2m[36m(pid=21634)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21634)[0m 
[2m[36m(pid=21634)[0m   | Name      | Type              | Params
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21634)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21634)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 12.0 K    Trainable params
[2m[36m(pid=21634)[0m 0         Non-trainable params
[2m[36m(pid=21634)[0m 12.0 K    Total params
[2m[36m(pid=21630)[0m time to fit was 582.0682590007782
[2m[36m(pid=21630)[0m GPU available: False, used: False
[2m[36m(pid=21630)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21630)[0m 
[2m[36m(pid=21630)[0m   | Name      | Type              | Params
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21630)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21630)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 12.0 K    Trainable params
[2m[36m(pid=21630)[0m 0         Non-trainable params
[2m[36m(pid=21630)[0m 12.0 K    Total params
[2m[36m(pid=21700)[0m time to fit was 755.9153642654419
[2m[36m(pid=21700)[0m GPU available: False, used: False
[2m[36m(pid=21700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21700)[0m 
[2m[36m(pid=21700)[0m   | Name      | Type              | Params
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21700)[0m ------------------------------------------------
[2m[36m(pid=21700)[0m 12.0 K    Trainable params
[2m[36m(pid=21700)[0m 0         Non-trainable params
[2m[36m(pid=21700)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m time to fit was 609.8317122459412
[2m[36m(pid=21736)[0m GPU available: False, used: False
[2m[36m(pid=21736)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21736)[0m 
[2m[36m(pid=21736)[0m   | Name      | Type              | Params
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21736)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21736)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21736)[0m ------------------------------------------------
[2m[36m(pid=21736)[0m 12.0 K    Trainable params
[2m[36m(pid=21736)[0m 0         Non-trainable params
[2m[36m(pid=21736)[0m 12.0 K    Total params
[2m[36m(pid=21627)[0m time to fit was 518.4892950057983
[2m[36m(pid=21627)[0m GPU available: False, used: False
[2m[36m(pid=21627)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21627)[0m 
[2m[36m(pid=21627)[0m   | Name      | Type              | Params
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21627)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21627)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 12.0 K    Trainable params
[2m[36m(pid=21627)[0m 0         Non-trainable params
[2m[36m(pid=21627)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m time to fit was 360.1318483352661
[2m[36m(pid=21633)[0m GPU available: False, used: False
[2m[36m(pid=21633)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21633)[0m 
[2m[36m(pid=21633)[0m   | Name      | Type              | Params
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21633)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21633)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 12.0 K    Trainable params
[2m[36m(pid=21633)[0m 0         Non-trainable params
[2m[36m(pid=21633)[0m 12.0 K    Total params
[2m[36m(pid=21632)[0m time to fit was 515.3266875743866
[2m[36m(pid=21632)[0m GPU available: False, used: False
[2m[36m(pid=21632)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21632)[0m 
[2m[36m(pid=21632)[0m   | Name      | Type              | Params
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21632)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21632)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 12.0 K    Trainable params
[2m[36m(pid=21632)[0m 0         Non-trainable params
[2m[36m(pid=21632)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m time to fit was 413.4533362388611
[2m[36m(pid=21642)[0m GPU available: False, used: False
[2m[36m(pid=21642)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m 
[2m[36m(pid=21642)[0m   | Name      | Type              | Params
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21642)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21642)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 12.0 K    Trainable params
[2m[36m(pid=21642)[0m 0         Non-trainable params
[2m[36m(pid=21642)[0m 12.0 K    Total params
[2m[36m(pid=21634)[0m time to fit was 219.75817465782166
[2m[36m(pid=21634)[0m GPU available: False, used: False
[2m[36m(pid=21634)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21634)[0m 
[2m[36m(pid=21634)[0m   | Name      | Type              | Params
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21634)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21634)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 12.0 K    Trainable params
[2m[36m(pid=21634)[0m 0         Non-trainable params
[2m[36m(pid=21634)[0m 12.0 K    Total params
[2m[36m(pid=21635)[0m time to fit was 462.4175579547882
[2m[36m(pid=21635)[0m GPU available: False, used: False
[2m[36m(pid=21635)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21635)[0m 
[2m[36m(pid=21635)[0m   | Name      | Type              | Params
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21635)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21635)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 12.0 K    Trainable params
[2m[36m(pid=21635)[0m 0         Non-trainable params
[2m[36m(pid=21635)[0m 12.0 K    Total params
[2m[36m(pid=21667)[0m time to fit was 1564.600864648819
[2m[36m(pid=21667)[0m GPU available: False, used: False
[2m[36m(pid=21667)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m 
[2m[36m(pid=21667)[0m   | Name      | Type              | Params
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21667)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21667)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 12.0 K    Trainable params
[2m[36m(pid=21667)[0m 0         Non-trainable params
[2m[36m(pid=21667)[0m 12.0 K    Total params
[2m[36m(pid=21658)[0m time to fit was 1902.3404443264008
[2m[36m(pid=21658)[0m GPU available: False, used: False
[2m[36m(pid=21658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21658)[0m 
[2m[36m(pid=21658)[0m   | Name      | Type              | Params
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 12.0 K    Trainable params
[2m[36m(pid=21658)[0m 0         Non-trainable params
[2m[36m(pid=21658)[0m 12.0 K    Total params
[2m[36m(pid=21691)[0m time to fit was 993.147932767868
[2m[36m(pid=21691)[0m GPU available: False, used: False
[2m[36m(pid=21691)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21691)[0m 
[2m[36m(pid=21691)[0m   | Name      | Type              | Params
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21691)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21691)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 12.0 K    Trainable params
[2m[36m(pid=21691)[0m 0         Non-trainable params
[2m[36m(pid=21691)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m time to fit was 164.16098308563232
[2m[36m(pid=21642)[0m GPU available: False, used: False
[2m[36m(pid=21642)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21642)[0m 
[2m[36m(pid=21642)[0m   | Name      | Type              | Params
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21642)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21642)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21642)[0m ------------------------------------------------
[2m[36m(pid=21642)[0m 12.0 K    Trainable params
[2m[36m(pid=21642)[0m 0         Non-trainable params
[2m[36m(pid=21642)[0m 12.0 K    Total params
[2m[36m(pid=21717)[0m time to fit was 458.18252420425415
Result for _inner_e98d6_00009:
  auc: 0.9123960494995117
  date: 2021-03-17_23-52-30
  done: false
  experiment_id: a6027ce462d54cf0976b01d24faefd11
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21717
  time_since_restore: 2803.4944434165955
  time_this_iter_s: 2803.4944434165955
  time_total_s: 2803.4944434165955
  timestamp: 1616021550
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00009
  
[2m[36m(pid=21717)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 512 - mean val auc: 0.9123960494995117
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 43/180 (1 PENDING, 26 RUNNING, 16 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |                     |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    |                     |          256 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00009 | RUNNING    | 145.101.32.82:21717 |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00042 | PENDING    |                     |          128 |     0 | 0.1   |    0.01  |        |                  |          |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |                     |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00021 | TERMINATED |                     |           64 |     0 | 2     |    0.001 |      1 |         2059.79  | 0.830584 |
| _inner_e98d6_00022 | TERMINATED |                     |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 23 more trials not shown (16 RUNNING, 6 TERMINATED)


Result for _inner_e98d6_00009:
  auc: 0.9123960494995117
  date: 2021-03-17_23-52-30
  done: true
  experiment_id: a6027ce462d54cf0976b01d24faefd11
  experiment_tag: 9_batch_size=512,eta=0.0,lr=0.01,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21717
  time_since_restore: 2803.4944434165955
  time_this_iter_s: 2803.4944434165955
  time_total_s: 2803.4944434165955
  timestamp: 1616021550
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00009
  
[2m[36m(pid=21624)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 128
[2m[36m(pid=21624)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21624)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21624)[0m GPU available: False, used: False
[2m[36m(pid=21624)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21624)[0m 
[2m[36m(pid=21624)[0m   | Name      | Type              | Params
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21624)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21624)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 12.0 K    Trainable params
[2m[36m(pid=21624)[0m 0         Non-trainable params
[2m[36m(pid=21624)[0m 12.0 K    Total params
[2m[36m(pid=21624)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21624)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21632)[0m time to fit was 184.25018763542175
[2m[36m(pid=21632)[0m GPU available: False, used: False
[2m[36m(pid=21632)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21632)[0m 
[2m[36m(pid=21632)[0m   | Name      | Type              | Params
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21632)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21632)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 12.0 K    Trainable params
[2m[36m(pid=21632)[0m 0         Non-trainable params
[2m[36m(pid=21632)[0m 12.0 K    Total params
[2m[36m(pid=21624)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21624)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21624)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21624)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21634)[0m time to fit was 167.73935270309448
[2m[36m(pid=21634)[0m GPU available: False, used: False
[2m[36m(pid=21634)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21634)[0m 
[2m[36m(pid=21634)[0m   | Name      | Type              | Params
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21634)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21634)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21634)[0m ------------------------------------------------
[2m[36m(pid=21634)[0m 12.0 K    Trainable params
[2m[36m(pid=21634)[0m 0         Non-trainable params
[2m[36m(pid=21634)[0m 12.0 K    Total params
[2m[36m(pid=21672)[0m time to fit was 2049.9509909152985
[2m[36m(pid=21672)[0m GPU available: False, used: False
[2m[36m(pid=21672)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21672)[0m 
[2m[36m(pid=21672)[0m   | Name      | Type              | Params
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21672)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21672)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 12.0 K    Trainable params
[2m[36m(pid=21672)[0m 0         Non-trainable params
[2m[36m(pid=21672)[0m 12.0 K    Total params
[2m[36m(pid=21695)[0m time to fit was 637.4024977684021
Result for _inner_e98d6_00008:
  auc: 0.9126632690429688
  date: 2021-03-17_23-54-17
  done: false
  experiment_id: 815424dbc464497994fcea63a61320f5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21695
  time_since_restore: 2911.3960852622986
  time_this_iter_s: 2911.3960852622986
  time_total_s: 2911.3960852622986
  timestamp: 1616021657
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00008
  
[2m[36m(pid=21695)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 256 - mean val auc: 0.9126632690429688
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 44/180 (1 PENDING, 26 RUNNING, 17 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |                     |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00008 | RUNNING    | 145.101.32.82:21695 |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00010 | RUNNING    |                     |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00043 | PENDING    |                     |          256 |     0 | 0.1   |    0.01  |        |                  |          |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |                     |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00021 | TERMINATED |                     |           64 |     0 | 2     |    0.001 |      1 |         2059.79  | 0.830584 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 24 more trials not shown (16 RUNNING, 7 TERMINATED)


Result for _inner_e98d6_00008:
  auc: 0.9126632690429688
  date: 2021-03-17_23-54-17
  done: true
  experiment_id: 815424dbc464497994fcea63a61320f5
  experiment_tag: 8_batch_size=256,eta=0.0,lr=0.01,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21695
  time_since_restore: 2911.3960852622986
  time_this_iter_s: 2911.3960852622986
  time_total_s: 2911.3960852622986
  timestamp: 1616021657
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00008
  
[2m[36m(pid=21638)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 256
[2m[36m(pid=21638)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21638)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21638)[0m GPU available: False, used: False
[2m[36m(pid=21638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21638)[0m 
[2m[36m(pid=21638)[0m   | Name      | Type              | Params
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 12.0 K    Trainable params
[2m[36m(pid=21638)[0m 0         Non-trainable params
[2m[36m(pid=21638)[0m 12.0 K    Total params
[2m[36m(pid=21638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21719)[0m time to fit was 880.1574997901917
[2m[36m(pid=21719)[0m GPU available: False, used: False
[2m[36m(pid=21719)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21719)[0m 
[2m[36m(pid=21719)[0m   | Name      | Type              | Params
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21719)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21719)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21719)[0m ------------------------------------------------
[2m[36m(pid=21719)[0m 12.0 K    Trainable params
[2m[36m(pid=21719)[0m 0         Non-trainable params
[2m[36m(pid=21719)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m time to fit was 319.5548839569092
[2m[36m(pid=21633)[0m GPU available: False, used: False
[2m[36m(pid=21633)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21633)[0m 
[2m[36m(pid=21633)[0m   | Name      | Type              | Params
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21633)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21633)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 12.0 K    Trainable params
[2m[36m(pid=21633)[0m 0         Non-trainable params
[2m[36m(pid=21633)[0m 12.0 K    Total params
[2m[36m(pid=21642)[0m time to fit was 142.47622776031494
Result for _inner_e98d6_00038:
  auc: 0.910489296913147
  date: 2021-03-17_23-54-46
  done: false
  experiment_id: 9ac88960532a42fab16b081a3b626ab3
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21642
  time_since_restore: 1064.9620387554169
  time_this_iter_s: 1064.9620387554169
  time_total_s: 1064.9620387554169
  timestamp: 1616021686
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00038
  
[2m[36m(pid=21642)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 256 - mean val auc: 0.910489296913147
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 45/180 (1 PENDING, 26 RUNNING, 18 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00044 | PENDING    |       |          512 |     0 | 0.1   |    0.01  |        |                  |          |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 25 more trials not shown (16 RUNNING, 8 TERMINATED)


Result for _inner_e98d6_00038:
  auc: 0.910489296913147
  date: 2021-03-17_23-54-46
  done: true
  experiment_id: 9ac88960532a42fab16b081a3b626ab3
  experiment_tag: 38_batch_size=256,eta=0.0,lr=0.01,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21642
  time_since_restore: 1064.9620387554169
  time_this_iter_s: 1064.9620387554169
  time_total_s: 1064.9620387554169
  timestamp: 1616021686
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00038
  
[2m[36m(pid=21637)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 512
[2m[36m(pid=21637)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21637)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21637)[0m GPU available: False, used: False
[2m[36m(pid=21637)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21637)[0m 
[2m[36m(pid=21637)[0m   | Name      | Type              | Params
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21637)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21637)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 12.0 K    Trainable params
[2m[36m(pid=21637)[0m 0         Non-trainable params
[2m[36m(pid=21637)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21637)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21637)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21637)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21637)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21637)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21634)[0m time to fit was 151.02022910118103
Result for _inner_e98d6_00039:
  auc: 0.90971360206604
  date: 2021-03-17_23-55-18
  done: false
  experiment_id: d3b1baa5f68741e8bee512f6b8cc642b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21634
  time_since_restore: 900.6947503089905
  time_this_iter_s: 900.6947503089905
  time_total_s: 900.6947503089905
  timestamp: 1616021718
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00039
  
[2m[36m(pid=21634)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 512 - mean val auc: 0.90971360206604
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 46/180 (1 PENDING, 26 RUNNING, 19 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    |       |          128 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00045 | PENDING    |       |           32 |     0 | 1     |    0.01  |        |                  |          |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 26 more trials not shown (16 RUNNING, 9 TERMINATED)


Result for _inner_e98d6_00039:
  auc: 0.90971360206604
  date: 2021-03-17_23-55-18
  done: true
  experiment_id: d3b1baa5f68741e8bee512f6b8cc642b
  experiment_tag: 39_batch_size=512,eta=0.0,lr=0.01,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21634
  time_since_restore: 900.6947503089905
  time_this_iter_s: 900.6947503089905
  time_total_s: 900.6947503089905
  timestamp: 1616021718
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00039
  
[2m[36m(pid=21628)[0m Starting run with seed 0 - lr 1 - sec_lr 0.01 - bs 32
[2m[36m(pid=21628)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21628)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21628)[0m GPU available: False, used: False
[2m[36m(pid=21628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21628)[0m 
[2m[36m(pid=21628)[0m   | Name      | Type              | Params
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 12.0 K    Trainable params
[2m[36m(pid=21628)[0m 0         Non-trainable params
[2m[36m(pid=21628)[0m 12.0 K    Total params
[2m[36m(pid=21628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21624)[0m time to fit was 203.38402795791626
[2m[36m(pid=21624)[0m GPU available: False, used: False
[2m[36m(pid=21624)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21624)[0m 
[2m[36m(pid=21624)[0m   | Name      | Type              | Params
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21624)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21624)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 12.0 K    Trainable params
[2m[36m(pid=21624)[0m 0         Non-trainable params
[2m[36m(pid=21624)[0m 12.0 K    Total params
[2m[36m(pid=21724)[0m time to fit was 758.4965686798096
[2m[36m(pid=21724)[0m GPU available: False, used: False
[2m[36m(pid=21724)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21724)[0m 
[2m[36m(pid=21724)[0m   | Name      | Type              | Params
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21724)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21724)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21724)[0m ------------------------------------------------
[2m[36m(pid=21724)[0m 12.0 K    Trainable params
[2m[36m(pid=21724)[0m 0         Non-trainable params
[2m[36m(pid=21724)[0m 12.0 K    Total params
[2m[36m(pid=21632)[0m time to fit was 218.8855197429657
[2m[36m(pid=21632)[0m GPU available: False, used: False
[2m[36m(pid=21632)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21632)[0m 
[2m[36m(pid=21632)[0m   | Name      | Type              | Params
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21632)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21632)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21632)[0m ------------------------------------------------
[2m[36m(pid=21632)[0m 12.0 K    Trainable params
[2m[36m(pid=21632)[0m 0         Non-trainable params
[2m[36m(pid=21632)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m time to fit was 87.13046550750732
[2m[36m(pid=21637)[0m GPU available: False, used: False
[2m[36m(pid=21637)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21637)[0m 
[2m[36m(pid=21637)[0m   | Name      | Type              | Params
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21637)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21637)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 12.0 K    Trainable params
[2m[36m(pid=21637)[0m 0         Non-trainable params
[2m[36m(pid=21637)[0m 12.0 K    Total params
[2m[36m(pid=21638)[0m time to fit was 117.5554530620575
[2m[36m(pid=21638)[0m GPU available: False, used: False
[2m[36m(pid=21638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21638)[0m 
[2m[36m(pid=21638)[0m   | Name      | Type              | Params
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 12.0 K    Trainable params
[2m[36m(pid=21638)[0m 0         Non-trainable params
[2m[36m(pid=21638)[0m 12.0 K    Total params
[2m[36m(pid=21720)[0m time to fit was 3073.368591785431
[2m[36m(pid=21720)[0m GPU available: False, used: False
[2m[36m(pid=21720)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21720)[0m 
[2m[36m(pid=21720)[0m   | Name      | Type              | Params
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21720)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21720)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 12.0 K    Trainable params
[2m[36m(pid=21720)[0m 0         Non-trainable params
[2m[36m(pid=21720)[0m 12.0 K    Total params
[2m[36m(pid=21630)[0m time to fit was 602.1519212722778
[2m[36m(pid=21630)[0m GPU available: False, used: False
[2m[36m(pid=21630)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21630)[0m 
[2m[36m(pid=21630)[0m   | Name      | Type              | Params
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21630)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21630)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 12.0 K    Trainable params
[2m[36m(pid=21630)[0m 0         Non-trainable params
[2m[36m(pid=21630)[0m 12.0 K    Total params
[2m[36m(pid=21736)[0m time to fit was 502.19237327575684
Result for _inner_e98d6_00007:
  auc: 0.9126635432243347
  date: 2021-03-17_23-57-18
  done: false
  experiment_id: 7bc7164d229149f78e30ce8180d490ec
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21736
  time_since_restore: 3090.548577785492
  time_this_iter_s: 3090.548577785492
  time_total_s: 3090.548577785492
  timestamp: 1616021838
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00007
  
[2m[36m(pid=21736)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 128 - mean val auc: 0.9126635432243347
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 47/180 (1 PENDING, 26 RUNNING, 20 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00007 | RUNNING    | 145.101.32.82:21736 |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00010 | RUNNING    |                     |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |                     |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00046 | PENDING    |                     |           64 |     0 | 1     |    0.01  |        |                  |          |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |                     |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 27 more trials not shown (16 RUNNING, 10 TERMINATED)


Result for _inner_e98d6_00007:
  auc: 0.9126635432243347
  date: 2021-03-17_23-57-18
  done: true
  experiment_id: 7bc7164d229149f78e30ce8180d490ec
  experiment_tag: 7_batch_size=128,eta=0.0,lr=0.01,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21736
  time_since_restore: 3090.548577785492
  time_this_iter_s: 3090.548577785492
  time_total_s: 3090.548577785492
  timestamp: 1616021838
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00007
  
[2m[36m(pid=21636)[0m Starting run with seed 0 - lr 1 - sec_lr 0.01 - bs 64
[2m[36m(pid=21636)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21636)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21636)[0m GPU available: False, used: False
[2m[36m(pid=21636)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21636)[0m 
[2m[36m(pid=21636)[0m   | Name      | Type              | Params
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21636)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21636)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 12.0 K    Trainable params
[2m[36m(pid=21636)[0m 0         Non-trainable params
[2m[36m(pid=21636)[0m 12.0 K    Total params
[2m[36m(pid=21636)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21636)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21636)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21636)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21636)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21636)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21635)[0m time to fit was 466.3948631286621
[2m[36m(pid=21635)[0m GPU available: False, used: False
[2m[36m(pid=21635)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21635)[0m 
[2m[36m(pid=21635)[0m   | Name      | Type              | Params
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21635)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21635)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 12.0 K    Trainable params
[2m[36m(pid=21635)[0m 0         Non-trainable params
[2m[36m(pid=21635)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m time to fit was 1137.7716438770294
[2m[36m(pid=21640)[0m GPU available: False, used: False
[2m[36m(pid=21640)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21640)[0m 
[2m[36m(pid=21640)[0m   | Name      | Type              | Params
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21640)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21640)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21640)[0m ------------------------------------------------
[2m[36m(pid=21640)[0m 12.0 K    Trainable params
[2m[36m(pid=21640)[0m 0         Non-trainable params
[2m[36m(pid=21640)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m time to fit was 130.17056703567505
[2m[36m(pid=21637)[0m GPU available: False, used: False
[2m[36m(pid=21637)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21637)[0m 
[2m[36m(pid=21637)[0m   | Name      | Type              | Params
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21637)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21637)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 12.0 K    Trainable params
[2m[36m(pid=21637)[0m 0         Non-trainable params
[2m[36m(pid=21637)[0m 12.0 K    Total params
[2m[36m(pid=21638)[0m time to fit was 132.30610013008118
[2m[36m(pid=21638)[0m GPU available: False, used: False
[2m[36m(pid=21638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21638)[0m 
[2m[36m(pid=21638)[0m   | Name      | Type              | Params
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 12.0 K    Trainable params
[2m[36m(pid=21638)[0m 0         Non-trainable params
[2m[36m(pid=21638)[0m 12.0 K    Total params
[2m[36m(pid=21624)[0m time to fit was 154.754154920578
[2m[36m(pid=21624)[0m GPU available: False, used: False
[2m[36m(pid=21624)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21624)[0m 
[2m[36m(pid=21624)[0m   | Name      | Type              | Params
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21624)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21624)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 12.0 K    Trainable params
[2m[36m(pid=21624)[0m 0         Non-trainable params
[2m[36m(pid=21624)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m time to fit was 293.20382738113403
[2m[36m(pid=21633)[0m GPU available: False, used: False
[2m[36m(pid=21633)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21633)[0m 
[2m[36m(pid=21633)[0m   | Name      | Type              | Params
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21633)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21633)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 12.0 K    Trainable params
[2m[36m(pid=21633)[0m 0         Non-trainable params
[2m[36m(pid=21633)[0m 12.0 K    Total params
[2m[36m(pid=21632)[0m time to fit was 225.7064654827118
Result for _inner_e98d6_00037:
  auc: 0.9100371241569519
  date: 2021-03-18_00-00-06
  done: false
  experiment_id: 4245262c9e8547de9afc011292c5edbb
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21632
  time_since_restore: 1416.904373407364
  time_this_iter_s: 1416.904373407364
  time_total_s: 1416.904373407364
  timestamp: 1616022006
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00037
  
[2m[36m(pid=21632)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 128 - mean val auc: 0.9100371241569519
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 48/180 (1 PENDING, 26 RUNNING, 21 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00020 | RUNNING    |       |           32 |     0 | 2     |    0.001 |        |                  |          |
| _inner_e98d6_00047 | PENDING    |       |          128 |     0 | 1     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 28 more trials not shown (16 RUNNING, 11 TERMINATED)


Result for _inner_e98d6_00037:
  auc: 0.9100371241569519
  date: 2021-03-18_00-00-06
  done: true
  experiment_id: 4245262c9e8547de9afc011292c5edbb
  experiment_tag: 37_batch_size=128,eta=0.0,lr=0.01,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21632
  time_since_restore: 1416.904373407364
  time_this_iter_s: 1416.904373407364
  time_total_s: 1416.904373407364
  timestamp: 1616022006
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00037
  
[2m[36m(pid=21623)[0m Starting run with seed 0 - lr 1 - sec_lr 0.01 - bs 128
[2m[36m(pid=21623)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21623)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21623)[0m GPU available: False, used: False
[2m[36m(pid=21623)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21623)[0m 
[2m[36m(pid=21623)[0m   | Name      | Type              | Params
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21623)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21623)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 12.0 K    Trainable params
[2m[36m(pid=21623)[0m 0         Non-trainable params
[2m[36m(pid=21623)[0m 12.0 K    Total params
[2m[36m(pid=21623)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21623)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21623)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21623)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21623)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21623)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21691)[0m time to fit was 583.7363305091858
[2m[36m(pid=21691)[0m GPU available: False, used: False
[2m[36m(pid=21691)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21691)[0m 
[2m[36m(pid=21691)[0m   | Name      | Type              | Params
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21691)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21691)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21691)[0m ------------------------------------------------
[2m[36m(pid=21691)[0m 12.0 K    Trainable params
[2m[36m(pid=21691)[0m 0         Non-trainable params
[2m[36m(pid=21691)[0m 12.0 K    Total params
[2m[36m(pid=21638)[0m time to fit was 137.40989899635315
[2m[36m(pid=21638)[0m GPU available: False, used: False
[2m[36m(pid=21638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21638)[0m 
[2m[36m(pid=21638)[0m   | Name      | Type              | Params
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 12.0 K    Trainable params
[2m[36m(pid=21638)[0m 0         Non-trainable params
[2m[36m(pid=21638)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m time to fit was 151.9861876964569
[2m[36m(pid=21637)[0m GPU available: False, used: False
[2m[36m(pid=21637)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21637)[0m 
[2m[36m(pid=21637)[0m   | Name      | Type              | Params
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21637)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21637)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 12.0 K    Trainable params
[2m[36m(pid=21637)[0m 0         Non-trainable params
[2m[36m(pid=21637)[0m 12.0 K    Total params
[2m[36m(pid=21624)[0m time to fit was 177.63922929763794
[2m[36m(pid=21624)[0m GPU available: False, used: False
[2m[36m(pid=21624)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21624)[0m 
[2m[36m(pid=21624)[0m   | Name      | Type              | Params
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21624)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21624)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 12.0 K    Trainable params
[2m[36m(pid=21624)[0m 0         Non-trainable params
[2m[36m(pid=21624)[0m 12.0 K    Total params
[2m[36m(pid=21640)[0m time to fit was 227.71418452262878
Result for _inner_e98d6_00026:
  auc: 0.7014720797538757
  date: 2021-03-18_00-01-38
  done: false
  experiment_id: a854d18b97e549279cc330e7b9b7139e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21640
  time_since_restore: 2859.1080775260925
  time_this_iter_s: 2859.1080775260925
  time_total_s: 2859.1080775260925
  timestamp: 1616022098
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00026
  
[2m[36m(pid=21640)[0m Finished run with seed 0 - lr 5 - sec_lr 0.001 - bs 64 - mean val auc: 0.7014720797538757
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 49/180 (1 PENDING, 26 RUNNING, 22 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |       |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00020 | RUNNING    |       |           32 |     0 | 2     |    0.001 |        |                  |          |
| _inner_e98d6_00048 | PENDING    |       |          256 |     0 | 1     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 29 more trials not shown (16 RUNNING, 12 TERMINATED)


Result for _inner_e98d6_00026:
  auc: 0.7014720797538757
  date: 2021-03-18_00-01-38
  done: true
  experiment_id: a854d18b97e549279cc330e7b9b7139e
  experiment_tag: 26_batch_size=64,eta=0.0,lr=5,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21640
  time_since_restore: 2859.1080775260925
  time_this_iter_s: 2859.1080775260925
  time_total_s: 2859.1080775260925
  timestamp: 1616022098
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00026
  
[2m[36m(pid=21629)[0m Starting run with seed 0 - lr 1 - sec_lr 0.01 - bs 256
[2m[36m(pid=21629)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21629)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21629)[0m GPU available: False, used: False
[2m[36m(pid=21629)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21629)[0m 
[2m[36m(pid=21629)[0m   | Name      | Type              | Params
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21629)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21629)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 12.0 K    Trainable params
[2m[36m(pid=21629)[0m 0         Non-trainable params
[2m[36m(pid=21629)[0m 12.0 K    Total params
[2m[36m(pid=21629)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21629)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21629)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21629)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21629)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21629)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21700)[0m time to fit was 825.681398153305
Result for _inner_e98d6_00020:
  auc: 0.8299441456794738
  date: 2021-03-18_00-02-12
  done: false
  experiment_id: 6deb5c178520408c97f808491f5da4ac
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21700
  time_since_restore: 3384.510024547577
  time_this_iter_s: 3384.510024547577
  time_total_s: 3384.510024547577
  timestamp: 1616022132
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00020
  
[2m[36m(pid=21700)[0m Finished run with seed 0 - lr 2 - sec_lr 0.001 - bs 32 - mean val auc: 0.8299441456794738
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 50/180 (1 PENDING, 26 RUNNING, 23 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    |                     |           32 |     0 | 0.1   |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |                     |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00020 | RUNNING    | 145.101.32.82:21700 |           32 |     0 | 2     |    0.001 |      1 |         3384.51  | 0.829944 |
| _inner_e98d6_00049 | PENDING    |                     |          512 |     0 | 1     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 30 more trials not shown (16 RUNNING, 13 TERMINATED)


Result for _inner_e98d6_00020:
  auc: 0.8299441456794738
  date: 2021-03-18_00-02-12
  done: true
  experiment_id: 6deb5c178520408c97f808491f5da4ac
  experiment_tag: 20_batch_size=32,eta=0.0,lr=2,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21700
  time_since_restore: 3384.510024547577
  time_this_iter_s: 3384.510024547577
  time_total_s: 3384.510024547577
  timestamp: 1616022132
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00020
  
[2m[36m(pid=21631)[0m Starting run with seed 0 - lr 1 - sec_lr 0.01 - bs 512
[2m[36m(pid=21631)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21631)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21631)[0m GPU available: False, used: False
[2m[36m(pid=21631)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21631)[0m 
[2m[36m(pid=21631)[0m   | Name      | Type              | Params
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21631)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21631)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 12.0 K    Trainable params
[2m[36m(pid=21631)[0m 0         Non-trainable params
[2m[36m(pid=21631)[0m 12.0 K    Total params
[2m[36m(pid=21631)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21631)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21631)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21631)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21631)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21631)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21719)[0m time to fit was 467.02681732177734
Result for _inner_e98d6_00010:
  auc: 0.9137715816497802
  date: 2021-03-18_00-02-24
  done: false
  experiment_id: c3e479e35a554c3d91e11cb893ee10d6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21719
  time_since_restore: 3397.995373249054
  time_this_iter_s: 3397.995373249054
  time_total_s: 3397.995373249054
  timestamp: 1616022144
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00010
  
[2m[36m(pid=21719)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.001 - bs 32 - mean val auc: 0.9137715816497802
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 51/180 (1 PENDING, 26 RUNNING, 24 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00010 | RUNNING    | 145.101.32.82:21719 |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00015 | RUNNING    |                     |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00050 | PENDING    |                     |           32 |     0 | 2     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 31 more trials not shown (16 RUNNING, 14 TERMINATED)


Result for _inner_e98d6_00010:
  auc: 0.9137715816497802
  date: 2021-03-18_00-02-24
  done: true
  experiment_id: c3e479e35a554c3d91e11cb893ee10d6
  experiment_tag: 10_batch_size=32,eta=0.0,lr=0.1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21719
  time_since_restore: 3397.995373249054
  time_this_iter_s: 3397.995373249054
  time_total_s: 3397.995373249054
  timestamp: 1616022144
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00010
  
[2m[36m(pid=21636)[0m time to fit was 299.39861583709717
[2m[36m(pid=21636)[0m GPU available: False, used: False
[2m[36m(pid=21636)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21636)[0m 
[2m[36m(pid=21636)[0m   | Name      | Type              | Params
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21636)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21636)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 12.0 K    Trainable params
[2m[36m(pid=21636)[0m 0         Non-trainable params
[2m[36m(pid=21636)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m Starting run with seed 0 - lr 2 - sec_lr 0.01 - bs 32
[2m[36m(pid=21626)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21626)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21626)[0m GPU available: False, used: False
[2m[36m(pid=21626)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21626)[0m 
[2m[36m(pid=21626)[0m   | Name      | Type              | Params
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21626)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21626)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 12.0 K    Trainable params
[2m[36m(pid=21626)[0m 0         Non-trainable params
[2m[36m(pid=21626)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21626)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21626)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21626)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21626)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21626)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21638)[0m time to fit was 105.27280640602112
[2m[36m(pid=21638)[0m GPU available: False, used: False
[2m[36m(pid=21638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21638)[0m 
[2m[36m(pid=21638)[0m   | Name      | Type              | Params
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21638)[0m ------------------------------------------------
[2m[36m(pid=21638)[0m 12.0 K    Trainable params
[2m[36m(pid=21638)[0m 0         Non-trainable params
[2m[36m(pid=21638)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m time to fit was 103.6662368774414
[2m[36m(pid=21637)[0m GPU available: False, used: False
[2m[36m(pid=21637)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21637)[0m 
[2m[36m(pid=21637)[0m   | Name      | Type              | Params
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21637)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21637)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21637)[0m ------------------------------------------------
[2m[36m(pid=21637)[0m 12.0 K    Trainable params
[2m[36m(pid=21637)[0m 0         Non-trainable params
[2m[36m(pid=21637)[0m 12.0 K    Total params
[2m[36m(pid=21630)[0m time to fit was 348.9780104160309
[2m[36m(pid=21630)[0m GPU available: False, used: False
[2m[36m(pid=21630)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21630)[0m 
[2m[36m(pid=21630)[0m   | Name      | Type              | Params
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21630)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21630)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21630)[0m ------------------------------------------------
[2m[36m(pid=21630)[0m 12.0 K    Trainable params
[2m[36m(pid=21630)[0m 0         Non-trainable params
[2m[36m(pid=21630)[0m 12.0 K    Total params
[2m[36m(pid=21629)[0m time to fit was 91.79391050338745
[2m[36m(pid=21629)[0m GPU available: False, used: False
[2m[36m(pid=21629)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21629)[0m 
[2m[36m(pid=21629)[0m   | Name      | Type              | Params
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21629)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21629)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 12.0 K    Trainable params
[2m[36m(pid=21629)[0m 0         Non-trainable params
[2m[36m(pid=21629)[0m 12.0 K    Total params
[2m[36m(pid=21631)[0m time to fit was 78.07946014404297
[2m[36m(pid=21631)[0m GPU available: False, used: False
[2m[36m(pid=21631)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21631)[0m 
[2m[36m(pid=21631)[0m   | Name      | Type              | Params
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21631)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21631)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 12.0 K    Trainable params
[2m[36m(pid=21631)[0m 0         Non-trainable params
[2m[36m(pid=21631)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m time to fit was 249.53959155082703
[2m[36m(pid=21633)[0m GPU available: False, used: False
[2m[36m(pid=21633)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21633)[0m 
[2m[36m(pid=21633)[0m   | Name      | Type              | Params
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21633)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21633)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21633)[0m ------------------------------------------------
[2m[36m(pid=21633)[0m 12.0 K    Trainable params
[2m[36m(pid=21633)[0m 0         Non-trainable params
[2m[36m(pid=21633)[0m 12.0 K    Total params
[2m[36m(pid=21623)[0m time to fit was 213.48715329170227
[2m[36m(pid=21623)[0m GPU available: False, used: False
[2m[36m(pid=21623)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21623)[0m 
[2m[36m(pid=21623)[0m   | Name      | Type              | Params
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21623)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21623)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 12.0 K    Trainable params
[2m[36m(pid=21623)[0m 0         Non-trainable params
[2m[36m(pid=21623)[0m 12.0 K    Total params
[2m[36m(pid=21637)[0m time to fit was 91.52369689941406
[2m[36m(pid=21628)[0m time to fit was 532.7695834636688
Result for _inner_e98d6_00044:
  auc: 0.9136373281478882
  date: 2021-03-18_00-04-20
  done: false
  experiment_id: 5ef88e16fded4ff1b59efabc9de6825e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21637
  time_since_restore: 565.6880786418915
  time_this_iter_s: 565.6880786418915
  time_total_s: 565.6880786418915
  timestamp: 1616022260
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00044
  
[2m[36m(pid=21637)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 512 - mean val auc: 0.9136373281478882
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 52/180 (1 PENDING, 26 RUNNING, 25 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00051 | PENDING    |       |           64 |     0 | 2     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 32 more trials not shown (16 RUNNING, 15 TERMINATED)


Result for _inner_e98d6_00044:
  auc: 0.9136373281478882
  date: 2021-03-18_00-04-20
  done: true
  experiment_id: 5ef88e16fded4ff1b59efabc9de6825e
  experiment_tag: 44_batch_size=512,eta=0.0,lr=0.1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21637
  time_since_restore: 565.6880786418915
  time_this_iter_s: 565.6880786418915
  time_total_s: 565.6880786418915
  timestamp: 1616022260
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00044
  
[2m[36m(pid=21628)[0m GPU available: False, used: False
[2m[36m(pid=21628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21628)[0m 
[2m[36m(pid=21628)[0m   | Name      | Type              | Params
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 12.0 K    Trainable params
[2m[36m(pid=21628)[0m 0         Non-trainable params
[2m[36m(pid=21628)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m Starting run with seed 0 - lr 2 - sec_lr 0.01 - bs 64
[2m[36m(pid=21625)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21625)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21625)[0m GPU available: False, used: False
[2m[36m(pid=21625)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21625)[0m 
[2m[36m(pid=21625)[0m   | Name      | Type              | Params
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21625)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21625)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 12.0 K    Trainable params
[2m[36m(pid=21625)[0m 0         Non-trainable params
[2m[36m(pid=21625)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21625)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21625)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21625)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21625)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21625)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21638)[0m time to fit was 128.20314526557922
Result for _inner_e98d6_00043:
  auc: 0.9130890846252442
  date: 2021-03-18_00-04-49
  done: false
  experiment_id: 5eea035e906c4ff6a40e0c844613dad5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21638
  time_since_restore: 622.1343879699707
  time_this_iter_s: 622.1343879699707
  time_total_s: 622.1343879699707
  timestamp: 1616022289
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00043
  
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 53/180 (1 PENDING, 26 RUNNING, 26 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    |       |           32 |     0 | 1     |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00052 | PENDING    |       |          128 |     0 | 2     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 33 more trials not shown (16 RUNNING, 16 TERMINATED)


Result for _inner_e98d6_00043:
  auc: 0.9130890846252442
  date: 2021-03-18_00-04-49
  done: true
  experiment_id: 5eea035e906c4ff6a40e0c844613dad5
  experiment_tag: 43_batch_size=256,eta=0.0,lr=0.1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21638
  time_since_restore: 622.1343879699707
  time_this_iter_s: 622.1343879699707
  time_total_s: 622.1343879699707
  timestamp: 1616022289
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00043
  
[2m[36m(pid=21638)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 256 - mean val auc: 0.9130890846252442
[2m[36m(pid=21624)[0m time to fit was 201.7680423259735
[2m[36m(pid=21624)[0m GPU available: False, used: False
[2m[36m(pid=21624)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21624)[0m 
[2m[36m(pid=21624)[0m   | Name      | Type              | Params
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21624)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21624)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21624)[0m ------------------------------------------------
[2m[36m(pid=21624)[0m 12.0 K    Trainable params
[2m[36m(pid=21624)[0m 0         Non-trainable params
[2m[36m(pid=21624)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m Starting run with seed 0 - lr 2 - sec_lr 0.01 - bs 128
[2m[36m(pid=52037)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52037)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=52037)[0m GPU available: False, used: False
[2m[36m(pid=52037)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52037)[0m 
[2m[36m(pid=52037)[0m   | Name      | Type              | Params
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52037)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52037)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 12.0 K    Trainable params
[2m[36m(pid=52037)[0m 0         Non-trainable params
[2m[36m(pid=52037)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=52037)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=52037)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=52037)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=52037)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=52037)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21629)[0m time to fit was 118.15543341636658
[2m[36m(pid=21629)[0m GPU available: False, used: False
[2m[36m(pid=21629)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21629)[0m 
[2m[36m(pid=21629)[0m   | Name      | Type              | Params
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21629)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21629)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 12.0 K    Trainable params
[2m[36m(pid=21629)[0m 0         Non-trainable params
[2m[36m(pid=21629)[0m 12.0 K    Total params
[2m[36m(pid=21631)[0m time to fit was 110.41774320602417
[2m[36m(pid=21631)[0m GPU available: False, used: False
[2m[36m(pid=21631)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21631)[0m 
[2m[36m(pid=21631)[0m   | Name      | Type              | Params
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21631)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21631)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 12.0 K    Trainable params
[2m[36m(pid=21631)[0m 0         Non-trainable params
[2m[36m(pid=21631)[0m 12.0 K    Total params
[2m[36m(pid=21623)[0m time to fit was 155.6281840801239
[2m[36m(pid=21623)[0m GPU available: False, used: False
[2m[36m(pid=21623)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21623)[0m 
[2m[36m(pid=21623)[0m   | Name      | Type              | Params
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21623)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21623)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 12.0 K    Trainable params
[2m[36m(pid=21623)[0m 0         Non-trainable params
[2m[36m(pid=21623)[0m 12.0 K    Total params
[2m[36m(pid=21724)[0m time to fit was 624.0003061294556
Result for _inner_e98d6_00015:
  auc: 0.9130908131599427
  date: 2021-03-18_00-06-36
  done: false
  experiment_id: 2fd0195f22154e9fa993dd91733d01b2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21724
  time_since_restore: 3649.8911266326904
  time_this_iter_s: 3649.8911266326904
  time_total_s: 3649.8911266326904
  timestamp: 1616022396
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00015
  
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 54/180 (1 PENDING, 26 RUNNING, 27 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |                     |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00015 | RUNNING    | 145.101.32.82:21724 |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00053 | PENDING    |                     |          256 |     0 | 2     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 34 more trials not shown (16 RUNNING, 17 TERMINATED)


[2m[36m(pid=21724)[0m Finished run with seed 0 - lr 1 - sec_lr 0.001 - bs 32 - mean val auc: 0.9130908131599427
Result for _inner_e98d6_00015:
  auc: 0.9130908131599427
  date: 2021-03-18_00-06-36
  done: true
  experiment_id: 2fd0195f22154e9fa993dd91733d01b2
  experiment_tag: 15_batch_size=32,eta=0.0,lr=1,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21724
  time_since_restore: 3649.8911266326904
  time_this_iter_s: 3649.8911266326904
  time_total_s: 3649.8911266326904
  timestamp: 1616022396
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00015
  
2021-03-18 00:06:37,655	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffffd9a5dd8201000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=3131)[0m Starting run with seed 0 - lr 2 - sec_lr 0.01 - bs 256
[2m[36m(pid=3131)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3131)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=3131)[0m GPU available: False, used: False
[2m[36m(pid=3131)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3131)[0m 
[2m[36m(pid=3131)[0m   | Name      | Type              | Params
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3131)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3131)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 12.0 K    Trainable params
[2m[36m(pid=3131)[0m 0         Non-trainable params
[2m[36m(pid=3131)[0m 12.0 K    Total params
[2m[36m(pid=3131)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3131)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3131)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3131)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3131)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=3131)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21631)[0m time to fit was 84.28600239753723
[2m[36m(pid=21631)[0m GPU available: False, used: False
[2m[36m(pid=21631)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21631)[0m 
[2m[36m(pid=21631)[0m   | Name      | Type              | Params
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21631)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21631)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 12.0 K    Trainable params
[2m[36m(pid=21631)[0m 0         Non-trainable params
[2m[36m(pid=21631)[0m 12.0 K    Total params
[2m[36m(pid=21636)[0m time to fit was 284.75237917900085
[2m[36m(pid=21636)[0m GPU available: False, used: False
[2m[36m(pid=21636)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21636)[0m 
[2m[36m(pid=21636)[0m   | Name      | Type              | Params
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21636)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21636)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 12.0 K    Trainable params
[2m[36m(pid=21636)[0m 0         Non-trainable params
[2m[36m(pid=21636)[0m 12.0 K    Total params
[2m[36m(pid=21629)[0m time to fit was 118.13245892524719
[2m[36m(pid=21629)[0m GPU available: False, used: False
[2m[36m(pid=21629)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21629)[0m 
[2m[36m(pid=21629)[0m   | Name      | Type              | Params
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21629)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21629)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 12.0 K    Trainable params
[2m[36m(pid=21629)[0m 0         Non-trainable params
[2m[36m(pid=21629)[0m 12.0 K    Total params
[2m[36m(pid=21635)[0m time to fit was 575.778980255127
[2m[36m(pid=21635)[0m GPU available: False, used: False
[2m[36m(pid=21635)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21635)[0m 
[2m[36m(pid=21635)[0m   | Name      | Type              | Params
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21635)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21635)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 12.0 K    Trainable params
[2m[36m(pid=21635)[0m 0         Non-trainable params
[2m[36m(pid=21635)[0m 12.0 K    Total params
[2m[36m(pid=21624)[0m time to fit was 155.75000286102295
Result for _inner_e98d6_00042:
  auc: 0.9128313779830932
  date: 2021-03-18_00-07-35
  done: false
  experiment_id: 879fa4e69742467897df078e490d93bc
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21624
  time_since_restore: 894.5536222457886
  time_this_iter_s: 894.5536222457886
  time_total_s: 894.5536222457886
  timestamp: 1616022455
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00042
  
[2m[36m(pid=21624)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 128 - mean val auc: 0.9128313779830932
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 55/180 (1 PENDING, 26 RUNNING, 28 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00054 | PENDING    |       |          512 |     0 | 2     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 35 more trials not shown (16 RUNNING, 18 TERMINATED)


Result for _inner_e98d6_00042:
  auc: 0.9128313779830932
  date: 2021-03-18_00-07-35
  done: true
  experiment_id: 879fa4e69742467897df078e490d93bc
  experiment_tag: 42_batch_size=128,eta=0.0,lr=0.1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21624
  time_since_restore: 894.5536222457886
  time_this_iter_s: 894.5536222457886
  time_total_s: 894.5536222457886
  timestamp: 1616022455
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00042
  
[2m[36m(pid=21630)[0m time to fit was 286.46657395362854
Result for _inner_e98d6_00036:
  auc: 0.9104490995407104
  date: 2021-03-18_00-07-43
  done: false
  experiment_id: 4498ad765c7544bd8f7bc0d7d2841f66
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21630
  time_since_restore: 2167.5699689388275
  time_this_iter_s: 2167.5699689388275
  time_total_s: 2167.5699689388275
  timestamp: 1616022463
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00036
  
[2m[36m(pid=21630)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 64 - mean val auc: 0.9104490995407104
== Status ==
Memory usage on this node: 10.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 56/180 (1 PENDING, 26 RUNNING, 29 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00055 | PENDING    |       |           32 |     0 | 5     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 36 more trials not shown (16 RUNNING, 19 TERMINATED)


Result for _inner_e98d6_00036:
  auc: 0.9104490995407104
  date: 2021-03-18_00-07-43
  done: true
  experiment_id: 4498ad765c7544bd8f7bc0d7d2841f66
  experiment_tag: 36_batch_size=64,eta=0.0,lr=0.01,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21630
  time_since_restore: 2167.5699689388275
  time_this_iter_s: 2167.5699689388275
  time_total_s: 2167.5699689388275
  timestamp: 1616022463
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00036
  
[2m[36m(pid=5335)[0m Starting run with seed 0 - lr 2 - sec_lr 0.01 - bs 512
[2m[36m(pid=5335)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5335)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=5335)[0m GPU available: False, used: False
[2m[36m(pid=5335)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5335)[0m 
[2m[36m(pid=5335)[0m   | Name      | Type              | Params
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5335)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5335)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 12.0 K    Trainable params
[2m[36m(pid=5335)[0m 0         Non-trainable params
[2m[36m(pid=5335)[0m 12.0 K    Total params
[2m[36m(pid=5335)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5335)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5335)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5335)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5335)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=5335)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m Starting run with seed 0 - lr 5 - sec_lr 0.01 - bs 32
[2m[36m(pid=5628)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5628)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=5628)[0m GPU available: False, used: False
[2m[36m(pid=5628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5628)[0m 
[2m[36m(pid=5628)[0m   | Name      | Type              | Params
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 12.0 K    Trainable params
[2m[36m(pid=5628)[0m 0         Non-trainable params
[2m[36m(pid=5628)[0m 12.0 K    Total params
[2m[36m(pid=5628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=5628)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21627)[0m time to fit was 1171.776667356491
[2m[36m(pid=21627)[0m GPU available: False, used: False
[2m[36m(pid=21627)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21627)[0m 
[2m[36m(pid=21627)[0m   | Name      | Type              | Params
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21627)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21627)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 12.0 K    Trainable params
[2m[36m(pid=21627)[0m 0         Non-trainable params
[2m[36m(pid=21627)[0m 12.0 K    Total params
[2m[36m(pid=21631)[0m time to fit was 108.62095284461975
[2m[36m(pid=21631)[0m GPU available: False, used: False
[2m[36m(pid=21631)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21631)[0m 
[2m[36m(pid=21631)[0m   | Name      | Type              | Params
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21631)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21631)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21631)[0m ------------------------------------------------
[2m[36m(pid=21631)[0m 12.0 K    Trainable params
[2m[36m(pid=21631)[0m 0         Non-trainable params
[2m[36m(pid=21631)[0m 12.0 K    Total params
[2m[36m(pid=3131)[0m time to fit was 118.7173330783844
[2m[36m(pid=3131)[0m GPU available: False, used: False
[2m[36m(pid=3131)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3131)[0m 
[2m[36m(pid=3131)[0m   | Name      | Type              | Params
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3131)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3131)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 12.0 K    Trainable params
[2m[36m(pid=3131)[0m 0         Non-trainable params
[2m[36m(pid=3131)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m time to fit was 232.84043788909912
[2m[36m(pid=52037)[0m GPU available: False, used: False
[2m[36m(pid=52037)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52037)[0m 
[2m[36m(pid=52037)[0m   | Name      | Type              | Params
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52037)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52037)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 12.0 K    Trainable params
[2m[36m(pid=52037)[0m 0         Non-trainable params
[2m[36m(pid=52037)[0m 12.0 K    Total params
[2m[36m(pid=21629)[0m time to fit was 99.02225947380066
[2m[36m(pid=21629)[0m GPU available: False, used: False
[2m[36m(pid=21629)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21629)[0m 
[2m[36m(pid=21629)[0m   | Name      | Type              | Params
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21629)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21629)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21629)[0m ------------------------------------------------
[2m[36m(pid=21629)[0m 12.0 K    Trainable params
[2m[36m(pid=21629)[0m 0         Non-trainable params
[2m[36m(pid=21629)[0m 12.0 K    Total params
[2m[36m(pid=21639)[0m time to fit was 2568.0364861488342
[2m[36m(pid=21639)[0m GPU available: False, used: False
[2m[36m(pid=21639)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21639)[0m 
[2m[36m(pid=21639)[0m   | Name      | Type              | Params
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21639)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21639)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 12.0 K    Trainable params
[2m[36m(pid=21639)[0m 0         Non-trainable params
[2m[36m(pid=21639)[0m 12.0 K    Total params
[2m[36m(pid=21633)[0m time to fit was 333.98204588890076
Result for _inner_e98d6_00041:
  auc: 0.9120811820030212
  date: 2021-03-18_00-09-17
  done: false
  experiment_id: f56bbedea35c492e8e1b186e9814dd6b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21633
  time_since_restore: 1557.826533794403
  time_this_iter_s: 1557.826533794403
  time_total_s: 1557.826533794403
  timestamp: 1616022557
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00041
  
[2m[36m(pid=21633)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 64 - mean val auc: 0.9120811820030212
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00018 with auc=0.9141204833984375 and parameters={'lr': 1, 'sec_lr': 0.001, 'batch_size': 256, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 57/180 (1 PENDING, 26 RUNNING, 30 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00056 | PENDING    |       |           64 |     0 | 5     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 37 more trials not shown (16 RUNNING, 20 TERMINATED)


Result for _inner_e98d6_00041:
  auc: 0.9120811820030212
  date: 2021-03-18_00-09-17
  done: true
  experiment_id: f56bbedea35c492e8e1b186e9814dd6b
  experiment_tag: 41_batch_size=64,eta=0.0,lr=0.1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21633
  time_since_restore: 1557.826533794403
  time_this_iter_s: 1557.826533794403
  time_total_s: 1557.826533794403
  timestamp: 1616022557
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00041
  
2021-03-18 00:09:18,152	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff1fa374ee01000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=9398)[0m Starting run with seed 0 - lr 5 - sec_lr 0.01 - bs 64
[2m[36m(pid=9398)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9398)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9398)[0m GPU available: False, used: False
[2m[36m(pid=9398)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9398)[0m 
[2m[36m(pid=9398)[0m   | Name      | Type              | Params
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9398)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9398)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 12.0 K    Trainable params
[2m[36m(pid=9398)[0m 0         Non-trainable params
[2m[36m(pid=9398)[0m 12.0 K    Total params
[2m[36m(pid=9398)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9398)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9398)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9398)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9398)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9398)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21737)[0m time to fit was 1570.2985956668854
[2m[36m(pid=21737)[0m GPU available: False, used: False
[2m[36m(pid=21737)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m 
[2m[36m(pid=21737)[0m   | Name      | Type              | Params
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21737)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21737)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 12.0 K    Trainable params
[2m[36m(pid=21737)[0m 0         Non-trainable params
[2m[36m(pid=21737)[0m 12.0 K    Total params
[2m[36m(pid=5335)[0m time to fit was 139.4467329978943
[2m[36m(pid=5335)[0m GPU available: False, used: False
[2m[36m(pid=5335)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5335)[0m 
[2m[36m(pid=5335)[0m   | Name      | Type              | Params
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5335)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5335)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 12.0 K    Trainable params
[2m[36m(pid=5335)[0m 0         Non-trainable params
[2m[36m(pid=5335)[0m 12.0 K    Total params
[2m[36m(pid=21631)[0m time to fit was 86.50061249732971
Result for _inner_e98d6_00049:
  auc: 0.914304780960083
  date: 2021-03-18_00-10-09
  done: false
  experiment_id: 92edbdfe17c1453092ed3187430dd6f0
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21631
  time_since_restore: 469.2212965488434
  time_this_iter_s: 469.2212965488434
  time_total_s: 469.2212965488434
  timestamp: 1616022609
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00049
  
[2m[36m(pid=21631)[0m Finished run with seed 0 - lr 1 - sec_lr 0.01 - bs 512 - mean val auc: 0.914304780960083
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 58/180 (1 PENDING, 26 RUNNING, 31 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00057 | PENDING    |       |          128 |     0 | 5     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 38 more trials not shown (16 RUNNING, 21 TERMINATED)


Result for _inner_e98d6_00049:
  auc: 0.914304780960083
  date: 2021-03-18_00-10-09
  done: true
  experiment_id: 92edbdfe17c1453092ed3187430dd6f0
  experiment_tag: 49_batch_size=512,eta=0.0,lr=1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21631
  time_since_restore: 469.2212965488434
  time_this_iter_s: 469.2212965488434
  time_total_s: 469.2212965488434
  timestamp: 1616022609
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00049
  
[2m[36m(pid=11433)[0m Starting run with seed 0 - lr 5 - sec_lr 0.01 - bs 128
[2m[36m(pid=11433)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11433)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=11433)[0m GPU available: False, used: False
[2m[36m(pid=11433)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11433)[0m 
[2m[36m(pid=11433)[0m   | Name      | Type              | Params
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11433)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11433)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 12.0 K    Trainable params
[2m[36m(pid=11433)[0m 0         Non-trainable params
[2m[36m(pid=11433)[0m 12.0 K    Total params
[2m[36m(pid=11433)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11433)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11433)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11433)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11433)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=11433)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21629)[0m time to fit was 113.15788912773132
Result for _inner_e98d6_00048:
  auc: 0.9137223243713379
  date: 2021-03-18_00-10-49
  done: false
  experiment_id: 81d46b6e8cfa4884b6e6b4429fcba5c7
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21629
  time_since_restore: 541.7044174671173
  time_this_iter_s: 541.7044174671173
  time_total_s: 541.7044174671173
  timestamp: 1616022649
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00048
  
[2m[36m(pid=21629)[0m Finished run with seed 0 - lr 1 - sec_lr 0.01 - bs 256 - mean val auc: 0.9137223243713379
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 59/180 (1 PENDING, 26 RUNNING, 32 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    |       |           64 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00058 | PENDING    |       |          256 |     0 | 5     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 39 more trials not shown (16 RUNNING, 22 TERMINATED)


Result for _inner_e98d6_00048:
  auc: 0.9137223243713379
  date: 2021-03-18_00-10-49
  done: true
  experiment_id: 81d46b6e8cfa4884b6e6b4429fcba5c7
  experiment_tag: 48_batch_size=256,eta=0.0,lr=1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21629
  time_since_restore: 541.7044174671173
  time_this_iter_s: 541.7044174671173
  time_total_s: 541.7044174671173
  timestamp: 1616022649
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00048
  
[2m[36m(pid=21623)[0m time to fit was 271.43366599082947
[2m[36m(pid=21623)[0m GPU available: False, used: False
[2m[36m(pid=21623)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21623)[0m 
[2m[36m(pid=21623)[0m   | Name      | Type              | Params
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21623)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21623)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 12.0 K    Trainable params
[2m[36m(pid=21623)[0m 0         Non-trainable params
[2m[36m(pid=21623)[0m 12.0 K    Total params
[2m[36m(pid=12914)[0m Starting run with seed 0 - lr 5 - sec_lr 0.01 - bs 256
[2m[36m(pid=12914)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12914)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=12914)[0m GPU available: False, used: False
[2m[36m(pid=12914)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12914)[0m 
[2m[36m(pid=12914)[0m   | Name      | Type              | Params
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12914)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12914)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 12.0 K    Trainable params
[2m[36m(pid=12914)[0m 0         Non-trainable params
[2m[36m(pid=12914)[0m 12.0 K    Total params
[2m[36m(pid=12914)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=12914)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12914)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=12914)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12914)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=12914)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3131)[0m time to fit was 139.2399137020111
[2m[36m(pid=3131)[0m GPU available: False, used: False
[2m[36m(pid=3131)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3131)[0m 
[2m[36m(pid=3131)[0m   | Name      | Type              | Params
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3131)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3131)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 12.0 K    Trainable params
[2m[36m(pid=3131)[0m 0         Non-trainable params
[2m[36m(pid=3131)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m time to fit was 425.21909379959106
[2m[36m(pid=21625)[0m GPU available: False, used: False
[2m[36m(pid=21625)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21625)[0m 
[2m[36m(pid=21625)[0m   | Name      | Type              | Params
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21625)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21625)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 12.0 K    Trainable params
[2m[36m(pid=21625)[0m 0         Non-trainable params
[2m[36m(pid=21625)[0m 12.0 K    Total params
[2m[36m(pid=21636)[0m time to fit was 264.30913186073303
[2m[36m(pid=21636)[0m GPU available: False, used: False
[2m[36m(pid=21636)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21636)[0m 
[2m[36m(pid=21636)[0m   | Name      | Type              | Params
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21636)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21636)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 12.0 K    Trainable params
[2m[36m(pid=21636)[0m 0         Non-trainable params
[2m[36m(pid=21636)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m time to fit was 190.3163924217224
[2m[36m(pid=52037)[0m GPU available: False, used: False
[2m[36m(pid=52037)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52037)[0m 
[2m[36m(pid=52037)[0m   | Name      | Type              | Params
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52037)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52037)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 12.0 K    Trainable params
[2m[36m(pid=52037)[0m 0         Non-trainable params
[2m[36m(pid=52037)[0m 12.0 K    Total params
[2m[36m(pid=11433)[0m time to fit was 121.80877995491028
[2m[36m(pid=11433)[0m GPU available: False, used: False
[2m[36m(pid=11433)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11433)[0m 
[2m[36m(pid=11433)[0m   | Name      | Type              | Params
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11433)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11433)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 12.0 K    Trainable params
[2m[36m(pid=11433)[0m 0         Non-trainable params
[2m[36m(pid=11433)[0m 12.0 K    Total params
[2m[36m(pid=5335)[0m time to fit was 151.14237594604492
[2m[36m(pid=5335)[0m GPU available: False, used: False
[2m[36m(pid=5335)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5335)[0m 
[2m[36m(pid=5335)[0m   | Name      | Type              | Params
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5335)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5335)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 12.0 K    Trainable params
[2m[36m(pid=5335)[0m 0         Non-trainable params
[2m[36m(pid=5335)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m time to fit was 615.7790741920471
[2m[36m(pid=21626)[0m GPU available: False, used: False
[2m[36m(pid=21626)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21626)[0m 
[2m[36m(pid=21626)[0m   | Name      | Type              | Params
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21626)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21626)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 12.0 K    Trainable params
[2m[36m(pid=21626)[0m 0         Non-trainable params
[2m[36m(pid=21626)[0m 12.0 K    Total params
[2m[36m(pid=21691)[0m time to fit was 742.545126914978
Result for _inner_e98d6_00006:
  auc: 0.912795615196228
  date: 2021-03-18_00-12-56
  done: false
  experiment_id: 081aac2852ef457eb5062529c14139f5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21691
  time_since_restore: 4029.6296377182007
  time_this_iter_s: 4029.6296377182007
  time_total_s: 4029.6296377182007
  timestamp: 1616022776
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00006
  
[2m[36m(pid=21691)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 64 - mean val auc: 0.912795615196228
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 60/180 (1 PENDING, 26 RUNNING, 33 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |                     |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00006 | RUNNING    | 145.101.32.82:21691 |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00059 | PENDING    |                     |          512 |     0 | 5     |    0.01  |        |                  |          |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 40 more trials not shown (16 RUNNING, 23 TERMINATED)


Result for _inner_e98d6_00006:
  auc: 0.912795615196228
  date: 2021-03-18_00-12-56
  done: true
  experiment_id: 081aac2852ef457eb5062529c14139f5
  experiment_tag: 6_batch_size=64,eta=0.0,lr=0.01,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21691
  time_since_restore: 4029.6296377182007
  time_this_iter_s: 4029.6296377182007
  time_total_s: 4029.6296377182007
  timestamp: 1616022776
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00006
  
2021-03-18 00:12:58,842	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff5aedc34401000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=3131)[0m time to fit was 119.42438101768494
[2m[36m(pid=3131)[0m GPU available: False, used: False
[2m[36m(pid=3131)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3131)[0m 
[2m[36m(pid=3131)[0m   | Name      | Type              | Params
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3131)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3131)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 12.0 K    Trainable params
[2m[36m(pid=3131)[0m 0         Non-trainable params
[2m[36m(pid=3131)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m Starting run with seed 0 - lr 5 - sec_lr 0.01 - bs 512
[2m[36m(pid=17685)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17685)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=17685)[0m GPU available: False, used: False
[2m[36m(pid=17685)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=17685)[0m 
[2m[36m(pid=17685)[0m   | Name      | Type              | Params
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=17685)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=17685)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 12.0 K    Trainable params
[2m[36m(pid=17685)[0m 0         Non-trainable params
[2m[36m(pid=17685)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=17685)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=17685)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=17685)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=17685)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=17685)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12914)[0m time to fit was 138.95485877990723
[2m[36m(pid=12914)[0m GPU available: False, used: False
[2m[36m(pid=12914)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12914)[0m 
[2m[36m(pid=12914)[0m   | Name      | Type              | Params
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12914)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12914)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 12.0 K    Trainable params
[2m[36m(pid=12914)[0m 0         Non-trainable params
[2m[36m(pid=12914)[0m 12.0 K    Total params
[2m[36m(pid=5335)[0m time to fit was 45.74079704284668
[2m[36m(pid=5335)[0m GPU available: False, used: False
[2m[36m(pid=5335)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5335)[0m 
[2m[36m(pid=5335)[0m   | Name      | Type              | Params
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5335)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5335)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 12.0 K    Trainable params
[2m[36m(pid=5335)[0m 0         Non-trainable params
[2m[36m(pid=5335)[0m 12.0 K    Total params
[2m[36m(pid=21731)[0m time to fit was 4058.0573694705963
[2m[36m(pid=21731)[0m GPU available: False, used: False
[2m[36m(pid=21731)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21731)[0m 
[2m[36m(pid=21731)[0m   | Name      | Type              | Params
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21731)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21731)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 12.0 K    Trainable params
[2m[36m(pid=21731)[0m 0         Non-trainable params
[2m[36m(pid=21731)[0m 12.0 K    Total params
[2m[36m(pid=21661)[0m time to fit was 2999.9366450309753
[2m[36m(pid=21661)[0m GPU available: False, used: False
[2m[36m(pid=21661)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21661)[0m 
[2m[36m(pid=21661)[0m   | Name      | Type              | Params
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21661)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21661)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 12.0 K    Trainable params
[2m[36m(pid=21661)[0m 0         Non-trainable params
[2m[36m(pid=21661)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m time to fit was 46.074143409729004
[2m[36m(pid=17685)[0m GPU available: False, used: False
[2m[36m(pid=17685)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=17685)[0m 
[2m[36m(pid=17685)[0m   | Name      | Type              | Params
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=17685)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=17685)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 12.0 K    Trainable params
[2m[36m(pid=17685)[0m 0         Non-trainable params
[2m[36m(pid=17685)[0m 12.0 K    Total params
[2m[36m(pid=21628)[0m time to fit was 612.42622590065
[2m[36m(pid=21628)[0m GPU available: False, used: False
[2m[36m(pid=21628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21628)[0m 
[2m[36m(pid=21628)[0m   | Name      | Type              | Params
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 12.0 K    Trainable params
[2m[36m(pid=21628)[0m 0         Non-trainable params
[2m[36m(pid=21628)[0m 12.0 K    Total params
[2m[36m(pid=12914)[0m time to fit was 78.68292331695557
[2m[36m(pid=12914)[0m GPU available: False, used: False
[2m[36m(pid=12914)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12914)[0m 
[2m[36m(pid=12914)[0m   | Name      | Type              | Params
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12914)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12914)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 12.0 K    Trainable params
[2m[36m(pid=12914)[0m 0         Non-trainable params
[2m[36m(pid=12914)[0m 12.0 K    Total params
[2m[36m(pid=3131)[0m time to fit was 94.18228197097778
[2m[36m(pid=3131)[0m GPU available: False, used: False
[2m[36m(pid=3131)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3131)[0m 
[2m[36m(pid=3131)[0m   | Name      | Type              | Params
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3131)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3131)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3131)[0m ------------------------------------------------
[2m[36m(pid=3131)[0m 12.0 K    Trainable params
[2m[36m(pid=3131)[0m 0         Non-trainable params
[2m[36m(pid=3131)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m time to fit was 46.460880517959595
[2m[36m(pid=5335)[0m time to fit was 78.6639335155487
[2m[36m(pid=17685)[0m GPU available: False, used: False
[2m[36m(pid=17685)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=17685)[0m 
[2m[36m(pid=17685)[0m   | Name      | Type              | Params
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=17685)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=17685)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 12.0 K    Trainable params
[2m[36m(pid=17685)[0m 0         Non-trainable params
[2m[36m(pid=17685)[0m 12.0 K    Total params
[2m[36m(pid=5335)[0m GPU available: False, used: False
[2m[36m(pid=5335)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5335)[0m 
[2m[36m(pid=5335)[0m   | Name      | Type              | Params
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5335)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5335)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5335)[0m ------------------------------------------------
[2m[36m(pid=5335)[0m 12.0 K    Trainable params
[2m[36m(pid=5335)[0m 0         Non-trainable params
[2m[36m(pid=5335)[0m 12.0 K    Total params
[2m[36m(pid=21623)[0m time to fit was 250.77981567382812
[2m[36m(pid=21623)[0m GPU available: False, used: False
[2m[36m(pid=21623)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21623)[0m 
[2m[36m(pid=21623)[0m   | Name      | Type              | Params
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21623)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21623)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21623)[0m ------------------------------------------------
[2m[36m(pid=21623)[0m 12.0 K    Trainable params
[2m[36m(pid=21623)[0m 0         Non-trainable params
[2m[36m(pid=21623)[0m 12.0 K    Total params
[2m[36m(pid=21635)[0m time to fit was 463.8002257347107
[2m[36m(pid=21635)[0m GPU available: False, used: False
[2m[36m(pid=21635)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21635)[0m 
[2m[36m(pid=21635)[0m   | Name      | Type              | Params
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21635)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21635)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21635)[0m ------------------------------------------------
[2m[36m(pid=21635)[0m 12.0 K    Trainable params
[2m[36m(pid=21635)[0m 0         Non-trainable params
[2m[36m(pid=21635)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m time to fit was 47.04491305351257
[2m[36m(pid=17685)[0m GPU available: False, used: False
[2m[36m(pid=17685)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=17685)[0m 
[2m[36m(pid=17685)[0m   | Name      | Type              | Params
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=17685)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=17685)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 12.0 K    Trainable params
[2m[36m(pid=17685)[0m 0         Non-trainable params
[2m[36m(pid=17685)[0m 12.0 K    Total params
[2m[36m(pid=12914)[0m time to fit was 98.69432735443115
[2m[36m(pid=12914)[0m GPU available: False, used: False
[2m[36m(pid=12914)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12914)[0m 
[2m[36m(pid=12914)[0m   | Name      | Type              | Params
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12914)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12914)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 12.0 K    Trainable params
[2m[36m(pid=12914)[0m 0         Non-trainable params
[2m[36m(pid=12914)[0m 12.0 K    Total params
[2m[36m(pid=3131)[0m time to fit was 106.43951272964478
Result for _inner_e98d6_00053:
  auc: 0.9114279389381409
  date: 2021-03-18_00-16-27
  done: false
  experiment_id: 4bb391f271cd4db8807b3921b013bfbc
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3131
  time_since_restore: 579.315004825592
  time_this_iter_s: 579.315004825592
  time_total_s: 579.315004825592
  timestamp: 1616022987
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00053
  
[2m[36m(pid=3131)[0m Finished run with seed 0 - lr 2 - sec_lr 0.01 - bs 256 - mean val auc: 0.9114279389381409
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 61/180 (1 PENDING, 26 RUNNING, 34 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00060 | PENDING    |       |           32 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 41 more trials not shown (16 RUNNING, 24 TERMINATED)


Result for _inner_e98d6_00053:
  auc: 0.9114279389381409
  date: 2021-03-18_00-16-27
  done: true
  experiment_id: 4bb391f271cd4db8807b3921b013bfbc
  experiment_tag: 53_batch_size=256,eta=0.0,lr=2,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3131
  time_since_restore: 579.315004825592
  time_this_iter_s: 579.315004825592
  time_total_s: 579.315004825592
  timestamp: 1616022987
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00053
  
2021-03-18 00:16:29,463	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff1e69661801000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=5335)[0m time to fit was 109.13218760490417
Result for _inner_e98d6_00054:
  auc: 0.7667165040969849
  date: 2021-03-18_00-16-31
  done: false
  experiment_id: 57a9625c689d41bda2bd442ff65c713c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5335
  time_since_restore: 525.3395285606384
  time_this_iter_s: 525.3395285606384
  time_total_s: 525.3395285606384
  timestamp: 1616022991
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00054
  
Result for _inner_e98d6_00054:
  auc: 0.7667165040969849
  date: 2021-03-18_00-16-31
  done: true
  experiment_id: 57a9625c689d41bda2bd442ff65c713c
  experiment_tag: 54_batch_size=512,eta=0.0,lr=2,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5335
  time_since_restore: 525.3395285606384
  time_this_iter_s: 525.3395285606384
  time_total_s: 525.3395285606384
  timestamp: 1616022991
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00054
  
[2m[36m(pid=5335)[0m Finished run with seed 0 - lr 2 - sec_lr 0.01 - bs 512 - mean val auc: 0.7667165040969849
[2m[36m(pid=26509)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 32
[2m[36m(pid=26509)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26509)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=26509)[0m GPU available: False, used: False
[2m[36m(pid=26509)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26509)[0m 
[2m[36m(pid=26509)[0m   | Name      | Type              | Params
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26509)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26509)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 12.0 K    Trainable params
[2m[36m(pid=26509)[0m 0         Non-trainable params
[2m[36m(pid=26509)[0m 12.0 K    Total params
[2m[36m(pid=26509)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26509)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26509)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26509)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26509)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=26509)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26638)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 64
[2m[36m(pid=26638)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26638)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=26638)[0m GPU available: False, used: False
[2m[36m(pid=26638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26638)[0m 
[2m[36m(pid=26638)[0m   | Name      | Type              | Params
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 12.0 K    Trainable params
[2m[36m(pid=26638)[0m 0         Non-trainable params
[2m[36m(pid=26638)[0m 12.0 K    Total params
[2m[36m(pid=26638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26638)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=26638)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21636)[0m time to fit was 343.63671374320984
[2m[36m(pid=21636)[0m GPU available: False, used: False
[2m[36m(pid=21636)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21636)[0m 
[2m[36m(pid=21636)[0m   | Name      | Type              | Params
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21636)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21636)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21636)[0m ------------------------------------------------
[2m[36m(pid=21636)[0m 12.0 K    Trainable params
[2m[36m(pid=21636)[0m 0         Non-trainable params
[2m[36m(pid=21636)[0m 12.0 K    Total params
[2m[36m(pid=21623)[0m time to fit was 157.89874839782715
Result for _inner_e98d6_00047:
  auc: 0.912090516090393
  date: 2021-03-18_00-17-46
  done: false
  experiment_id: 22d01b7410734606a6f0844c9ae55bc4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21623
  time_since_restore: 1050.5453214645386
  time_this_iter_s: 1050.5453214645386
  time_total_s: 1050.5453214645386
  timestamp: 1616023066
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00047
  
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 63/180 (1 PENDING, 26 RUNNING, 36 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00062 | PENDING    |       |          128 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 43 more trials not shown (16 RUNNING, 26 TERMINATED)


[2m[36m(pid=21623)[0m Finished run with seed 0 - lr 1 - sec_lr 0.01 - bs 128 - mean val auc: 0.912090516090393
Result for _inner_e98d6_00047:
  auc: 0.912090516090393
  date: 2021-03-18_00-17-46
  done: true
  experiment_id: 22d01b7410734606a6f0844c9ae55bc4
  experiment_tag: 47_batch_size=128,eta=0.0,lr=1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21623
  time_since_restore: 1050.5453214645386
  time_this_iter_s: 1050.5453214645386
  time_total_s: 1050.5453214645386
  timestamp: 1616023066
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00047
  
[2m[36m(pid=17685)[0m time to fit was 137.5246925354004
[2m[36m(pid=17685)[0m GPU available: False, used: False
[2m[36m(pid=17685)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=17685)[0m 
[2m[36m(pid=17685)[0m   | Name      | Type              | Params
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=17685)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=17685)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=17685)[0m ------------------------------------------------
[2m[36m(pid=17685)[0m 12.0 K    Trainable params
[2m[36m(pid=17685)[0m 0         Non-trainable params
[2m[36m(pid=17685)[0m 12.0 K    Total params
[2m[36m(pid=9398)[0m time to fit was 507.0434935092926
[2m[36m(pid=9398)[0m GPU available: False, used: False
[2m[36m(pid=9398)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9398)[0m 
[2m[36m(pid=9398)[0m   | Name      | Type              | Params
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9398)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9398)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 12.0 K    Trainable params
[2m[36m(pid=9398)[0m 0         Non-trainable params
[2m[36m(pid=9398)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 128
[2m[36m(pid=29305)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29305)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=29305)[0m GPU available: False, used: False
[2m[36m(pid=29305)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29305)[0m 
[2m[36m(pid=29305)[0m   | Name      | Type              | Params
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29305)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29305)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 12.0 K    Trainable params
[2m[36m(pid=29305)[0m 0         Non-trainable params
[2m[36m(pid=29305)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=29305)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29305)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=29305)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29305)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=29305)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=52037)[0m time to fit was 363.0485119819641
[2m[36m(pid=52037)[0m GPU available: False, used: False
[2m[36m(pid=52037)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52037)[0m 
[2m[36m(pid=52037)[0m   | Name      | Type              | Params
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52037)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52037)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 12.0 K    Trainable params
[2m[36m(pid=52037)[0m 0         Non-trainable params
[2m[36m(pid=52037)[0m 12.0 K    Total params
[2m[36m(pid=17685)[0m time to fit was 45.83651351928711
Result for _inner_e98d6_00059:
  auc: 0.5824637889862061
  date: 2021-03-18_00-18-33
  done: false
  experiment_id: 6e89fde0ff604a41883040a6a147dd0d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 17685
  time_since_restore: 324.1364779472351
  time_this_iter_s: 324.1364779472351
  time_total_s: 324.1364779472351
  timestamp: 1616023113
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00059
  
[2m[36m(pid=17685)[0m Finished run with seed 0 - lr 5 - sec_lr 0.01 - bs 512 - mean val auc: 0.5824637889862061
== Status ==
Memory usage on this node: 10.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 64/180 (1 PENDING, 26 RUNNING, 37 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | PENDING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 44 more trials not shown (16 RUNNING, 27 TERMINATED)


Result for _inner_e98d6_00059:
  auc: 0.5824637889862061
  date: 2021-03-18_00-18-33
  done: true
  experiment_id: 6e89fde0ff604a41883040a6a147dd0d
  experiment_tag: 59_batch_size=512,eta=0.0,lr=5,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 17685
  time_since_restore: 324.1364779472351
  time_this_iter_s: 324.1364779472351
  time_total_s: 324.1364779472351
  timestamp: 1616023113
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00059
  
[2m[36m(pid=31069)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 256
[2m[36m(pid=31069)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=31069)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=31069)[0m GPU available: False, used: False
[2m[36m(pid=31069)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31069)[0m 
[2m[36m(pid=31069)[0m   | Name      | Type              | Params
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31069)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31069)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 12.0 K    Trainable params
[2m[36m(pid=31069)[0m 0         Non-trainable params
[2m[36m(pid=31069)[0m 12.0 K    Total params
[2m[36m(pid=31069)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=31069)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=31069)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=31069)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=31069)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=31069)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m time to fit was 661.2329077720642
[2m[36m(pid=5628)[0m GPU available: False, used: False
[2m[36m(pid=5628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5628)[0m 
[2m[36m(pid=5628)[0m   | Name      | Type              | Params
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 12.0 K    Trainable params
[2m[36m(pid=5628)[0m 0         Non-trainable params
[2m[36m(pid=5628)[0m 12.0 K    Total params
[2m[36m(pid=21627)[0m time to fit was 658.0917222499847
[2m[36m(pid=21627)[0m GPU available: False, used: False
[2m[36m(pid=21627)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21627)[0m 
[2m[36m(pid=21627)[0m   | Name      | Type              | Params
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21627)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21627)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21627)[0m ------------------------------------------------
[2m[36m(pid=21627)[0m 12.0 K    Trainable params
[2m[36m(pid=21627)[0m 0         Non-trainable params
[2m[36m(pid=21627)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m time to fit was 188.03601670265198
[2m[36m(pid=52037)[0m GPU available: False, used: False
[2m[36m(pid=52037)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52037)[0m 
[2m[36m(pid=52037)[0m   | Name      | Type              | Params
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52037)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52037)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52037)[0m ------------------------------------------------
[2m[36m(pid=52037)[0m 12.0 K    Trainable params
[2m[36m(pid=52037)[0m 0         Non-trainable params
[2m[36m(pid=52037)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m time to fit was 591.787162065506
[2m[36m(pid=21625)[0m GPU available: False, used: False
[2m[36m(pid=21625)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21625)[0m 
[2m[36m(pid=21625)[0m   | Name      | Type              | Params
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21625)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21625)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 12.0 K    Trainable params
[2m[36m(pid=21625)[0m 0         Non-trainable params
[2m[36m(pid=21625)[0m 12.0 K    Total params
[2m[36m(pid=21636)[0m time to fit was 259.20662569999695
Result for _inner_e98d6_00046:
  auc: 0.9116374135017395
  date: 2021-03-18_00-21-40
  done: false
  experiment_id: 4f689a8d1ba647cf85a0bcefeb580dee
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21636
  time_since_restore: 1452.5618391036987
  time_this_iter_s: 1452.5618391036987
  time_total_s: 1452.5618391036987
  timestamp: 1616023300
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00046
  
== Status ==
Memory usage on this node: 13.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 65/180 (1 PENDING, 26 RUNNING, 38 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00064 | PENDING    |       |          512 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 45 more trials not shown (16 RUNNING, 28 TERMINATED)


Result for _inner_e98d6_00046:
  auc: 0.9116374135017395
  date: 2021-03-18_00-21-40
  done: true
  experiment_id: 4f689a8d1ba647cf85a0bcefeb580dee
  experiment_tag: 46_batch_size=64,eta=0.0,lr=1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21636
  time_since_restore: 1452.5618391036987
  time_this_iter_s: 1452.5618391036987
  time_total_s: 1452.5618391036987
  timestamp: 1616023300
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00046
  
[2m[36m(pid=21636)[0m Finished run with seed 0 - lr 1 - sec_lr 0.01 - bs 64 - mean val auc: 0.9116374135017395
[2m[36m(pid=37757)[0m Starting run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 512
[2m[36m(pid=37757)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37757)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=37757)[0m GPU available: False, used: False
[2m[36m(pid=37757)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37757)[0m 
[2m[36m(pid=37757)[0m   | Name      | Type              | Params
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37757)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37757)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 12.0 K    Trainable params
[2m[36m(pid=37757)[0m 0         Non-trainable params
[2m[36m(pid=37757)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=37757)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29305)[0m time to fit was 234.19078183174133
[2m[36m(pid=29305)[0m GPU available: False, used: False
[2m[36m(pid=29305)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29305)[0m 
[2m[36m(pid=29305)[0m   | Name      | Type              | Params
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29305)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29305)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 12.0 K    Trainable params
[2m[36m(pid=29305)[0m 0         Non-trainable params
[2m[36m(pid=29305)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=37757)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=37757)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=37757)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9398)[0m time to fit was 240.1403591632843
[2m[36m(pid=9398)[0m GPU available: False, used: False
[2m[36m(pid=9398)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9398)[0m 
[2m[36m(pid=9398)[0m   | Name      | Type              | Params
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9398)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9398)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 12.0 K    Trainable params
[2m[36m(pid=9398)[0m 0         Non-trainable params
[2m[36m(pid=9398)[0m 12.0 K    Total params
[2m[36m(pid=26638)[0m time to fit was 360.0974872112274
[2m[36m(pid=26638)[0m GPU available: False, used: False
[2m[36m(pid=26638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26638)[0m 
[2m[36m(pid=26638)[0m   | Name      | Type              | Params
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 12.0 K    Trainable params
[2m[36m(pid=26638)[0m 0         Non-trainable params
[2m[36m(pid=26638)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m time to fit was 94.37233972549438
[2m[36m(pid=37757)[0m GPU available: False, used: False
[2m[36m(pid=37757)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37757)[0m 
[2m[36m(pid=37757)[0m   | Name      | Type              | Params
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37757)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37757)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 12.0 K    Trainable params
[2m[36m(pid=37757)[0m 0         Non-trainable params
[2m[36m(pid=37757)[0m 12.0 K    Total params
[2m[36m(pid=21737)[0m time to fit was 856.4079957008362
[2m[36m(pid=21737)[0m GPU available: False, used: False
[2m[36m(pid=21737)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21737)[0m 
[2m[36m(pid=21737)[0m   | Name      | Type              | Params
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21737)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21737)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21737)[0m ------------------------------------------------
[2m[36m(pid=21737)[0m 12.0 K    Trainable params
[2m[36m(pid=21737)[0m 0         Non-trainable params
[2m[36m(pid=21737)[0m 12.0 K    Total params
[2m[36m(pid=21635)[0m time to fit was 536.450154542923
Result for _inner_e98d6_00040:
  auc: 0.9122784376144409
  date: 2021-03-18_00-24-06
  done: false
  experiment_id: db981181ccb8446f9a9ff691f0a995c9
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21635
  time_since_restore: 2506.066884994507
  time_this_iter_s: 2506.066884994507
  time_total_s: 2506.066884994507
  timestamp: 1616023446
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00040
  
[2m[36m(pid=21635)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.01 - bs 32 - mean val auc: 0.9122784376144409
== Status ==
Memory usage on this node: 13.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 66/180 (1 PENDING, 26 RUNNING, 39 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00065 | PENDING    |       |           32 |     0 | 0.01  |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 46 more trials not shown (16 RUNNING, 29 TERMINATED)


Result for _inner_e98d6_00040:
  auc: 0.9122784376144409
  date: 2021-03-18_00-24-06
  done: true
  experiment_id: db981181ccb8446f9a9ff691f0a995c9
  experiment_tag: 40_batch_size=32,eta=0.0,lr=0.1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21635
  time_since_restore: 2506.066884994507
  time_this_iter_s: 2506.066884994507
  time_total_s: 2506.066884994507
  timestamp: 1616023446
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00040
  
[2m[36m(pid=12914)[0m time to fit was 469.18196177482605
[2m[36m(pid=12914)[0m GPU available: False, used: False
[2m[36m(pid=12914)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12914)[0m 
[2m[36m(pid=12914)[0m   | Name      | Type              | Params
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12914)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12914)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12914)[0m ------------------------------------------------
[2m[36m(pid=12914)[0m 12.0 K    Trainable params
[2m[36m(pid=12914)[0m 0         Non-trainable params
[2m[36m(pid=12914)[0m 12.0 K    Total params
[2m[36m(pid=21628)[0m time to fit was 577.8989748954773
[2m[36m(pid=21628)[0m GPU available: False, used: False
[2m[36m(pid=21628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21628)[0m 
[2m[36m(pid=21628)[0m   | Name      | Type              | Params
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 12.0 K    Trainable params
[2m[36m(pid=21628)[0m 0         Non-trainable params
[2m[36m(pid=21628)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 32
[2m[36m(pid=43203)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43203)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43203)[0m GPU available: False, used: False
[2m[36m(pid=43203)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43203)[0m 
[2m[36m(pid=43203)[0m   | Name      | Type              | Params
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43203)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43203)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 12.0 K    Trainable params
[2m[36m(pid=43203)[0m 0         Non-trainable params
[2m[36m(pid=43203)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43203)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43203)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43203)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43203)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43203)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26509)[0m time to fit was 496.3444848060608
[2m[36m(pid=26509)[0m GPU available: False, used: False
[2m[36m(pid=26509)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26509)[0m 
[2m[36m(pid=26509)[0m   | Name      | Type              | Params
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26509)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26509)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 12.0 K    Trainable params
[2m[36m(pid=26509)[0m 0         Non-trainable params
[2m[36m(pid=26509)[0m 12.0 K    Total params
[2m[36m(pid=52037)[0m time to fit was 236.9365222454071
Result for _inner_e98d6_00052:
  auc: 0.9090004324913025
  date: 2021-03-18_00-25-12
  done: false
  experiment_id: 7200914ce2634f98900010627d81d5e1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 52037
  time_since_restore: 1212.4957253932953
  time_this_iter_s: 1212.4957253932953
  time_total_s: 1212.4957253932953
  timestamp: 1616023512
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00052
  
[2m[36m(pid=52037)[0m Finished run with seed 0 - lr 2 - sec_lr 0.01 - bs 128 - mean val auc: 0.9090004324913025
== Status ==
Memory usage on this node: 13.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 67/180 (1 PENDING, 26 RUNNING, 40 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00066 | PENDING    |       |           64 |     0 | 0.01  |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 47 more trials not shown (16 RUNNING, 30 TERMINATED)


Result for _inner_e98d6_00052:
  auc: 0.9090004324913025
  date: 2021-03-18_00-25-12
  done: true
  experiment_id: 7200914ce2634f98900010627d81d5e1
  experiment_tag: 52_batch_size=128,eta=0.0,lr=2,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 52037
  time_since_restore: 1212.4957253932953
  time_this_iter_s: 1212.4957253932953
  time_total_s: 1212.4957253932953
  timestamp: 1616023512
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00052
  
[2m[36m(pid=45643)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 64
[2m[36m(pid=45643)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=45643)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=45643)[0m GPU available: False, used: False
[2m[36m(pid=45643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45643)[0m 
[2m[36m(pid=45643)[0m   | Name      | Type              | Params
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 12.0 K    Trainable params
[2m[36m(pid=45643)[0m 0         Non-trainable params
[2m[36m(pid=45643)[0m 12.0 K    Total params
[2m[36m(pid=45643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=45643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=45643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45643)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=45643)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21626)[0m time to fit was 811.5898771286011
[2m[36m(pid=21626)[0m GPU available: False, used: False
[2m[36m(pid=21626)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21626)[0m 
[2m[36m(pid=21626)[0m   | Name      | Type              | Params
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21626)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21626)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 12.0 K    Trainable params
[2m[36m(pid=21626)[0m 0         Non-trainable params
[2m[36m(pid=21626)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m time to fit was 270.3955981731415
[2m[36m(pid=29305)[0m GPU available: False, used: False
[2m[36m(pid=29305)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29305)[0m 
[2m[36m(pid=29305)[0m   | Name      | Type              | Params
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29305)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29305)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 12.0 K    Trainable params
[2m[36m(pid=29305)[0m 0         Non-trainable params
[2m[36m(pid=29305)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m time to fit was 186.03305649757385
[2m[36m(pid=37757)[0m GPU available: False, used: False
[2m[36m(pid=37757)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37757)[0m 
[2m[36m(pid=37757)[0m   | Name      | Type              | Params
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37757)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37757)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 12.0 K    Trainable params
[2m[36m(pid=37757)[0m 0         Non-trainable params
[2m[36m(pid=37757)[0m 12.0 K    Total params
[2m[36m(pid=5628)[0m time to fit was 466.96082949638367
[2m[36m(pid=5628)[0m GPU available: False, used: False
[2m[36m(pid=5628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5628)[0m 
[2m[36m(pid=5628)[0m   | Name      | Type              | Params
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 12.0 K    Trainable params
[2m[36m(pid=5628)[0m 0         Non-trainable params
[2m[36m(pid=5628)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m time to fit was 83.80088090896606
[2m[36m(pid=37757)[0m GPU available: False, used: False
[2m[36m(pid=37757)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37757)[0m 
[2m[36m(pid=37757)[0m   | Name      | Type              | Params
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37757)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37757)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 12.0 K    Trainable params
[2m[36m(pid=37757)[0m 0         Non-trainable params
[2m[36m(pid=37757)[0m 12.0 K    Total params
[2m[36m(pid=11433)[0m time to fit was 953.3505611419678
[2m[36m(pid=11433)[0m GPU available: False, used: False
[2m[36m(pid=11433)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11433)[0m 
[2m[36m(pid=11433)[0m   | Name      | Type              | Params
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11433)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11433)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 12.0 K    Trainable params
[2m[36m(pid=11433)[0m 0         Non-trainable params
[2m[36m(pid=11433)[0m 12.0 K    Total params
[2m[36m(pid=45643)[0m time to fit was 220.55771136283875
[2m[36m(pid=45643)[0m GPU available: False, used: False
[2m[36m(pid=45643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45643)[0m 
[2m[36m(pid=45643)[0m   | Name      | Type              | Params
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 12.0 K    Trainable params
[2m[36m(pid=45643)[0m 0         Non-trainable params
[2m[36m(pid=45643)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m time to fit was 489.5678277015686
[2m[36m(pid=21625)[0m GPU available: False, used: False
[2m[36m(pid=21625)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21625)[0m 
[2m[36m(pid=21625)[0m   | Name      | Type              | Params
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21625)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21625)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 12.0 K    Trainable params
[2m[36m(pid=21625)[0m 0         Non-trainable params
[2m[36m(pid=21625)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m time to fit was 105.88061618804932
[2m[36m(pid=37757)[0m GPU available: False, used: False
[2m[36m(pid=37757)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37757)[0m 
[2m[36m(pid=37757)[0m   | Name      | Type              | Params
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37757)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37757)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37757)[0m ------------------------------------------------
[2m[36m(pid=37757)[0m 12.0 K    Trainable params
[2m[36m(pid=37757)[0m 0         Non-trainable params
[2m[36m(pid=37757)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m time to fit was 235.85845708847046
[2m[36m(pid=29305)[0m GPU available: False, used: False
[2m[36m(pid=29305)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29305)[0m 
[2m[36m(pid=29305)[0m   | Name      | Type              | Params
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29305)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29305)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 12.0 K    Trainable params
[2m[36m(pid=29305)[0m 0         Non-trainable params
[2m[36m(pid=29305)[0m 12.0 K    Total params
[2m[36m(pid=11433)[0m time to fit was 154.7179913520813
[2m[36m(pid=11433)[0m GPU available: False, used: False
[2m[36m(pid=11433)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11433)[0m 
[2m[36m(pid=11433)[0m   | Name      | Type              | Params
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11433)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11433)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 12.0 K    Trainable params
[2m[36m(pid=11433)[0m 0         Non-trainable params
[2m[36m(pid=11433)[0m 12.0 K    Total params
[2m[36m(pid=37757)[0m time to fit was 110.12707495689392
[2m[36m(pid=37757)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 512 - mean val auc: 0.8576088547706604
Result for _inner_e98d6_00064:
  auc: 0.8576088547706604
  date: 2021-03-18_00-31-33
  done: false
  experiment_id: 38c2ba503f924571ae4205ce4cb77d1b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 37757
  time_since_restore: 581.4610457420349
  time_this_iter_s: 581.4610457420349
  time_total_s: 581.4610457420349
  timestamp: 1616023893
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00064
  
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 68/180 (1 PENDING, 26 RUNNING, 41 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00067 | PENDING    |       |          128 |     0 | 0.01  |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 48 more trials not shown (16 RUNNING, 31 TERMINATED)


Result for _inner_e98d6_00064:
  auc: 0.8576088547706604
  date: 2021-03-18_00-31-33
  done: true
  experiment_id: 38c2ba503f924571ae4205ce4cb77d1b
  experiment_tag: 64_batch_size=512,eta=0.0,lr=0.001,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 37757
  time_since_restore: 581.4610457420349
  time_this_iter_s: 581.4610457420349
  time_total_s: 581.4610457420349
  timestamp: 1616023893
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00064
  
[2m[36m(pid=6733)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 128
[2m[36m(pid=6733)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=6733)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=6733)[0m GPU available: False, used: False
[2m[36m(pid=6733)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6733)[0m 
[2m[36m(pid=6733)[0m   | Name      | Type              | Params
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6733)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6733)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 12.0 K    Trainable params
[2m[36m(pid=6733)[0m 0         Non-trainable params
[2m[36m(pid=6733)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6733)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21628)[0m time to fit was 455.5664439201355
[2m[36m(pid=21628)[0m GPU available: False, used: False
[2m[36m(pid=21628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21628)[0m 
[2m[36m(pid=21628)[0m   | Name      | Type              | Params
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21628)[0m ------------------------------------------------
[2m[36m(pid=21628)[0m 12.0 K    Trainable params
[2m[36m(pid=21628)[0m 0         Non-trainable params
[2m[36m(pid=21628)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6733)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6733)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=6733)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43203)[0m time to fit was 492.9297311306
[2m[36m(pid=43203)[0m GPU available: False, used: False
[2m[36m(pid=43203)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43203)[0m 
[2m[36m(pid=43203)[0m   | Name      | Type              | Params
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43203)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43203)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 12.0 K    Trainable params
[2m[36m(pid=43203)[0m 0         Non-trainable params
[2m[36m(pid=43203)[0m 12.0 K    Total params
[2m[36m(pid=45643)[0m time to fit was 223.09119653701782
[2m[36m(pid=45643)[0m GPU available: False, used: False
[2m[36m(pid=45643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45643)[0m 
[2m[36m(pid=45643)[0m   | Name      | Type              | Params
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 12.0 K    Trainable params
[2m[36m(pid=45643)[0m 0         Non-trainable params
[2m[36m(pid=45643)[0m 12.0 K    Total params
[2m[36m(pid=12914)[0m time to fit was 535.3147292137146
[2m[36m(pid=12914)[0m Finished run with seed 0 - lr 5 - sec_lr 0.01 - bs 256 - mean val auc: 0.6544020533561706
Result for _inner_e98d6_00058:
  auc: 0.6544020533561706
  date: 2021-03-18_00-33-03
  done: false
  experiment_id: c91a8a1cf8b64621971f47546fd2b6b9
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 12914
  time_since_restore: 1322.0999455451965
  time_this_iter_s: 1322.0999455451965
  time_total_s: 1322.0999455451965
  timestamp: 1616023983
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00058
  
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 69/180 (1 PENDING, 26 RUNNING, 42 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00068 | PENDING    |       |          256 |     0 | 0.01  |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 49 more trials not shown (16 RUNNING, 32 TERMINATED)


Result for _inner_e98d6_00058:
  auc: 0.6544020533561706
  date: 2021-03-18_00-33-03
  done: true
  experiment_id: c91a8a1cf8b64621971f47546fd2b6b9
  experiment_tag: 58_batch_size=256,eta=0.0,lr=5,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 12914
  time_since_restore: 1322.0999455451965
  time_this_iter_s: 1322.0999455451965
  time_total_s: 1322.0999455451965
  timestamp: 1616023983
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00058
  
[2m[36m(pid=9844)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 256
[2m[36m(pid=9844)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9844)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9844)[0m GPU available: False, used: False
[2m[36m(pid=9844)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9844)[0m 
[2m[36m(pid=9844)[0m   | Name      | Type              | Params
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9844)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9844)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 12.0 K    Trainable params
[2m[36m(pid=9844)[0m 0         Non-trainable params
[2m[36m(pid=9844)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9844)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11433)[0m time to fit was 143.33498334884644
[2m[36m(pid=11433)[0m GPU available: False, used: False
[2m[36m(pid=11433)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11433)[0m 
[2m[36m(pid=11433)[0m   | Name      | Type              | Params
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11433)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11433)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11433)[0m ------------------------------------------------
[2m[36m(pid=11433)[0m 12.0 K    Trainable params
[2m[36m(pid=11433)[0m 0         Non-trainable params
[2m[36m(pid=11433)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9844)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9844)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9844)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m time to fit was 421.42098236083984
[2m[36m(pid=5628)[0m GPU available: False, used: False
[2m[36m(pid=5628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5628)[0m 
[2m[36m(pid=5628)[0m   | Name      | Type              | Params
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 12.0 K    Trainable params
[2m[36m(pid=5628)[0m 0         Non-trainable params
[2m[36m(pid=5628)[0m 12.0 K    Total params
[2m[36m(pid=26509)[0m time to fit was 572.2101545333862
[2m[36m(pid=26509)[0m GPU available: False, used: False
[2m[36m(pid=26509)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26509)[0m 
[2m[36m(pid=26509)[0m   | Name      | Type              | Params
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26509)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26509)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 12.0 K    Trainable params
[2m[36m(pid=26509)[0m 0         Non-trainable params
[2m[36m(pid=26509)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m time to fit was 163.31787109375
[2m[36m(pid=6733)[0m GPU available: False, used: False
[2m[36m(pid=6733)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6733)[0m 
[2m[36m(pid=6733)[0m   | Name      | Type              | Params
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6733)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6733)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 12.0 K    Trainable params
[2m[36m(pid=6733)[0m 0         Non-trainable params
[2m[36m(pid=6733)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m time to fit was 90.22397756576538
[2m[36m(pid=9844)[0m GPU available: False, used: False
[2m[36m(pid=9844)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9844)[0m 
[2m[36m(pid=9844)[0m   | Name      | Type              | Params
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9844)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9844)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 12.0 K    Trainable params
[2m[36m(pid=9844)[0m 0         Non-trainable params
[2m[36m(pid=9844)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m time to fit was 289.0573606491089
[2m[36m(pid=29305)[0m GPU available: False, used: False
[2m[36m(pid=29305)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29305)[0m 
[2m[36m(pid=29305)[0m   | Name      | Type              | Params
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29305)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29305)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29305)[0m ------------------------------------------------
[2m[36m(pid=29305)[0m 12.0 K    Trainable params
[2m[36m(pid=29305)[0m 0         Non-trainable params
[2m[36m(pid=29305)[0m 12.0 K    Total params
[2m[36m(pid=11433)[0m time to fit was 120.35986351966858
Result for _inner_e98d6_00057:
  auc: 0.6973867774009704
  date: 2021-03-18_00-35-16
  done: false
  experiment_id: e678b72484e74a63876aed8255b7adab
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11433
  time_since_restore: 1494.860732793808
  time_this_iter_s: 1494.860732793808
  time_total_s: 1494.860732793808
  timestamp: 1616024116
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00057
  
[2m[36m(pid=11433)[0m Finished run with seed 0 - lr 5 - sec_lr 0.01 - bs 128 - mean val auc: 0.6973867774009704
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 70/180 (1 PENDING, 26 RUNNING, 43 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00069 | PENDING    |       |          512 |     0 | 0.01  |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 50 more trials not shown (16 RUNNING, 33 TERMINATED)


Result for _inner_e98d6_00057:
  auc: 0.6973867774009704
  date: 2021-03-18_00-35-16
  done: true
  experiment_id: e678b72484e74a63876aed8255b7adab
  experiment_tag: 57_batch_size=128,eta=0.0,lr=5,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11433
  time_since_restore: 1494.860732793808
  time_this_iter_s: 1494.860732793808
  time_total_s: 1494.860732793808
  timestamp: 1616024116
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00057
  
[2m[36m(pid=21627)[0m time to fit was 954.8422999382019
Result for _inner_e98d6_00035:
  auc: 0.9095814108848572
  date: 2021-03-18_00-35-23
  done: false
  experiment_id: 8b2174bb66bd4c348263378f0e77be9d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21627
  time_since_restore: 4054.4907035827637
  time_this_iter_s: 4054.4907035827637
  time_total_s: 4054.4907035827637
  timestamp: 1616024123
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00035
  
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 71/180 (1 PENDING, 26 RUNNING, 44 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    |       |           32 |     0 | 0.01  |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00070 | PENDING    |       |           32 |     0 | 0.1   |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 51 more trials not shown (16 RUNNING, 34 TERMINATED)


Result for _inner_e98d6_00035:
  auc: 0.9095814108848572
  date: 2021-03-18_00-35-23
  done: true
  experiment_id: 8b2174bb66bd4c348263378f0e77be9d
  experiment_tag: 35_batch_size=32,eta=0.0,lr=0.01,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21627
  time_since_restore: 4054.4907035827637
  time_this_iter_s: 4054.4907035827637
  time_total_s: 4054.4907035827637
  timestamp: 1616024123
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00035
  
[2m[36m(pid=21627)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.01 - bs 32 - mean val auc: 0.9095814108848572
[2m[36m(pid=14841)[0m Starting run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 512
[2m[36m(pid=14841)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=14841)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=14841)[0m GPU available: False, used: False
[2m[36m(pid=14841)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m 
[2m[36m(pid=14841)[0m   | Name      | Type              | Params
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14841)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14841)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 12.0 K    Trainable params
[2m[36m(pid=14841)[0m 0         Non-trainable params
[2m[36m(pid=14841)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14841)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14841)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14841)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14841)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=14841)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15100)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 32
[2m[36m(pid=15100)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15100)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=15100)[0m GPU available: False, used: False
[2m[36m(pid=15100)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15100)[0m 
[2m[36m(pid=15100)[0m   | Name      | Type              | Params
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15100)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15100)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 12.0 K    Trainable params
[2m[36m(pid=15100)[0m 0         Non-trainable params
[2m[36m(pid=15100)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15100)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15100)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15100)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15100)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=15100)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9844)[0m time to fit was 83.14144730567932
[2m[36m(pid=9844)[0m GPU available: False, used: False
[2m[36m(pid=9844)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9844)[0m 
[2m[36m(pid=9844)[0m   | Name      | Type              | Params
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9844)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9844)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 12.0 K    Trainable params
[2m[36m(pid=9844)[0m 0         Non-trainable params
[2m[36m(pid=9844)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m time to fit was 447.3593933582306
[2m[36m(pid=21625)[0m GPU available: False, used: False
[2m[36m(pid=21625)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21625)[0m 
[2m[36m(pid=21625)[0m   | Name      | Type              | Params
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21625)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21625)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21625)[0m ------------------------------------------------
[2m[36m(pid=21625)[0m 12.0 K    Trainable params
[2m[36m(pid=21625)[0m 0         Non-trainable params
[2m[36m(pid=21625)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m time to fit was 106.21353197097778
[2m[36m(pid=14841)[0m GPU available: False, used: False
[2m[36m(pid=14841)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m 
[2m[36m(pid=14841)[0m   | Name      | Type              | Params
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14841)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14841)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 12.0 K    Trainable params
[2m[36m(pid=14841)[0m 0         Non-trainable params
[2m[36m(pid=14841)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m time to fit was 693.9550495147705
[2m[36m(pid=21626)[0m GPU available: False, used: False
[2m[36m(pid=21626)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21626)[0m 
[2m[36m(pid=21626)[0m   | Name      | Type              | Params
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21626)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21626)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 12.0 K    Trainable params
[2m[36m(pid=21626)[0m 0         Non-trainable params
[2m[36m(pid=21626)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m time to fit was 245.0008602142334
[2m[36m(pid=6733)[0m GPU available: False, used: False
[2m[36m(pid=6733)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m time to fit was 80.94229316711426
[2m[36m(pid=6733)[0m 
[2m[36m(pid=6733)[0m   | Name      | Type              | Params
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6733)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6733)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 12.0 K    Trainable params
[2m[36m(pid=6733)[0m 0         Non-trainable params
[2m[36m(pid=6733)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m GPU available: False, used: False
[2m[36m(pid=14841)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m 
[2m[36m(pid=14841)[0m   | Name      | Type              | Params
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14841)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14841)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 12.0 K    Trainable params
[2m[36m(pid=14841)[0m 0         Non-trainable params
[2m[36m(pid=14841)[0m 12.0 K    Total params
[2m[36m(pid=21737)[0m time to fit was 880.5518486499786
Result for _inner_e98d6_00005:
  auc: 0.9122215032577514
  date: 2021-03-18_00-38-46
  done: false
  experiment_id: d66b7d6f218643ce9863387db4ab76a4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21737
  time_since_restore: 5578.912028312683
  time_this_iter_s: 5578.912028312683
  time_total_s: 5578.912028312683
  timestamp: 1616024326
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00005
  
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 72/180 (1 PENDING, 26 RUNNING, 45 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |                     |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00005 | RUNNING    | 145.101.32.82:21737 |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00071 | PENDING    |                     |           64 |     0 | 0.1   |    0.1   |        |                  |          |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 52 more trials not shown (16 RUNNING, 35 TERMINATED)


Result for _inner_e98d6_00005:
  auc: 0.9122215032577514
  date: 2021-03-18_00-38-46
  done: true
  experiment_id: d66b7d6f218643ce9863387db4ab76a4
  experiment_tag: 5_batch_size=32,eta=0.0,lr=0.01,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21737
  time_since_restore: 5578.912028312683
  time_this_iter_s: 5578.912028312683
  time_total_s: 5578.912028312683
  timestamp: 1616024326
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00005
  
[2m[36m(pid=21737)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.001 - bs 32 - mean val auc: 0.9122215032577514
[2m[36m(pid=22819)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 64
[2m[36m(pid=22819)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22819)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=22819)[0m GPU available: False, used: False
[2m[36m(pid=22819)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22819)[0m 
[2m[36m(pid=22819)[0m   | Name      | Type              | Params
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22819)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22819)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 12.0 K    Trainable params
[2m[36m(pid=22819)[0m 0         Non-trainable params
[2m[36m(pid=22819)[0m 12.0 K    Total params
[2m[36m(pid=22819)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22819)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22819)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22819)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22819)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=22819)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21720)[0m time to fit was 2523.85049533844
[2m[36m(pid=21720)[0m GPU available: False, used: False
[2m[36m(pid=21720)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21720)[0m 
[2m[36m(pid=21720)[0m   | Name      | Type              | Params
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21720)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21720)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 12.0 K    Trainable params
[2m[36m(pid=21720)[0m 0         Non-trainable params
[2m[36m(pid=21720)[0m 12.0 K    Total params
[2m[36m(pid=21628)[0m time to fit was 496.4271070957184
Result for _inner_e98d6_00045:
  auc: 0.9112599849700928
  date: 2021-03-18_00-40-04
  done: false
  experiment_id: 2146665ebf394d96acd3c409d420a5e0
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21628
  time_since_restore: 2676.458861351013
  time_this_iter_s: 2676.458861351013
  time_total_s: 2676.458861351013
  timestamp: 1616024404
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00045
  
[2m[36m(pid=21628)[0m Finished run with seed 0 - lr 1 - sec_lr 0.01 - bs 32 - mean val auc: 0.9112599849700928
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 73/180 (1 PENDING, 26 RUNNING, 46 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00072 | PENDING    |       |          128 |     0 | 0.1   |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 53 more trials not shown (16 RUNNING, 36 TERMINATED)


Result for _inner_e98d6_00045:
  auc: 0.9112599849700928
  date: 2021-03-18_00-40-04
  done: true
  experiment_id: 2146665ebf394d96acd3c409d420a5e0
  experiment_tag: 45_batch_size=32,eta=0.0,lr=1,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21628
  time_since_restore: 2676.458861351013
  time_this_iter_s: 2676.458861351013
  time_total_s: 2676.458861351013
  timestamp: 1616024404
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00045
  
[2m[36m(pid=25658)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 128
[2m[36m(pid=25658)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25658)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=25658)[0m GPU available: False, used: False
[2m[36m(pid=25658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25658)[0m 
[2m[36m(pid=25658)[0m   | Name      | Type              | Params
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 12.0 K    Trainable params
[2m[36m(pid=25658)[0m 0         Non-trainable params
[2m[36m(pid=25658)[0m 12.0 K    Total params
[2m[36m(pid=25658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25658)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=25658)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5628)[0m time to fit was 423.0754177570343
[2m[36m(pid=5628)[0m GPU available: False, used: False
[2m[36m(pid=5628)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5628)[0m 
[2m[36m(pid=5628)[0m   | Name      | Type              | Params
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5628)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5628)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5628)[0m ------------------------------------------------
[2m[36m(pid=5628)[0m 12.0 K    Trainable params
[2m[36m(pid=5628)[0m 0         Non-trainable params
[2m[36m(pid=5628)[0m 12.0 K    Total params
[2m[36m(pid=29305)[0m time to fit was 376.46940517425537
Result for _inner_e98d6_00062:
  auc: 0.8808209061622619
  date: 2021-03-18_00-41-25
  done: false
  experiment_id: d80e9447e1a848959b85fea479ef6f6a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 29305
  time_since_restore: 1407.2946860790253
  time_this_iter_s: 1407.2946860790253
  time_total_s: 1407.2946860790253
  timestamp: 1616024485
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00062
  
[2m[36m(pid=29305)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 128 - mean val auc: 0.8808209061622619
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 74/180 (1 PENDING, 26 RUNNING, 47 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00073 | PENDING    |       |          256 |     0 | 0.1   |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 54 more trials not shown (16 RUNNING, 37 TERMINATED)


Result for _inner_e98d6_00062:
  auc: 0.8808209061622619
  date: 2021-03-18_00-41-25
  done: true
  experiment_id: d80e9447e1a848959b85fea479ef6f6a
  experiment_tag: 62_batch_size=128,eta=0.0,lr=0.001,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 29305
  time_since_restore: 1407.2946860790253
  time_this_iter_s: 1407.2946860790253
  time_total_s: 1407.2946860790253
  timestamp: 1616024485
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00062
  
[2m[36m(pid=28710)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 256
[2m[36m(pid=28710)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28710)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=28710)[0m GPU available: False, used: False
[2m[36m(pid=28710)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28710)[0m 
[2m[36m(pid=28710)[0m   | Name      | Type              | Params
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28710)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28710)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 12.0 K    Trainable params
[2m[36m(pid=28710)[0m 0         Non-trainable params
[2m[36m(pid=28710)[0m 12.0 K    Total params
[2m[36m(pid=28710)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28710)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28710)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28710)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28710)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=28710)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45643)[0m time to fit was 569.0344839096069
[2m[36m(pid=45643)[0m GPU available: False, used: False
[2m[36m(pid=45643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45643)[0m 
[2m[36m(pid=45643)[0m   | Name      | Type              | Params
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 12.0 K    Trainable params
[2m[36m(pid=45643)[0m 0         Non-trainable params
[2m[36m(pid=45643)[0m 12.0 K    Total params
[2m[36m(pid=25658)[0m time to fit was 122.67014908790588
[2m[36m(pid=25658)[0m GPU available: False, used: False
[2m[36m(pid=25658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25658)[0m 
[2m[36m(pid=25658)[0m   | Name      | Type              | Params
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 12.0 K    Trainable params
[2m[36m(pid=25658)[0m 0         Non-trainable params
[2m[36m(pid=25658)[0m 12.0 K    Total params
[2m[36m(pid=9398)[0m time to fit was 1224.7410006523132
[2m[36m(pid=9398)[0m GPU available: False, used: False
[2m[36m(pid=9398)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9398)[0m 
[2m[36m(pid=9398)[0m   | Name      | Type              | Params
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9398)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9398)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 12.0 K    Trainable params
[2m[36m(pid=9398)[0m 0         Non-trainable params
[2m[36m(pid=9398)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m time to fit was 419.43352937698364
[2m[36m(pid=15100)[0m GPU available: False, used: False
[2m[36m(pid=15100)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15100)[0m 
[2m[36m(pid=15100)[0m   | Name      | Type              | Params
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15100)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15100)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 12.0 K    Trainable params
[2m[36m(pid=15100)[0m 0         Non-trainable params
[2m[36m(pid=15100)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m time to fit was 245.5511372089386
[2m[36m(pid=14841)[0m GPU available: False, used: False
[2m[36m(pid=14841)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m 
[2m[36m(pid=14841)[0m   | Name      | Type              | Params
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14841)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14841)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 12.0 K    Trainable params
[2m[36m(pid=14841)[0m 0         Non-trainable params
[2m[36m(pid=14841)[0m 12.0 K    Total params
[2m[36m(pid=28710)[0m time to fit was 85.33216524124146
[2m[36m(pid=28710)[0m GPU available: False, used: False
[2m[36m(pid=28710)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28710)[0m 
[2m[36m(pid=28710)[0m   | Name      | Type              | Params
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28710)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28710)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 12.0 K    Trainable params
[2m[36m(pid=28710)[0m 0         Non-trainable params
[2m[36m(pid=28710)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m time to fit was 419.5866539478302
[2m[36m(pid=9844)[0m GPU available: False, used: False
[2m[36m(pid=9844)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9844)[0m 
[2m[36m(pid=9844)[0m   | Name      | Type              | Params
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9844)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9844)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 12.0 K    Trainable params
[2m[36m(pid=9844)[0m 0         Non-trainable params
[2m[36m(pid=9844)[0m 12.0 K    Total params
[2m[36m(pid=21625)[0m time to fit was 374.7523808479309
Result for _inner_e98d6_00051:
  auc: 0.9100551605224609
  date: 2021-03-18_00-43-20
  done: false
  experiment_id: ed51bbe0477a4174aed29153bf7ac6c8
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21625
  time_since_restore: 2330.103545665741
  time_this_iter_s: 2330.103545665741
  time_total_s: 2330.103545665741
  timestamp: 1616024600
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00051
  
[2m[36m(pid=21625)[0m Finished run with seed 0 - lr 2 - sec_lr 0.01 - bs 64 - mean val auc: 0.9100551605224609
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 75/180 (1 PENDING, 26 RUNNING, 48 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00074 | PENDING    |       |          512 |     0 | 0.1   |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 55 more trials not shown (16 RUNNING, 38 TERMINATED)


Result for _inner_e98d6_00051:
  auc: 0.9100551605224609
  date: 2021-03-18_00-43-20
  done: true
  experiment_id: ed51bbe0477a4174aed29153bf7ac6c8
  experiment_tag: 51_batch_size=64,eta=0.0,lr=2,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21625
  time_since_restore: 2330.103545665741
  time_this_iter_s: 2330.103545665741
  time_total_s: 2330.103545665741
  timestamp: 1616024600
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00051
  
[2m[36m(pid=26509)[0m time to fit was 540.8823592662811
[2m[36m(pid=26509)[0m GPU available: False, used: False
[2m[36m(pid=26509)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26509)[0m 
[2m[36m(pid=26509)[0m   | Name      | Type              | Params
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26509)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26509)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 12.0 K    Trainable params
[2m[36m(pid=26509)[0m 0         Non-trainable params
[2m[36m(pid=26509)[0m 12.0 K    Total params
[2m[36m(pid=33194)[0m Starting run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 512
[2m[36m(pid=33194)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33194)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=33194)[0m GPU available: False, used: False
[2m[36m(pid=33194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33194)[0m 
[2m[36m(pid=33194)[0m   | Name      | Type              | Params
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 12.0 K    Trainable params
[2m[36m(pid=33194)[0m 0         Non-trainable params
[2m[36m(pid=33194)[0m 12.0 K    Total params
[2m[36m(pid=33194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=33194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=33194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=33194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22819)[0m time to fit was 281.03985261917114
[2m[36m(pid=22819)[0m GPU available: False, used: False
[2m[36m(pid=22819)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22819)[0m 
[2m[36m(pid=22819)[0m   | Name      | Type              | Params
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22819)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22819)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 12.0 K    Trainable params
[2m[36m(pid=22819)[0m 0         Non-trainable params
[2m[36m(pid=22819)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m time to fit was 316.4640874862671
[2m[36m(pid=6733)[0m GPU available: False, used: False
[2m[36m(pid=6733)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6733)[0m 
[2m[36m(pid=6733)[0m   | Name      | Type              | Params
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6733)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6733)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 12.0 K    Trainable params
[2m[36m(pid=6733)[0m 0         Non-trainable params
[2m[36m(pid=6733)[0m 12.0 K    Total params
[2m[36m(pid=25658)[0m time to fit was 122.50765657424927
[2m[36m(pid=25658)[0m GPU available: False, used: False
[2m[36m(pid=25658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25658)[0m 
[2m[36m(pid=25658)[0m   | Name      | Type              | Params
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 12.0 K    Trainable params
[2m[36m(pid=25658)[0m 0         Non-trainable params
[2m[36m(pid=25658)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m time to fit was 107.47578620910645
[2m[36m(pid=14841)[0m GPU available: False, used: False
[2m[36m(pid=14841)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14841)[0m 
[2m[36m(pid=14841)[0m   | Name      | Type              | Params
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14841)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14841)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14841)[0m ------------------------------------------------
[2m[36m(pid=14841)[0m 12.0 K    Trainable params
[2m[36m(pid=14841)[0m 0         Non-trainable params
[2m[36m(pid=14841)[0m 12.0 K    Total params
[2m[36m(pid=28710)[0m time to fit was 90.966872215271
[2m[36m(pid=28710)[0m GPU available: False, used: False
[2m[36m(pid=28710)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28710)[0m 
[2m[36m(pid=28710)[0m   | Name      | Type              | Params
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28710)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28710)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 12.0 K    Trainable params
[2m[36m(pid=28710)[0m 0         Non-trainable params
[2m[36m(pid=28710)[0m 12.0 K    Total params
[2m[36m(pid=33194)[0m time to fit was 65.31545519828796
[2m[36m(pid=33194)[0m GPU available: False, used: False
[2m[36m(pid=33194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33194)[0m 
[2m[36m(pid=33194)[0m   | Name      | Type              | Params
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 12.0 K    Trainable params
[2m[36m(pid=33194)[0m 0         Non-trainable params
[2m[36m(pid=33194)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m time to fit was 778.7957651615143
[2m[36m(pid=43203)[0m GPU available: False, used: False
[2m[36m(pid=43203)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43203)[0m 
[2m[36m(pid=43203)[0m   | Name      | Type              | Params
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43203)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43203)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 12.0 K    Trainable params
[2m[36m(pid=43203)[0m 0         Non-trainable params
[2m[36m(pid=43203)[0m 12.0 K    Total params
[2m[36m(pid=14841)[0m time to fit was 73.26538372039795
Result for _inner_e98d6_00069:
  auc: 0.9071925044059753
  date: 2021-03-18_00-45-42
  done: false
  experiment_id: ade4797e36f149ff8c320be825688bc0
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14841
  time_since_restore: 614.6740500926971
  time_this_iter_s: 614.6740500926971
  time_total_s: 614.6740500926971
  timestamp: 1616024742
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00069
  
[2m[36m(pid=14841)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 512 - mean val auc: 0.9071925044059753
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 76/180 (1 PENDING, 26 RUNNING, 49 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00075 | PENDING    |       |           32 |     0 | 1     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 56 more trials not shown (16 RUNNING, 39 TERMINATED)


Result for _inner_e98d6_00069:
  auc: 0.9071925044059753
  date: 2021-03-18_00-45-42
  done: true
  experiment_id: ade4797e36f149ff8c320be825688bc0
  experiment_tag: 69_batch_size=512,eta=0.0,lr=0.01,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14841
  time_since_restore: 614.6740500926971
  time_this_iter_s: 614.6740500926971
  time_total_s: 614.6740500926971
  timestamp: 1616024742
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00069
  
[2m[36m(pid=33194)[0m time to fit was 65.49312043190002
[2m[36m(pid=33194)[0m GPU available: False, used: False
[2m[36m(pid=33194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33194)[0m 
[2m[36m(pid=33194)[0m   | Name      | Type              | Params
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 12.0 K    Trainable params
[2m[36m(pid=33194)[0m 0         Non-trainable params
[2m[36m(pid=33194)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m time to fit was 155.5986728668213
[2m[36m(pid=9844)[0m GPU available: False, used: False
[2m[36m(pid=9844)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9844)[0m 
[2m[36m(pid=9844)[0m   | Name      | Type              | Params
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9844)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9844)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9844)[0m ------------------------------------------------
[2m[36m(pid=9844)[0m 12.0 K    Trainable params
[2m[36m(pid=9844)[0m 0         Non-trainable params
[2m[36m(pid=9844)[0m 12.0 K    Total params
2021-03-18 00:45:44,739	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff213a300401000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=28710)[0m time to fit was 78.03052139282227
[2m[36m(pid=28710)[0m GPU available: False, used: False
[2m[36m(pid=28710)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28710)[0m 
[2m[36m(pid=28710)[0m   | Name      | Type              | Params
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28710)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28710)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 12.0 K    Trainable params
[2m[36m(pid=28710)[0m 0         Non-trainable params
[2m[36m(pid=28710)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m Starting run with seed 0 - lr 1 - sec_lr 0.1 - bs 32
[2m[36m(pid=38965)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=38965)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=38965)[0m GPU available: False, used: False
[2m[36m(pid=38965)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=38965)[0m 
[2m[36m(pid=38965)[0m   | Name      | Type              | Params
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=38965)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=38965)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 12.0 K    Trainable params
[2m[36m(pid=38965)[0m 0         Non-trainable params
[2m[36m(pid=38965)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=38965)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=38965)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=38965)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=38965)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=38965)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45643)[0m time to fit was 228.0681540966034
[2m[36m(pid=45643)[0m GPU available: False, used: False
[2m[36m(pid=45643)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45643)[0m 
[2m[36m(pid=45643)[0m   | Name      | Type              | Params
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45643)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45643)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45643)[0m ------------------------------------------------
[2m[36m(pid=45643)[0m 12.0 K    Trainable params
[2m[36m(pid=45643)[0m 0         Non-trainable params
[2m[36m(pid=45643)[0m 12.0 K    Total params
[2m[36m(pid=33194)[0m time to fit was 63.75915503501892
[2m[36m(pid=33194)[0m GPU available: False, used: False
[2m[36m(pid=33194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33194)[0m 
[2m[36m(pid=33194)[0m   | Name      | Type              | Params
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 12.0 K    Trainable params
[2m[36m(pid=33194)[0m 0         Non-trainable params
[2m[36m(pid=33194)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m time to fit was 545.4645438194275
[2m[36m(pid=21626)[0m GPU available: False, used: False
[2m[36m(pid=21626)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21626)[0m 
[2m[36m(pid=21626)[0m   | Name      | Type              | Params
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21626)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21626)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21626)[0m ------------------------------------------------
[2m[36m(pid=21626)[0m 12.0 K    Trainable params
[2m[36m(pid=21626)[0m 0         Non-trainable params
[2m[36m(pid=21626)[0m 12.0 K    Total params
[2m[36m(pid=25658)[0m time to fit was 168.76749539375305
[2m[36m(pid=25658)[0m GPU available: False, used: False
[2m[36m(pid=25658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25658)[0m 
[2m[36m(pid=25658)[0m   | Name      | Type              | Params
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 12.0 K    Trainable params
[2m[36m(pid=25658)[0m 0         Non-trainable params
[2m[36m(pid=25658)[0m 12.0 K    Total params
[2m[36m(pid=28710)[0m time to fit was 77.83870959281921
[2m[36m(pid=28710)[0m GPU available: False, used: False
[2m[36m(pid=28710)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28710)[0m 
[2m[36m(pid=28710)[0m   | Name      | Type              | Params
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28710)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28710)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28710)[0m ------------------------------------------------
[2m[36m(pid=28710)[0m 12.0 K    Trainable params
[2m[36m(pid=28710)[0m 0         Non-trainable params
[2m[36m(pid=28710)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m time to fit was 203.08500623703003
[2m[36m(pid=6733)[0m GPU available: False, used: False
[2m[36m(pid=6733)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6733)[0m 
[2m[36m(pid=6733)[0m   | Name      | Type              | Params
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6733)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6733)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6733)[0m ------------------------------------------------
[2m[36m(pid=6733)[0m 12.0 K    Trainable params
[2m[36m(pid=6733)[0m 0         Non-trainable params
[2m[36m(pid=6733)[0m 12.0 K    Total params
[2m[36m(pid=22819)[0m time to fit was 224.89461421966553
[2m[36m(pid=22819)[0m GPU available: False, used: False
[2m[36m(pid=22819)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22819)[0m 
[2m[36m(pid=22819)[0m   | Name      | Type              | Params
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22819)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22819)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 12.0 K    Trainable params
[2m[36m(pid=22819)[0m 0         Non-trainable params
[2m[36m(pid=22819)[0m 12.0 K    Total params
[2m[36m(pid=33194)[0m time to fit was 71.74119448661804
[2m[36m(pid=33194)[0m GPU available: False, used: False
[2m[36m(pid=33194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33194)[0m 
[2m[36m(pid=33194)[0m   | Name      | Type              | Params
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33194)[0m ------------------------------------------------
[2m[36m(pid=33194)[0m 12.0 K    Trainable params
[2m[36m(pid=33194)[0m 0         Non-trainable params
[2m[36m(pid=33194)[0m 12.0 K    Total params
[2m[36m(pid=5628)[0m time to fit was 433.05630230903625
Result for _inner_e98d6_00055:
  auc: 0.5375086307525635
  date: 2021-03-18_00-48-01
  done: false
  experiment_id: adc82244701a4953a459d4f877aa2fa2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5628
  time_since_restore: 2407.040449142456
  time_this_iter_s: 2407.040449142456
  time_total_s: 2407.040449142456
  timestamp: 1616024881
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00055
  
[2m[36m(pid=5628)[0m Finished run with seed 0 - lr 5 - sec_lr 0.01 - bs 32 - mean val auc: 0.5375086307525635
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 77/180 (1 PENDING, 26 RUNNING, 50 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00076 | PENDING    |       |           64 |     0 | 1     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 57 more trials not shown (16 RUNNING, 40 TERMINATED)


Result for _inner_e98d6_00055:
  auc: 0.5375086307525635
  date: 2021-03-18_00-48-01
  done: true
  experiment_id: adc82244701a4953a459d4f877aa2fa2
  experiment_tag: 55_batch_size=32,eta=0.0,lr=5,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5628
  time_since_restore: 2407.040449142456
  time_this_iter_s: 2407.040449142456
  time_total_s: 2407.040449142456
  timestamp: 1616024881
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00055
  
[2m[36m(pid=44324)[0m Starting run with seed 0 - lr 1 - sec_lr 0.1 - bs 64
[2m[36m(pid=44324)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44324)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=44324)[0m GPU available: False, used: False
[2m[36m(pid=44324)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44324)[0m 
[2m[36m(pid=44324)[0m   | Name      | Type              | Params
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44324)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44324)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 12.0 K    Trainable params
[2m[36m(pid=44324)[0m 0         Non-trainable params
[2m[36m(pid=44324)[0m 12.0 K    Total params
[2m[36m(pid=44324)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=44324)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44324)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=44324)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44324)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=44324)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28710)[0m time to fit was 77.64205384254456
[2m[36m(pid=28710)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 256 - mean val auc: 0.9115670442581176
Result for _inner_e98d6_00073:
  auc: 0.9115670442581176
  date: 2021-03-18_00-48-29
  done: false
  experiment_id: 65642fb5c1294c4985b9cdcff1e08e85
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28710
  time_since_restore: 411.11668038368225
  time_this_iter_s: 411.11668038368225
  time_total_s: 411.11668038368225
  timestamp: 1616024909
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00073
  
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 78/180 (1 PENDING, 26 RUNNING, 51 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00077 | PENDING    |       |          128 |     0 | 1     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 58 more trials not shown (16 RUNNING, 41 TERMINATED)


Result for _inner_e98d6_00073:
  auc: 0.9115670442581176
  date: 2021-03-18_00-48-29
  done: true
  experiment_id: 65642fb5c1294c4985b9cdcff1e08e85
  experiment_tag: 73_batch_size=256,eta=0.0,lr=0.1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28710
  time_since_restore: 411.11668038368225
  time_this_iter_s: 411.11668038368225
  time_total_s: 411.11668038368225
  timestamp: 1616024909
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00073
  
[2m[36m(pid=45437)[0m Starting run with seed 0 - lr 1 - sec_lr 0.1 - bs 128
[2m[36m(pid=45437)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=45437)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=45437)[0m GPU available: False, used: False
[2m[36m(pid=45437)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45437)[0m 
[2m[36m(pid=45437)[0m   | Name      | Type              | Params
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45437)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45437)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 12.0 K    Trainable params
[2m[36m(pid=45437)[0m 0         Non-trainable params
[2m[36m(pid=45437)[0m 12.0 K    Total params
[2m[36m(pid=45437)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=45437)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45437)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=45437)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45437)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=45437)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33194)[0m time to fit was 74.25162172317505
Result for _inner_e98d6_00074:
  auc: 0.9116923809051514
  date: 2021-03-18_00-49-13
  done: false
  experiment_id: b0c43e255a574fa1bdb1cc00de460be7
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 33194
  time_since_restore: 341.78108620643616
  time_this_iter_s: 341.78108620643616
  time_total_s: 341.78108620643616
  timestamp: 1616024953
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00074
  
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 79/180 (1 PENDING, 26 RUNNING, 52 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00078 | PENDING    |       |          256 |     0 | 1     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 59 more trials not shown (16 RUNNING, 42 TERMINATED)

[2m[36m(pid=33194)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 512 - mean val auc: 0.9116923809051514

Result for _inner_e98d6_00074:
  auc: 0.9116923809051514
  date: 2021-03-18_00-49-13
  done: true
  experiment_id: b0c43e255a574fa1bdb1cc00de460be7
  experiment_tag: 74_batch_size=512,eta=0.0,lr=0.1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 33194
  time_since_restore: 341.78108620643616
  time_this_iter_s: 341.78108620643616
  time_total_s: 341.78108620643616
  timestamp: 1616024953
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00074
  
[2m[36m(pid=25658)[0m time to fit was 123.50040340423584
[2m[36m(pid=25658)[0m GPU available: False, used: False
[2m[36m(pid=25658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25658)[0m 
[2m[36m(pid=25658)[0m   | Name      | Type              | Params
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25658)[0m ------------------------------------------------
[2m[36m(pid=25658)[0m 12.0 K    Trainable params
[2m[36m(pid=25658)[0m 0         Non-trainable params
[2m[36m(pid=25658)[0m 12.0 K    Total params
2021-03-18 00:49:15,358	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff08b99a2a01000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=47239)[0m Starting run with seed 0 - lr 1 - sec_lr 0.1 - bs 256
[2m[36m(pid=47239)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47239)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=47239)[0m GPU available: False, used: False
[2m[36m(pid=47239)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=47239)[0m 
[2m[36m(pid=47239)[0m   | Name      | Type              | Params
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=47239)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=47239)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 12.0 K    Trainable params
[2m[36m(pid=47239)[0m 0         Non-trainable params
[2m[36m(pid=47239)[0m 12.0 K    Total params
[2m[36m(pid=47239)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=47239)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=47239)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=47239)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=47239)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=47239)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=47239)[0m time to fit was 84.69489908218384
[2m[36m(pid=47239)[0m GPU available: False, used: False
[2m[36m(pid=47239)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=47239)[0m 
[2m[36m(pid=47239)[0m   | Name      | Type              | Params
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=47239)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=47239)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 12.0 K    Trainable params
[2m[36m(pid=47239)[0m 0         Non-trainable params
[2m[36m(pid=47239)[0m 12.0 K    Total params
[2m[36m(pid=45437)[0m time to fit was 133.63040733337402
[2m[36m(pid=45437)[0m GPU available: False, used: False
[2m[36m(pid=45437)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45437)[0m 
[2m[36m(pid=45437)[0m   | Name      | Type              | Params
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45437)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45437)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 12.0 K    Trainable params
[2m[36m(pid=45437)[0m 0         Non-trainable params
[2m[36m(pid=45437)[0m 12.0 K    Total params
[2m[36m(pid=9844)[0m time to fit was 317.9835865497589
Result for _inner_e98d6_00068:
  auc: 0.9064191579818726
  date: 2021-03-18_00-51-02
  done: false
  experiment_id: 1f3177c45d524cd9a61ad656edf8bcfd
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9844
  time_since_restore: 1067.882873058319
  time_this_iter_s: 1067.882873058319
  time_total_s: 1067.882873058319
  timestamp: 1616025062
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00068
  
[2m[36m(pid=9844)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 256 - mean val auc: 0.9064191579818726
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 80/180 (1 PENDING, 26 RUNNING, 53 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00079 | PENDING    |       |          512 |     0 | 1     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 60 more trials not shown (16 RUNNING, 43 TERMINATED)


Result for _inner_e98d6_00068:
  auc: 0.9064191579818726
  date: 2021-03-18_00-51-02
  done: true
  experiment_id: 1f3177c45d524cd9a61ad656edf8bcfd
  experiment_tag: 68_batch_size=256,eta=0.0,lr=0.01,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9844
  time_since_restore: 1067.882873058319
  time_this_iter_s: 1067.882873058319
  time_total_s: 1067.882873058319
  timestamp: 1616025062
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00068
  
[2m[36m(pid=22819)[0m time to fit was 223.50971341133118
[2m[36m(pid=22819)[0m GPU available: False, used: False
[2m[36m(pid=22819)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22819)[0m 
[2m[36m(pid=22819)[0m   | Name      | Type              | Params
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22819)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22819)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 12.0 K    Trainable params
[2m[36m(pid=22819)[0m 0         Non-trainable params
[2m[36m(pid=22819)[0m 12.0 K    Total params
[2m[36m(pid=51272)[0m Starting run with seed 0 - lr 1 - sec_lr 0.1 - bs 512
[2m[36m(pid=51272)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51272)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=51272)[0m GPU available: False, used: False
[2m[36m(pid=51272)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51272)[0m 
[2m[36m(pid=51272)[0m   | Name      | Type              | Params
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51272)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51272)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 12.0 K    Trainable params
[2m[36m(pid=51272)[0m 0         Non-trainable params
[2m[36m(pid=51272)[0m 12.0 K    Total params
[2m[36m(pid=51272)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=51272)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51272)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=51272)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51272)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=51272)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25658)[0m time to fit was 131.9090027809143
Result for _inner_e98d6_00072:
  auc: 0.9091430544853211
  date: 2021-03-18_00-51-26
  done: false
  experiment_id: 74ca351f77a24cbe977fb7c3599a8114
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25658
  time_since_restore: 670.6690604686737
  time_this_iter_s: 670.6690604686737
  time_total_s: 670.6690604686737
  timestamp: 1616025086
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00072
  
[2m[36m(pid=25658)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 128 - mean val auc: 0.9091430544853211
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 81/180 (1 PENDING, 26 RUNNING, 54 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00080 | PENDING    |       |           32 |     0 | 2     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 61 more trials not shown (16 RUNNING, 44 TERMINATED)


Result for _inner_e98d6_00072:
  auc: 0.9091430544853211
  date: 2021-03-18_00-51-26
  done: true
  experiment_id: 74ca351f77a24cbe977fb7c3599a8114
  experiment_tag: 72_batch_size=128,eta=0.0,lr=0.1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25658
  time_since_restore: 670.6690604686737
  time_this_iter_s: 670.6690604686737
  time_total_s: 670.6690604686737
  timestamp: 1616025086
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00072
  
[2m[36m(pid=52147)[0m Starting run with seed 0 - lr 2 - sec_lr 0.1 - bs 32
[2m[36m(pid=52147)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52147)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=52147)[0m GPU available: False, used: False
[2m[36m(pid=52147)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m 
[2m[36m(pid=52147)[0m   | Name      | Type              | Params
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52147)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52147)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 12.0 K    Trainable params
[2m[36m(pid=52147)[0m 0         Non-trainable params
[2m[36m(pid=52147)[0m 12.0 K    Total params
[2m[36m(pid=52147)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=52147)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=52147)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=52147)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=52147)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=52147)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21731)[0m time to fit was 2320.5349690914154
[2m[36m(pid=21731)[0m GPU available: False, used: False
[2m[36m(pid=21731)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21731)[0m 
[2m[36m(pid=21731)[0m   | Name      | Type              | Params
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21731)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21731)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 12.0 K    Trainable params
[2m[36m(pid=21731)[0m 0         Non-trainable params
[2m[36m(pid=21731)[0m 12.0 K    Total params
[2m[36m(pid=6733)[0m time to fit was 294.4104731082916
Result for _inner_e98d6_00067:
  auc: 0.9098693609237671
  date: 2021-03-18_00-52-09
  done: false
  experiment_id: e1a7f6690b6d4c04a30d5766f47affd7
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6733
  time_since_restore: 1223.708328485489
  time_this_iter_s: 1223.708328485489
  time_total_s: 1223.708328485489
  timestamp: 1616025129
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00067
  
[2m[36m(pid=6733)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 128 - mean val auc: 0.9098693609237671
[2m[36m(pid=47239)[0m time to fit was 79.05307030677795
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 82/180 (1 PENDING, 26 RUNNING, 55 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00081 | PENDING    |       |           64 |     0 | 2     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 62 more trials not shown (16 RUNNING, 45 TERMINATED)


Result for _inner_e98d6_00067:
  auc: 0.9098693609237671
  date: 2021-03-18_00-52-09
  done: true
  experiment_id: e1a7f6690b6d4c04a30d5766f47affd7
  experiment_tag: 67_batch_size=128,eta=0.0,lr=0.01,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6733
  time_since_restore: 1223.708328485489
  time_this_iter_s: 1223.708328485489
  time_total_s: 1223.708328485489
  timestamp: 1616025129
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00067
  
[2m[36m(pid=47239)[0m GPU available: False, used: False
[2m[36m(pid=47239)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=47239)[0m 
[2m[36m(pid=47239)[0m   | Name      | Type              | Params
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=47239)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=47239)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 12.0 K    Trainable params
[2m[36m(pid=47239)[0m 0         Non-trainable params
[2m[36m(pid=47239)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m time to fit was 581.1025960445404
[2m[36m(pid=15100)[0m GPU available: False, used: False
[2m[36m(pid=15100)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15100)[0m 
[2m[36m(pid=15100)[0m   | Name      | Type              | Params
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15100)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15100)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 12.0 K    Trainable params
[2m[36m(pid=15100)[0m 0         Non-trainable params
[2m[36m(pid=15100)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m Starting run with seed 0 - lr 2 - sec_lr 0.1 - bs 64
[2m[36m(pid=884)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=884)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=884)[0m GPU available: False, used: False
[2m[36m(pid=884)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=884)[0m 
[2m[36m(pid=884)[0m   | Name      | Type              | Params
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=884)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=884)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 12.0 K    Trainable params
[2m[36m(pid=884)[0m 0         Non-trainable params
[2m[36m(pid=884)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=884)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=884)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=884)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51272)[0m time to fit was 68.9369797706604
[2m[36m(pid=884)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=884)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51272)[0m GPU available: False, used: False
[2m[36m(pid=51272)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51272)[0m 
[2m[36m(pid=51272)[0m   | Name      | Type              | Params
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51272)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51272)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 12.0 K    Trainable params
[2m[36m(pid=51272)[0m 0         Non-trainable params
[2m[36m(pid=51272)[0m 12.0 K    Total params
[2m[36m(pid=26509)[0m time to fit was 542.7775061130524
[2m[36m(pid=26509)[0m GPU available: False, used: False
[2m[36m(pid=26509)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26509)[0m 
[2m[36m(pid=26509)[0m   | Name      | Type              | Params
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26509)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26509)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26509)[0m ------------------------------------------------
[2m[36m(pid=26509)[0m 12.0 K    Trainable params
[2m[36m(pid=26509)[0m 0         Non-trainable params
[2m[36m(pid=26509)[0m 12.0 K    Total params
[2m[36m(pid=45643)[0m time to fit was 408.24561166763306
Result for _inner_e98d6_00066:
  auc: 0.9052132487297058
  date: 2021-03-18_00-52-54
  done: false
  experiment_id: a639367ca04c43bdb8e970e7f9fed49f
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 45643
  time_since_restore: 1650.2617466449738
  time_this_iter_s: 1650.2617466449738
  time_total_s: 1650.2617466449738
  timestamp: 1616025174
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00066
  
[2m[36m(pid=45643)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 64 - mean val auc: 0.9052132487297058
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 83/180 (1 PENDING, 26 RUNNING, 56 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00082 | PENDING    |       |          128 |     0 | 2     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 63 more trials not shown (16 RUNNING, 46 TERMINATED)


Result for _inner_e98d6_00066:
  auc: 0.9052132487297058
  date: 2021-03-18_00-52-54
  done: true
  experiment_id: a639367ca04c43bdb8e970e7f9fed49f
  experiment_tag: 66_batch_size=64,eta=0.0,lr=0.01,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 45643
  time_since_restore: 1650.2617466449738
  time_this_iter_s: 1650.2617466449738
  time_total_s: 1650.2617466449738
  timestamp: 1616025174
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00066
  
2021-03-18 00:52:56,066	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff35fe796501000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=38965)[0m time to fit was 422.6768310070038
[2m[36m(pid=38965)[0m GPU available: False, used: False
[2m[36m(pid=38965)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=38965)[0m 
[2m[36m(pid=38965)[0m   | Name      | Type              | Params
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=38965)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=38965)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 12.0 K    Trainable params
[2m[36m(pid=38965)[0m 0         Non-trainable params
[2m[36m(pid=38965)[0m 12.0 K    Total params
[2m[36m(pid=44324)[0m time to fit was 285.02810621261597
[2m[36m(pid=44324)[0m GPU available: False, used: False
[2m[36m(pid=44324)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44324)[0m 
[2m[36m(pid=44324)[0m   | Name      | Type              | Params
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44324)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44324)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 12.0 K    Trainable params
[2m[36m(pid=44324)[0m 0         Non-trainable params
[2m[36m(pid=44324)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m Starting run with seed 0 - lr 2 - sec_lr 0.1 - bs 128
[2m[36m(pid=2680)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2680)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=2680)[0m GPU available: False, used: False
[2m[36m(pid=2680)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=2680)[0m 
[2m[36m(pid=2680)[0m   | Name      | Type              | Params
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=2680)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=2680)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 12.0 K    Trainable params
[2m[36m(pid=2680)[0m 0         Non-trainable params
[2m[36m(pid=2680)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=2680)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=2680)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=2680)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=2680)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=2680)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51272)[0m time to fit was 62.10955882072449
[2m[36m(pid=51272)[0m GPU available: False, used: False
[2m[36m(pid=51272)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51272)[0m 
[2m[36m(pid=51272)[0m   | Name      | Type              | Params
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51272)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51272)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 12.0 K    Trainable params
[2m[36m(pid=51272)[0m 0         Non-trainable params
[2m[36m(pid=51272)[0m 12.0 K    Total params
[2m[36m(pid=47239)[0m time to fit was 77.55629658699036
[2m[36m(pid=47239)[0m GPU available: False, used: False
[2m[36m(pid=47239)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=47239)[0m 
[2m[36m(pid=47239)[0m   | Name      | Type              | Params
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=47239)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=47239)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 12.0 K    Trainable params
[2m[36m(pid=47239)[0m 0         Non-trainable params
[2m[36m(pid=47239)[0m 12.0 K    Total params
[2m[36m(pid=45437)[0m time to fit was 211.87571573257446
[2m[36m(pid=45437)[0m GPU available: False, used: False
[2m[36m(pid=45437)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45437)[0m 
[2m[36m(pid=45437)[0m   | Name      | Type              | Params
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45437)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45437)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 12.0 K    Trainable params
[2m[36m(pid=45437)[0m 0         Non-trainable params
[2m[36m(pid=45437)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m time to fit was 550.1592457294464
[2m[36m(pid=43203)[0m GPU available: False, used: False
[2m[36m(pid=43203)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43203)[0m 
[2m[36m(pid=43203)[0m   | Name      | Type              | Params
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43203)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43203)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 12.0 K    Trainable params
[2m[36m(pid=43203)[0m 0         Non-trainable params
[2m[36m(pid=43203)[0m 12.0 K    Total params
[2m[36m(pid=51272)[0m time to fit was 77.97229957580566
[2m[36m(pid=51272)[0m GPU available: False, used: False
[2m[36m(pid=51272)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51272)[0m 
[2m[36m(pid=51272)[0m   | Name      | Type              | Params
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51272)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51272)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 12.0 K    Trainable params
[2m[36m(pid=51272)[0m 0         Non-trainable params
[2m[36m(pid=51272)[0m 12.0 K    Total params
[2m[36m(pid=47239)[0m time to fit was 78.16433548927307
[2m[36m(pid=47239)[0m GPU available: False, used: False
[2m[36m(pid=47239)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=47239)[0m 
[2m[36m(pid=47239)[0m   | Name      | Type              | Params
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=47239)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=47239)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=47239)[0m ------------------------------------------------
[2m[36m(pid=47239)[0m 12.0 K    Trainable params
[2m[36m(pid=47239)[0m 0         Non-trainable params
[2m[36m(pid=47239)[0m 12.0 K    Total params
[2m[36m(pid=22819)[0m time to fit was 223.38022446632385
[2m[36m(pid=22819)[0m GPU available: False, used: False
[2m[36m(pid=22819)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22819)[0m 
[2m[36m(pid=22819)[0m   | Name      | Type              | Params
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22819)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22819)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22819)[0m ------------------------------------------------
[2m[36m(pid=22819)[0m 12.0 K    Trainable params
[2m[36m(pid=22819)[0m 0         Non-trainable params
[2m[36m(pid=22819)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m time to fit was 143.8751392364502
[2m[36m(pid=2680)[0m GPU available: False, used: False
[2m[36m(pid=2680)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=2680)[0m 
[2m[36m(pid=2680)[0m   | Name      | Type              | Params
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=2680)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=2680)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 12.0 K    Trainable params
[2m[36m(pid=2680)[0m 0         Non-trainable params
[2m[36m(pid=2680)[0m 12.0 K    Total params
[2m[36m(pid=51272)[0m time to fit was 67.81288170814514
[2m[36m(pid=51272)[0m GPU available: False, used: False
[2m[36m(pid=51272)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51272)[0m 
[2m[36m(pid=51272)[0m   | Name      | Type              | Params
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51272)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51272)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51272)[0m ------------------------------------------------
[2m[36m(pid=51272)[0m 12.0 K    Trainable params
[2m[36m(pid=51272)[0m 0         Non-trainable params
[2m[36m(pid=51272)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m time to fit was 220.165221452713
[2m[36m(pid=884)[0m GPU available: False, used: False
[2m[36m(pid=884)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=884)[0m 
[2m[36m(pid=884)[0m   | Name      | Type              | Params
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=884)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=884)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 12.0 K    Trainable params
[2m[36m(pid=884)[0m 0         Non-trainable params
[2m[36m(pid=884)[0m 12.0 K    Total params
[2m[36m(pid=21626)[0m time to fit was 543.0922574996948
Result for _inner_e98d6_00050:
  auc: 0.8269483923912049
  date: 2021-03-18_00-56-04
  done: false
  experiment_id: fb1029afeecc43bd81a497641d2a70d2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21626
  time_since_restore: 3211.187848806381
  time_this_iter_s: 3211.187848806381
  time_total_s: 3211.187848806381
  timestamp: 1616025364
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00050
  
[2m[36m(pid=21626)[0m Finished run with seed 0 - lr 2 - sec_lr 0.01 - bs 32 - mean val auc: 0.8269483923912049
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 84/180 (1 PENDING, 26 RUNNING, 57 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00083 | PENDING    |       |          256 |     0 | 2     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 64 more trials not shown (16 RUNNING, 47 TERMINATED)


Result for _inner_e98d6_00050:
  auc: 0.8269483923912049
  date: 2021-03-18_00-56-04
  done: true
  experiment_id: fb1029afeecc43bd81a497641d2a70d2
  experiment_tag: 50_batch_size=32,eta=0.0,lr=2,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21626
  time_since_restore: 3211.187848806381
  time_this_iter_s: 3211.187848806381
  time_total_s: 3211.187848806381
  timestamp: 1616025364
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00050
  
[2m[36m(pid=47239)[0m time to fit was 79.21661376953125
Result for _inner_e98d6_00078:
  auc: 0.9109599947929382
  date: 2021-03-18_00-56-05
  done: false
  experiment_id: 5c02aebb9d2949d28e86364d46b9198a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 47239
  time_since_restore: 400.08299016952515
  time_this_iter_s: 400.08299016952515
  time_total_s: 400.08299016952515
  timestamp: 1616025365
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00078
  
[2m[36m(pid=47239)[0m Finished run with seed 0 - lr 1 - sec_lr 0.1 - bs 256 - mean val auc: 0.9109599947929382
Result for _inner_e98d6_00078:
  auc: 0.9109599947929382
  date: 2021-03-18_00-56-05
  done: true
  experiment_id: 5c02aebb9d2949d28e86364d46b9198a
  experiment_tag: 78_batch_size=256,eta=0.0,lr=1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 47239
  time_since_restore: 400.08299016952515
  time_this_iter_s: 400.08299016952515
  time_total_s: 400.08299016952515
  timestamp: 1616025365
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00078
  
[2m[36m(pid=9654)[0m Starting run with seed 0 - lr 2 - sec_lr 0.1 - bs 256
[2m[36m(pid=9654)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9654)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9654)[0m GPU available: False, used: False
[2m[36m(pid=9654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9654)[0m 
[2m[36m(pid=9654)[0m   | Name      | Type              | Params
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 12.0 K    Trainable params
[2m[36m(pid=9654)[0m 0         Non-trainable params
[2m[36m(pid=9654)[0m 12.0 K    Total params
[2m[36m(pid=9654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9704)[0m Starting run with seed 0 - lr 2 - sec_lr 0.1 - bs 512
[2m[36m(pid=9704)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9704)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9704)[0m GPU available: False, used: False
[2m[36m(pid=9704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9704)[0m 
[2m[36m(pid=9704)[0m   | Name      | Type              | Params
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 12.0 K    Trainable params
[2m[36m(pid=9704)[0m 0         Non-trainable params
[2m[36m(pid=9704)[0m 12.0 K    Total params
[2m[36m(pid=9704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9704)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9704)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44324)[0m time to fit was 222.33542943000793
[2m[36m(pid=44324)[0m GPU available: False, used: False
[2m[36m(pid=44324)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44324)[0m 
[2m[36m(pid=44324)[0m   | Name      | Type              | Params
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44324)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44324)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 12.0 K    Trainable params
[2m[36m(pid=44324)[0m 0         Non-trainable params
[2m[36m(pid=44324)[0m 12.0 K    Total params
[2m[36m(pid=51272)[0m time to fit was 63.48134255409241
Result for _inner_e98d6_00079:
  auc: 0.9128279328346253
  date: 2021-03-18_00-56-55
  done: false
  experiment_id: 8ae70257e34f45eaade9b5699db1ffff
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 51272
  time_since_restore: 341.5699987411499
  time_this_iter_s: 341.5699987411499
  time_total_s: 341.5699987411499
  timestamp: 1616025415
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00079
  
[2m[36m(pid=51272)[0m Finished run with seed 0 - lr 1 - sec_lr 0.1 - bs 512 - mean val auc: 0.9128279328346253
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 86/180 (1 PENDING, 26 RUNNING, 59 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00085 | PENDING    |       |           32 |     0 | 5     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 66 more trials not shown (16 RUNNING, 49 TERMINATED)


Result for _inner_e98d6_00079:
  auc: 0.9128279328346253
  date: 2021-03-18_00-56-55
  done: true
  experiment_id: 8ae70257e34f45eaade9b5699db1ffff
  experiment_tag: 79_batch_size=512,eta=0.0,lr=1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 51272
  time_since_restore: 341.5699987411499
  time_this_iter_s: 341.5699987411499
  time_total_s: 341.5699987411499
  timestamp: 1616025415
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00079
  
[2m[36m(pid=9770)[0m Starting run with seed 0 - lr 5 - sec_lr 0.1 - bs 32
[2m[36m(pid=9770)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9770)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9770)[0m GPU available: False, used: False
[2m[36m(pid=9770)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9770)[0m 
[2m[36m(pid=9770)[0m   | Name      | Type              | Params
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9770)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9770)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 12.0 K    Trainable params
[2m[36m(pid=9770)[0m 0         Non-trainable params
[2m[36m(pid=9770)[0m 12.0 K    Total params
[2m[36m(pid=9770)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9770)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9770)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9770)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9770)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9770)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=45437)[0m time to fit was 204.47559332847595
[2m[36m(pid=45437)[0m GPU available: False, used: False
[2m[36m(pid=45437)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45437)[0m 
[2m[36m(pid=45437)[0m   | Name      | Type              | Params
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45437)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45437)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 12.0 K    Trainable params
[2m[36m(pid=45437)[0m 0         Non-trainable params
[2m[36m(pid=45437)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m time to fit was 146.34699201583862
[2m[36m(pid=2680)[0m GPU available: False, used: False
[2m[36m(pid=2680)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=2680)[0m 
[2m[36m(pid=2680)[0m   | Name      | Type              | Params
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=2680)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=2680)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 12.0 K    Trainable params
[2m[36m(pid=2680)[0m 0         Non-trainable params
[2m[36m(pid=2680)[0m 12.0 K    Total params
[2m[36m(pid=9704)[0m time to fit was 114.34711289405823
[2m[36m(pid=9704)[0m GPU available: False, used: False
[2m[36m(pid=9704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9704)[0m 
[2m[36m(pid=9704)[0m   | Name      | Type              | Params
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 12.0 K    Trainable params
[2m[36m(pid=9704)[0m 0         Non-trainable params
[2m[36m(pid=9704)[0m 12.0 K    Total params
[2m[36m(pid=9654)[0m time to fit was 132.59300327301025
[2m[36m(pid=9654)[0m GPU available: False, used: False
[2m[36m(pid=9654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9654)[0m 
[2m[36m(pid=9654)[0m   | Name      | Type              | Params
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 12.0 K    Trainable params
[2m[36m(pid=9654)[0m 0         Non-trainable params
[2m[36m(pid=9654)[0m 12.0 K    Total params
[2m[36m(pid=22819)[0m time to fit was 227.28664827346802
Result for _inner_e98d6_00071:
  auc: 0.9047973990440369
  date: 2021-03-18_00-58-40
  done: false
  experiment_id: f479f4f146d749f8989f59e99bbb2029
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22819
  time_since_restore: 1181.4477195739746
  time_this_iter_s: 1181.4477195739746
  time_total_s: 1181.4477195739746
  timestamp: 1616025520
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00071
  
[2m[36m(pid=22819)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 64 - mean val auc: 0.9047973990440369
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 87/180 (1 PENDING, 26 RUNNING, 60 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00086 | PENDING    |       |           64 |     0 | 5     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 67 more trials not shown (16 RUNNING, 50 TERMINATED)


Result for _inner_e98d6_00071:
  auc: 0.9047973990440369
  date: 2021-03-18_00-58-40
  done: true
  experiment_id: f479f4f146d749f8989f59e99bbb2029
  experiment_tag: 71_batch_size=64,eta=0.0,lr=0.1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22819
  time_since_restore: 1181.4477195739746
  time_this_iter_s: 1181.4477195739746
  time_total_s: 1181.4477195739746
  timestamp: 1616025520
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00071
  
[2m[36m(pid=52147)[0m time to fit was 425.9635031223297
[2m[36m(pid=52147)[0m GPU available: False, used: False
[2m[36m(pid=52147)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m 
[2m[36m(pid=52147)[0m   | Name      | Type              | Params
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52147)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52147)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 12.0 K    Trainable params
[2m[36m(pid=52147)[0m 0         Non-trainable params
[2m[36m(pid=52147)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m Starting run with seed 0 - lr 5 - sec_lr 0.1 - bs 64
[2m[36m(pid=9705)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9705)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9705)[0m GPU available: False, used: False
[2m[36m(pid=9705)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9705)[0m 
[2m[36m(pid=9705)[0m   | Name      | Type              | Params
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9705)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9705)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 12.0 K    Trainable params
[2m[36m(pid=9705)[0m 0         Non-trainable params
[2m[36m(pid=9705)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9705)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9705)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9705)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9705)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9705)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9704)[0m time to fit was 89.82846879959106
[2m[36m(pid=9654)[0m time to fit was 71.81629490852356
[2m[36m(pid=9704)[0m GPU available: False, used: False
[2m[36m(pid=9704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9654)[0m GPU available: False, used: False
[2m[36m(pid=9654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9704)[0m 
[2m[36m(pid=9704)[0m   | Name      | Type              | Params
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 12.0 K    Trainable params
[2m[36m(pid=9704)[0m 0         Non-trainable params
[2m[36m(pid=9704)[0m 12.0 K    Total params
[2m[36m(pid=9654)[0m 
[2m[36m(pid=9654)[0m   | Name      | Type              | Params
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 12.0 K    Trainable params
[2m[36m(pid=9654)[0m 0         Non-trainable params
[2m[36m(pid=9654)[0m 12.0 K    Total params
[2m[36m(pid=45437)[0m time to fit was 135.6399211883545
[2m[36m(pid=45437)[0m GPU available: False, used: False
[2m[36m(pid=45437)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=45437)[0m 
[2m[36m(pid=45437)[0m   | Name      | Type              | Params
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=45437)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=45437)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=45437)[0m ------------------------------------------------
[2m[36m(pid=45437)[0m 12.0 K    Trainable params
[2m[36m(pid=45437)[0m 0         Non-trainable params
[2m[36m(pid=45437)[0m 12.0 K    Total params
[2m[36m(pid=9704)[0m time to fit was 45.32201385498047
[2m[36m(pid=9704)[0m GPU available: False, used: False
[2m[36m(pid=9704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9704)[0m 
[2m[36m(pid=9704)[0m   | Name      | Type              | Params
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 12.0 K    Trainable params
[2m[36m(pid=9704)[0m 0         Non-trainable params
[2m[36m(pid=9704)[0m 12.0 K    Total params
[2m[36m(pid=44324)[0m time to fit was 228.14526677131653
[2m[36m(pid=44324)[0m GPU available: False, used: False
[2m[36m(pid=44324)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44324)[0m 
[2m[36m(pid=44324)[0m   | Name      | Type              | Params
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44324)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44324)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 12.0 K    Trainable params
[2m[36m(pid=44324)[0m 0         Non-trainable params
[2m[36m(pid=44324)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m time to fit was 155.3355987071991
[2m[36m(pid=2680)[0m GPU available: False, used: False
[2m[36m(pid=2680)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=2680)[0m 
[2m[36m(pid=2680)[0m   | Name      | Type              | Params
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=2680)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=2680)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 12.0 K    Trainable params
[2m[36m(pid=2680)[0m 0         Non-trainable params
[2m[36m(pid=2680)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m time to fit was 508.6264989376068
[2m[36m(pid=15100)[0m GPU available: False, used: False
[2m[36m(pid=15100)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15100)[0m 
[2m[36m(pid=15100)[0m   | Name      | Type              | Params
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15100)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15100)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 12.0 K    Trainable params
[2m[36m(pid=15100)[0m 0         Non-trainable params
[2m[36m(pid=15100)[0m 12.0 K    Total params
[2m[36m(pid=26509)[0m time to fit was 505.26530504226685
Result for _inner_e98d6_00060:
  auc: 0.8823409676551819
  date: 2021-03-18_01-00-58
  done: false
  experiment_id: 2e518b59398a421c856ad01fdf8d4d77
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26509
  time_since_restore: 2658.7595357894897
  time_this_iter_s: 2658.7595357894897
  time_total_s: 2658.7595357894897
  timestamp: 1616025658
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00060
  
[2m[36m(pid=26509)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 32 - mean val auc: 0.8823409676551819
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 88/180 (1 PENDING, 26 RUNNING, 61 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00087 | PENDING    |       |          128 |     0 | 5     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 68 more trials not shown (16 RUNNING, 51 TERMINATED)


Result for _inner_e98d6_00060:
  auc: 0.8823409676551819
  date: 2021-03-18_01-00-58
  done: true
  experiment_id: 2e518b59398a421c856ad01fdf8d4d77
  experiment_tag: 60_batch_size=32,eta=0.0,lr=0.001,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26509
  time_since_restore: 2658.7595357894897
  time_this_iter_s: 2658.7595357894897
  time_total_s: 2658.7595357894897
  timestamp: 1616025658
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00060
  
[2m[36m(pid=9700)[0m Starting run with seed 0 - lr 5 - sec_lr 0.1 - bs 128
[2m[36m(pid=9700)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9700)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9700)[0m GPU available: False, used: False
[2m[36m(pid=9700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9700)[0m 
[2m[36m(pid=9700)[0m   | Name      | Type              | Params
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 12.0 K    Trainable params
[2m[36m(pid=9700)[0m 0         Non-trainable params
[2m[36m(pid=9700)[0m 12.0 K    Total params
[2m[36m(pid=9700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9700)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9700)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9654)[0m time to fit was 133.09920573234558
[2m[36m(pid=9654)[0m GPU available: False, used: False
[2m[36m(pid=9654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9654)[0m 
[2m[36m(pid=9654)[0m   | Name      | Type              | Params
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 12.0 K    Trainable params
[2m[36m(pid=9654)[0m 0         Non-trainable params
[2m[36m(pid=9654)[0m 12.0 K    Total params
[2m[36m(pid=9704)[0m time to fit was 109.65180563926697
[2m[36m(pid=9704)[0m GPU available: False, used: False
[2m[36m(pid=9704)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9704)[0m 
[2m[36m(pid=9704)[0m   | Name      | Type              | Params
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9704)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9704)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9704)[0m ------------------------------------------------
[2m[36m(pid=9704)[0m 12.0 K    Trainable params
[2m[36m(pid=9704)[0m 0         Non-trainable params
[2m[36m(pid=9704)[0m 12.0 K    Total params
[2m[36m(pid=45437)[0m time to fit was 135.08341479301453
Result for _inner_e98d6_00077:
  auc: 0.9096957564353942
  date: 2021-03-18_01-02-22
  done: false
  experiment_id: 7eedc66ce6194acaa405092b370a1313
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 45437
  time_since_restore: 822.0137848854065
  time_this_iter_s: 822.0137848854065
  time_total_s: 822.0137848854065
  timestamp: 1616025742
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00077
  
[2m[36m(pid=45437)[0m Finished run with seed 0 - lr 1 - sec_lr 0.1 - bs 128 - mean val auc: 0.9096957564353942
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 89/180 (1 PENDING, 26 RUNNING, 62 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00088 | PENDING    |       |          256 |     0 | 5     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 69 more trials not shown (16 RUNNING, 52 TERMINATED)


Result for _inner_e98d6_00077:
  auc: 0.9096957564353942
  date: 2021-03-18_01-02-22
  done: true
  experiment_id: 7eedc66ce6194acaa405092b370a1313
  experiment_tag: 77_batch_size=128,eta=0.0,lr=1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 45437
  time_since_restore: 822.0137848854065
  time_this_iter_s: 822.0137848854065
  time_total_s: 822.0137848854065
  timestamp: 1616025742
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00077
  
[2m[36m(pid=9702)[0m Starting run with seed 0 - lr 5 - sec_lr 0.1 - bs 256
[2m[36m(pid=9702)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9702)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9702)[0m GPU available: False, used: False
[2m[36m(pid=9702)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m 
[2m[36m(pid=9702)[0m   | Name      | Type              | Params
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9702)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9702)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 12.0 K    Trainable params
[2m[36m(pid=9702)[0m 0         Non-trainable params
[2m[36m(pid=9702)[0m 12.0 K    Total params
[2m[36m(pid=9702)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9702)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=884)[0m time to fit was 390.41098380088806
[2m[36m(pid=9702)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9702)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=884)[0m GPU available: False, used: False
[2m[36m(pid=884)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9702)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=884)[0m 
[2m[36m(pid=884)[0m   | Name      | Type              | Params
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=884)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=884)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 12.0 K    Trainable params
[2m[36m(pid=884)[0m 0         Non-trainable params
[2m[36m(pid=884)[0m 12.0 K    Total params
[2m[36m(pid=2680)[0m time to fit was 134.412850856781
[2m[36m(pid=2680)[0m GPU available: False, used: False
[2m[36m(pid=2680)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=2680)[0m 
[2m[36m(pid=2680)[0m   | Name      | Type              | Params
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=2680)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=2680)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=2680)[0m ------------------------------------------------
[2m[36m(pid=2680)[0m 12.0 K    Trainable params
[2m[36m(pid=2680)[0m 0         Non-trainable params
[2m[36m(pid=2680)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m time to fit was 264.02760648727417
[2m[36m(pid=9705)[0m GPU available: False, used: False
[2m[36m(pid=9705)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9705)[0m 
[2m[36m(pid=9705)[0m   | Name      | Type              | Params
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9705)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9705)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 12.0 K    Trainable params
[2m[36m(pid=9705)[0m 0         Non-trainable params
[2m[36m(pid=9705)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m time to fit was 621.2340877056122
[2m[36m(pid=38965)[0m GPU available: False, used: False
[2m[36m(pid=38965)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=38965)[0m 
[2m[36m(pid=38965)[0m   | Name      | Type              | Params
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=38965)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=38965)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 12.0 K    Trainable params
[2m[36m(pid=38965)[0m 0         Non-trainable params
[2m[36m(pid=38965)[0m 12.0 K    Total params
[2m[36m(pid=9654)[0m time to fit was 92.73740768432617
[2m[36m(pid=9654)[0m GPU available: False, used: False
[2m[36m(pid=9654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9654)[0m 
[2m[36m(pid=9654)[0m   | Name      | Type              | Params
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9654)[0m ------------------------------------------------
[2m[36m(pid=9654)[0m 12.0 K    Trainable params
[2m[36m(pid=9654)[0m 0         Non-trainable params
[2m[36m(pid=9654)[0m 12.0 K    Total params
[2m[36m(pid=9704)[0m time to fit was 71.51489067077637
Result for _inner_e98d6_00084:
  auc: 0.825761365890503
  date: 2021-03-18_01-03-28
  done: false
  experiment_id: 4c1eb147dd2740d6ad941b07c4bdfea8
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9704
  time_since_restore: 431.8814470767975
  time_this_iter_s: 431.8814470767975
  time_total_s: 431.8814470767975
  timestamp: 1616025808
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00084
  
[2m[36m(pid=9704)[0m Finished run with seed 0 - lr 2 - sec_lr 0.1 - bs 512 - mean val auc: 0.825761365890503
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 90/180 (1 PENDING, 26 RUNNING, 63 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00089 | PENDING    |       |          512 |     0 | 5     |    0.1   |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 70 more trials not shown (16 RUNNING, 53 TERMINATED)


Result for _inner_e98d6_00084:
  auc: 0.825761365890503
  date: 2021-03-18_01-03-28
  done: true
  experiment_id: 4c1eb147dd2740d6ad941b07c4bdfea8
  experiment_tag: 84_batch_size=512,eta=0.0,lr=2,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9704
  time_since_restore: 431.8814470767975
  time_this_iter_s: 431.8814470767975
  time_total_s: 431.8814470767975
  timestamp: 1616025808
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00084
  
[2m[36m(pid=26365)[0m Starting run with seed 0 - lr 5 - sec_lr 0.1 - bs 512
[2m[36m(pid=26365)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26365)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=26365)[0m GPU available: False, used: False
[2m[36m(pid=26365)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26365)[0m 
[2m[36m(pid=26365)[0m   | Name      | Type              | Params
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26365)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26365)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 12.0 K    Trainable params
[2m[36m(pid=26365)[0m 0         Non-trainable params
[2m[36m(pid=26365)[0m 12.0 K    Total params
[2m[36m(pid=26365)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26365)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26365)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26365)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26365)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=26365)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9770)[0m time to fit was 419.6244695186615
[2m[36m(pid=9770)[0m GPU available: False, used: False
[2m[36m(pid=9770)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9770)[0m 
[2m[36m(pid=9770)[0m   | Name      | Type              | Params
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9770)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9770)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 12.0 K    Trainable params
[2m[36m(pid=9770)[0m 0         Non-trainable params
[2m[36m(pid=9770)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m time to fit was 584.6897947788239
[2m[36m(pid=43203)[0m GPU available: False, used: False
[2m[36m(pid=43203)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43203)[0m 
[2m[36m(pid=43203)[0m   | Name      | Type              | Params
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43203)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43203)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43203)[0m ------------------------------------------------
[2m[36m(pid=43203)[0m 12.0 K    Trainable params
[2m[36m(pid=43203)[0m 0         Non-trainable params
[2m[36m(pid=43203)[0m 12.0 K    Total params
[2m[36m(pid=44324)[0m time to fit was 246.3870460987091
[2m[36m(pid=44324)[0m GPU available: False, used: False
[2m[36m(pid=44324)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44324)[0m 
[2m[36m(pid=44324)[0m   | Name      | Type              | Params
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44324)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44324)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44324)[0m ------------------------------------------------
[2m[36m(pid=44324)[0m 12.0 K    Trainable params
[2m[36m(pid=44324)[0m 0         Non-trainable params
[2m[36m(pid=44324)[0m 12.0 K    Total params
[2m[36m(pid=9398)[0m time to fit was 1342.2109687328339
[2m[36m(pid=9398)[0m GPU available: False, used: False
[2m[36m(pid=9398)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9398)[0m 
[2m[36m(pid=9398)[0m   | Name      | Type              | Params
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9398)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9398)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9398)[0m ------------------------------------------------
[2m[36m(pid=9398)[0m 12.0 K    Trainable params
[2m[36m(pid=9398)[0m 0         Non-trainable params
[2m[36m(pid=9398)[0m 12.0 K    Total params
[2m[36m(pid=26365)[0m time to fit was 64.65880560874939
[2m[36m(pid=26365)[0m GPU available: False, used: False
[2m[36m(pid=26365)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26365)[0m 
[2m[36m(pid=26365)[0m   | Name      | Type              | Params
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26365)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26365)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 12.0 K    Trainable params
[2m[36m(pid=26365)[0m 0         Non-trainable params
[2m[36m(pid=26365)[0m 12.0 K    Total params
[2m[36m(pid=9702)[0m time to fit was 146.01084351539612
[2m[36m(pid=9702)[0m GPU available: False, used: False
[2m[36m(pid=9702)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m 
[2m[36m(pid=9702)[0m   | Name      | Type              | Params
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9702)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9702)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 12.0 K    Trainable params
[2m[36m(pid=9702)[0m 0         Non-trainable params
[2m[36m(pid=9702)[0m 12.0 K    Total params
[2m[36m(pid=9654)[0m time to fit was 91.49330544471741
Result for _inner_e98d6_00083:
  auc: 0.8260024547576904
  date: 2021-03-18_01-04-59
  done: false
  experiment_id: 34b69b07a7c04a369d158e42b2ee779a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9654
  time_since_restore: 523.1957068443298
  time_this_iter_s: 523.1957068443298
  time_total_s: 523.1957068443298
  timestamp: 1616025899
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00083
  
[2m[36m(pid=9654)[0m Finished run with seed 0 - lr 2 - sec_lr 0.1 - bs 256 - mean val auc: 0.8260024547576904
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 91/180 (1 PENDING, 26 RUNNING, 64 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00090 | PENDING    |       |           32 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 71 more trials not shown (16 RUNNING, 54 TERMINATED)


Result for _inner_e98d6_00083:
  auc: 0.8260024547576904
  date: 2021-03-18_01-04-59
  done: true
  experiment_id: 34b69b07a7c04a369d158e42b2ee779a
  experiment_tag: 83_batch_size=256,eta=0.0,lr=2,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9654
  time_since_restore: 523.1957068443298
  time_this_iter_s: 523.1957068443298
  time_total_s: 523.1957068443298
  timestamp: 1616025899
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00083
  
[2m[36m(pid=30253)[0m Starting run with seed 0 - lr 0.001 - sec_lr 1 - bs 32
[2m[36m(pid=30253)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30253)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30253)[0m GPU available: False, used: False
[2m[36m(pid=30253)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30253)[0m 
[2m[36m(pid=30253)[0m   | Name      | Type              | Params
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30253)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30253)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 12.0 K    Trainable params
[2m[36m(pid=30253)[0m 0         Non-trainable params
[2m[36m(pid=30253)[0m 12.0 K    Total params
[2m[36m(pid=30253)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30253)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30253)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30253)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30253)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30253)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=2680)[0m time to fit was 169.8581395149231
Result for _inner_e98d6_00082:
  auc: 0.9015460729598999
  date: 2021-03-18_01-05-36
  done: false
  experiment_id: f9e70aaa11be4707991d1ed6b1f5d975
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 2680
  time_since_restore: 751.1500265598297
  time_this_iter_s: 751.1500265598297
  time_total_s: 751.1500265598297
  timestamp: 1616025936
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00082
  
[2m[36m(pid=2680)[0m Finished run with seed 0 - lr 2 - sec_lr 0.1 - bs 128 - mean val auc: 0.9015460729598999
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 92/180 (1 PENDING, 26 RUNNING, 65 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00091 | PENDING    |       |           64 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 72 more trials not shown (16 RUNNING, 55 TERMINATED)


Result for _inner_e98d6_00082:
  auc: 0.9015460729598999
  date: 2021-03-18_01-05-36
  done: true
  experiment_id: f9e70aaa11be4707991d1ed6b1f5d975
  experiment_tag: 82_batch_size=128,eta=0.0,lr=2,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 2680
  time_since_restore: 751.1500265598297
  time_this_iter_s: 751.1500265598297
  time_total_s: 751.1500265598297
  timestamp: 1616025936
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00082
  
2021-03-18 01:05:38,264	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff81a64b0b01000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=31590)[0m Starting run with seed 0 - lr 0.001 - sec_lr 1 - bs 64
[2m[36m(pid=31590)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=31590)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=31590)[0m GPU available: False, used: False
[2m[36m(pid=31590)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31590)[0m 
[2m[36m(pid=31590)[0m   | Name      | Type              | Params
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31590)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31590)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 12.0 K    Trainable params
[2m[36m(pid=31590)[0m 0         Non-trainable params
[2m[36m(pid=31590)[0m 12.0 K    Total params
[2m[36m(pid=31590)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=31590)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=31590)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=31590)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=31590)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=31590)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9700)[0m time to fit was 282.0318434238434
[2m[36m(pid=9700)[0m GPU available: False, used: False
[2m[36m(pid=9700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9700)[0m 
[2m[36m(pid=9700)[0m   | Name      | Type              | Params
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 12.0 K    Trainable params
[2m[36m(pid=9700)[0m 0         Non-trainable params
[2m[36m(pid=9700)[0m 12.0 K    Total params
[2m[36m(pid=52147)[0m time to fit was 428.1786332130432
[2m[36m(pid=52147)[0m GPU available: False, used: False
[2m[36m(pid=52147)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m 
[2m[36m(pid=52147)[0m   | Name      | Type              | Params
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52147)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52147)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 12.0 K    Trainable params
[2m[36m(pid=52147)[0m 0         Non-trainable params
[2m[36m(pid=52147)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m time to fit was 226.0218915939331
[2m[36m(pid=884)[0m GPU available: False, used: False
[2m[36m(pid=884)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=884)[0m 
[2m[36m(pid=884)[0m   | Name      | Type              | Params
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=884)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=884)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 12.0 K    Trainable params
[2m[36m(pid=884)[0m 0         Non-trainable params
[2m[36m(pid=884)[0m 12.0 K    Total params
[2m[36m(pid=26365)[0m time to fit was 186.8241274356842
[2m[36m(pid=26365)[0m GPU available: False, used: False
[2m[36m(pid=26365)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26365)[0m 
[2m[36m(pid=26365)[0m   | Name      | Type              | Params
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26365)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26365)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 12.0 K    Trainable params
[2m[36m(pid=26365)[0m 0         Non-trainable params
[2m[36m(pid=26365)[0m 12.0 K    Total params
[2m[36m(pid=9700)[0m time to fit was 122.37667560577393
[2m[36m(pid=9700)[0m GPU available: False, used: False
[2m[36m(pid=9700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9700)[0m 
[2m[36m(pid=9700)[0m   | Name      | Type              | Params
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 12.0 K    Trainable params
[2m[36m(pid=9700)[0m 0         Non-trainable params
[2m[36m(pid=9700)[0m 12.0 K    Total params
[2m[36m(pid=9702)[0m time to fit was 191.23539447784424
[2m[36m(pid=9702)[0m GPU available: False, used: False
[2m[36m(pid=9702)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m 
[2m[36m(pid=9702)[0m   | Name      | Type              | Params
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9702)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9702)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 12.0 K    Trainable params
[2m[36m(pid=9702)[0m 0         Non-trainable params
[2m[36m(pid=9702)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m time to fit was 5586.505601167679
[2m[36m(pid=21741)[0m GPU available: False, used: False
[2m[36m(pid=21741)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21741)[0m 
[2m[36m(pid=21741)[0m   | Name      | Type              | Params
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21741)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21741)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 12.0 K    Trainable params
[2m[36m(pid=21741)[0m 0         Non-trainable params
[2m[36m(pid=21741)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m time to fit was 504.4317772388458
[2m[36m(pid=15100)[0m GPU available: False, used: False
[2m[36m(pid=15100)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15100)[0m 
[2m[36m(pid=15100)[0m   | Name      | Type              | Params
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15100)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15100)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15100)[0m ------------------------------------------------
[2m[36m(pid=15100)[0m 12.0 K    Trainable params
[2m[36m(pid=15100)[0m 0         Non-trainable params
[2m[36m(pid=15100)[0m 12.0 K    Total params
[2m[36m(pid=26638)[0m time to fit was 2787.9907245635986
[2m[36m(pid=26638)[0m GPU available: False, used: False
[2m[36m(pid=26638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26638)[0m 
[2m[36m(pid=26638)[0m   | Name      | Type              | Params
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 12.0 K    Trainable params
[2m[36m(pid=26638)[0m 0         Non-trainable params
[2m[36m(pid=26638)[0m 12.0 K    Total params
[2m[36m(pid=21639)[0m time to fit was 3609.3685581684113
[2m[36m(pid=21639)[0m GPU available: False, used: False
[2m[36m(pid=21639)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21639)[0m 
[2m[36m(pid=21639)[0m   | Name      | Type              | Params
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21639)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21639)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 12.0 K    Trainable params
[2m[36m(pid=21639)[0m 0         Non-trainable params
[2m[36m(pid=21639)[0m 12.0 K    Total params
[2m[36m(pid=9702)[0m time to fit was 71.38649654388428
[2m[36m(pid=9702)[0m GPU available: False, used: False
[2m[36m(pid=9702)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m 
[2m[36m(pid=9702)[0m   | Name      | Type              | Params
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9702)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9702)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 12.0 K    Trainable params
[2m[36m(pid=9702)[0m 0         Non-trainable params
[2m[36m(pid=9702)[0m 12.0 K    Total params
[2m[36m(pid=26365)[0m time to fit was 89.98085117340088
[2m[36m(pid=26365)[0m GPU available: False, used: False
[2m[36m(pid=26365)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26365)[0m 
[2m[36m(pid=26365)[0m   | Name      | Type              | Params
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26365)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26365)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 12.0 K    Trainable params
[2m[36m(pid=26365)[0m 0         Non-trainable params
[2m[36m(pid=26365)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m time to fit was 228.1746826171875
[2m[36m(pid=884)[0m GPU available: False, used: False
[2m[36m(pid=884)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=884)[0m 
[2m[36m(pid=884)[0m   | Name      | Type              | Params
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=884)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=884)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=884)[0m ------------------------------------------------
[2m[36m(pid=884)[0m 12.0 K    Trainable params
[2m[36m(pid=884)[0m 0         Non-trainable params
[2m[36m(pid=884)[0m 12.0 K    Total params
[2m[36m(pid=21667)[0m time to fit was 4794.50343132019
[2m[36m(pid=21667)[0m GPU available: False, used: False
[2m[36m(pid=21667)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m 
[2m[36m(pid=21667)[0m   | Name      | Type              | Params
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21667)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21667)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 12.0 K    Trainable params
[2m[36m(pid=21667)[0m 0         Non-trainable params
[2m[36m(pid=21667)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m time to fit was 423.0987706184387
[2m[36m(pid=38965)[0m GPU available: False, used: False
[2m[36m(pid=38965)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=38965)[0m 
[2m[36m(pid=38965)[0m   | Name      | Type              | Params
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=38965)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=38965)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 12.0 K    Trainable params
[2m[36m(pid=38965)[0m 0         Non-trainable params
[2m[36m(pid=38965)[0m 12.0 K    Total params
[2m[36m(pid=44324)[0m time to fit was 349.0346438884735
Result for _inner_e98d6_00076:
  auc: 0.9074167370796203
  date: 2021-03-18_01-10-26
  done: false
  experiment_id: 49edca492df44189aa7f6d2a9f25c2c4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 44324
  time_since_restore: 1332.3128440380096
  time_this_iter_s: 1332.3128440380096
  time_total_s: 1332.3128440380096
  timestamp: 1616026226
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00076
  
[2m[36m(pid=44324)[0m Finished run with seed 0 - lr 1 - sec_lr 0.1 - bs 64 - mean val auc: 0.9074167370796203
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 93/180 (1 PENDING, 26 RUNNING, 66 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00092 | PENDING    |       |          128 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 73 more trials not shown (16 RUNNING, 56 TERMINATED)


Result for _inner_e98d6_00076:
  auc: 0.9074167370796203
  date: 2021-03-18_01-10-26
  done: true
  experiment_id: 49edca492df44189aa7f6d2a9f25c2c4
  experiment_tag: 76_batch_size=64,eta=0.0,lr=1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 44324
  time_since_restore: 1332.3128440380096
  time_this_iter_s: 1332.3128440380096
  time_total_s: 1332.3128440380096
  timestamp: 1616026226
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00076
  
[2m[36m(pid=42052)[0m Starting run with seed 0 - lr 0.001 - sec_lr 1 - bs 128
[2m[36m(pid=42052)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42052)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=42052)[0m GPU available: False, used: False
[2m[36m(pid=42052)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=42052)[0m 
[2m[36m(pid=42052)[0m   | Name      | Type              | Params
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=42052)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=42052)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 12.0 K    Trainable params
[2m[36m(pid=42052)[0m 0         Non-trainable params
[2m[36m(pid=42052)[0m 12.0 K    Total params
[2m[36m(pid=42052)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=42052)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=42052)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=42052)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=42052)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=42052)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21740)[0m time to fit was 7572.451854944229
[2m[36m(pid=21740)[0m GPU available: False, used: False
[2m[36m(pid=21740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m 
[2m[36m(pid=21740)[0m   | Name      | Type              | Params
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 12.0 K    Trainable params
[2m[36m(pid=21740)[0m 0         Non-trainable params
[2m[36m(pid=21740)[0m 12.0 K    Total params
[2m[36m(pid=52147)[0m time to fit was 421.7897572517395
[2m[36m(pid=52147)[0m GPU available: False, used: False
[2m[36m(pid=52147)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m 
[2m[36m(pid=52147)[0m   | Name      | Type              | Params
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52147)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52147)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 12.0 K    Trainable params
[2m[36m(pid=52147)[0m 0         Non-trainable params
[2m[36m(pid=52147)[0m 12.0 K    Total params
[2m[36m(pid=31590)[0m time to fit was 442.30767941474915
[2m[36m(pid=31590)[0m GPU available: False, used: False
[2m[36m(pid=31590)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31590)[0m 
[2m[36m(pid=31590)[0m   | Name      | Type              | Params
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31590)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31590)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 12.0 K    Trainable params
[2m[36m(pid=31590)[0m 0         Non-trainable params
[2m[36m(pid=31590)[0m 12.0 K    Total params
[2m[36m(pid=26365)[0m time to fit was 241.98271322250366
[2m[36m(pid=26365)[0m GPU available: False, used: False
[2m[36m(pid=26365)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26365)[0m 
[2m[36m(pid=26365)[0m   | Name      | Type              | Params
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26365)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26365)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26365)[0m ------------------------------------------------
[2m[36m(pid=26365)[0m 12.0 K    Trainable params
[2m[36m(pid=26365)[0m 0         Non-trainable params
[2m[36m(pid=26365)[0m 12.0 K    Total params
[2m[36m(pid=30253)[0m time to fit was 495.6108980178833
[2m[36m(pid=30253)[0m GPU available: False, used: False
[2m[36m(pid=30253)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30253)[0m 
[2m[36m(pid=30253)[0m   | Name      | Type              | Params
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30253)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30253)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 12.0 K    Trainable params
[2m[36m(pid=30253)[0m 0         Non-trainable params
[2m[36m(pid=30253)[0m 12.0 K    Total params
[2m[36m(pid=884)[0m time to fit was 222.68567037582397
Result for _inner_e98d6_00081:
  auc: 0.8175207853317261
  date: 2021-03-18_01-13-50
  done: false
  experiment_id: 5915ace2668e41eba52e1f5abb544994
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 884
  time_since_restore: 1288.8919351100922
  time_this_iter_s: 1288.8919351100922
  time_total_s: 1288.8919351100922
  timestamp: 1616026430
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00081
  
[2m[36m(pid=884)[0m Finished run with seed 0 - lr 2 - sec_lr 0.1 - bs 64 - mean val auc: 0.8175207853317261
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 94/180 (1 PENDING, 26 RUNNING, 67 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00093 | PENDING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 74 more trials not shown (16 RUNNING, 57 TERMINATED)


Result for _inner_e98d6_00081:
  auc: 0.8175207853317261
  date: 2021-03-18_01-13-50
  done: true
  experiment_id: 5915ace2668e41eba52e1f5abb544994
  experiment_tag: 81_batch_size=64,eta=0.0,lr=2,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 884
  time_since_restore: 1288.8919351100922
  time_this_iter_s: 1288.8919351100922
  time_total_s: 1288.8919351100922
  timestamp: 1616026430
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00081
  
[2m[36m(pid=9702)[0m time to fit was 282.20120763778687
[2m[36m(pid=49412)[0m Starting run with seed 0 - lr 0.001 - sec_lr 1 - bs 256
[2m[36m(pid=49412)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=49412)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=49412)[0m GPU available: False, used: False
[2m[36m(pid=49412)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=49412)[0m 
[2m[36m(pid=49412)[0m   | Name      | Type              | Params
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=49412)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=49412)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 12.0 K    Trainable params
[2m[36m(pid=49412)[0m 0         Non-trainable params
[2m[36m(pid=49412)[0m 12.0 K    Total params
[2m[36m(pid=49412)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=49412)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9702)[0m GPU available: False, used: False
[2m[36m(pid=9702)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9702)[0m 
[2m[36m(pid=9702)[0m   | Name      | Type              | Params
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9702)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9702)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9702)[0m ------------------------------------------------
[2m[36m(pid=9702)[0m 12.0 K    Trainable params
[2m[36m(pid=9702)[0m 0         Non-trainable params
[2m[36m(pid=9702)[0m 12.0 K    Total params
[2m[36m(pid=49412)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=49412)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=49412)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=49412)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26365)[0m time to fit was 45.43126177787781
Result for _inner_e98d6_00089:
  auc: 0.6630740761756897
  date: 2021-03-18_01-14-10
  done: false
  experiment_id: bb3dc11f35e744608cce1b4e4459a605
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26365
  time_since_restore: 630.1339728832245
  time_this_iter_s: 630.1339728832245
  time_total_s: 630.1339728832245
  timestamp: 1616026450
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00089
  
[2m[36m(pid=26365)[0m Finished run with seed 0 - lr 5 - sec_lr 0.1 - bs 512 - mean val auc: 0.6630740761756897
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 95/180 (1 PENDING, 26 RUNNING, 68 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00094 | PENDING    |       |          512 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 75 more trials not shown (16 RUNNING, 58 TERMINATED)


Result for _inner_e98d6_00089:
  auc: 0.6630740761756897
  date: 2021-03-18_01-14-10
  done: true
  experiment_id: bb3dc11f35e744608cce1b4e4459a605
  experiment_tag: 89_batch_size=512,eta=0.0,lr=5,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26365
  time_since_restore: 630.1339728832245
  time_this_iter_s: 630.1339728832245
  time_total_s: 630.1339728832245
  timestamp: 1616026450
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00089
  
[2m[36m(pid=50164)[0m Starting run with seed 0 - lr 0.001 - sec_lr 1 - bs 512
[2m[36m(pid=50164)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50164)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=50164)[0m GPU available: False, used: False
[2m[36m(pid=50164)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50164)[0m 
[2m[36m(pid=50164)[0m   | Name      | Type              | Params
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50164)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50164)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 12.0 K    Trainable params
[2m[36m(pid=50164)[0m 0         Non-trainable params
[2m[36m(pid=50164)[0m 12.0 K    Total params
[2m[36m(pid=50164)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=50164)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50164)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=50164)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50164)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=50164)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9398)[0m time to fit was 593.0583019256592
[2m[36m(pid=9398)[0m Finished run with seed 0 - lr 5 - sec_lr 0.01 - bs 64 - mean val auc: 0.7327016949653625
Result for _inner_e98d6_00056:
  auc: 0.7327016949653625
  date: 2021-03-18_01-14-38
  done: false
  experiment_id: 1b5a6a34cf8249d9afd21e52d00d3200
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9398
  time_since_restore: 3908.544588804245
  time_this_iter_s: 3908.544588804245
  time_total_s: 3908.544588804245
  timestamp: 1616026478
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00056
  
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 96/180 (1 PENDING, 26 RUNNING, 69 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00095 | PENDING    |       |           32 |     0 | 0.01  |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 76 more trials not shown (16 RUNNING, 59 TERMINATED)


Result for _inner_e98d6_00056:
  auc: 0.7327016949653625
  date: 2021-03-18_01-14-38
  done: true
  experiment_id: 1b5a6a34cf8249d9afd21e52d00d3200
  experiment_tag: 56_batch_size=64,eta=0.0,lr=5,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9398
  time_since_restore: 3908.544588804245
  time_this_iter_s: 3908.544588804245
  time_total_s: 3908.544588804245
  timestamp: 1616026478
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00056
  
2021-03-18 01:14:39,801	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffffe95019bf01000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=51143)[0m Starting run with seed 0 - lr 0.01 - sec_lr 1 - bs 32
[2m[36m(pid=51143)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51143)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=51143)[0m GPU available: False, used: False
[2m[36m(pid=51143)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51143)[0m 
[2m[36m(pid=51143)[0m   | Name      | Type              | Params
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51143)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51143)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 12.0 K    Trainable params
[2m[36m(pid=51143)[0m 0         Non-trainable params
[2m[36m(pid=51143)[0m 12.0 K    Total params
[2m[36m(pid=51143)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=51143)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51143)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=51143)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51143)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=51143)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21720)[0m time to fit was 2161.405469417572
[2m[36m(pid=21720)[0m GPU available: False, used: False
[2m[36m(pid=21720)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21720)[0m 
[2m[36m(pid=21720)[0m   | Name      | Type              | Params
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21720)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21720)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 12.0 K    Trainable params
[2m[36m(pid=21720)[0m 0         Non-trainable params
[2m[36m(pid=21720)[0m 12.0 K    Total params
[2m[36m(pid=26638)[0m time to fit was 371.3981809616089
[2m[36m(pid=26638)[0m GPU available: False, used: False
[2m[36m(pid=26638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26638)[0m 
[2m[36m(pid=26638)[0m   | Name      | Type              | Params
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 12.0 K    Trainable params
[2m[36m(pid=26638)[0m 0         Non-trainable params
[2m[36m(pid=26638)[0m 12.0 K    Total params
[2m[36m(pid=50164)[0m time to fit was 73.56466221809387
[2m[36m(pid=50164)[0m GPU available: False, used: False
[2m[36m(pid=50164)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50164)[0m 
[2m[36m(pid=50164)[0m   | Name      | Type              | Params
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50164)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50164)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 12.0 K    Trainable params
[2m[36m(pid=50164)[0m 0         Non-trainable params
[2m[36m(pid=50164)[0m 12.0 K    Total params
[2m[36m(pid=9700)[0m time to fit was 462.8722629547119
[2m[36m(pid=9700)[0m GPU available: False, used: False
[2m[36m(pid=9700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9700)[0m 
[2m[36m(pid=9700)[0m   | Name      | Type              | Params
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 12.0 K    Trainable params
[2m[36m(pid=9700)[0m 0         Non-trainable params
[2m[36m(pid=9700)[0m 12.0 K    Total params
[2m[36m(pid=9702)[0m time to fit was 93.92489671707153
Result for _inner_e98d6_00088:
  auc: 0.6758894920349121
  date: 2021-03-18_01-15-37
  done: false
  experiment_id: 653b083edd984e0c95f077e8190aed37
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9702
  time_since_restore: 786.0762312412262
  time_this_iter_s: 786.0762312412262
  time_total_s: 786.0762312412262
  timestamp: 1616026537
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00088
  
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 97/180 (1 PENDING, 26 RUNNING, 70 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00096 | PENDING    |       |           64 |     0 | 0.01  |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 77 more trials not shown (16 RUNNING, 60 TERMINATED)


Result for _inner_e98d6_00088:
  auc: 0.6758894920349121
  date: 2021-03-18_01-15-37
  done: true
  experiment_id: 653b083edd984e0c95f077e8190aed37
  experiment_tag: 88_batch_size=256,eta=0.0,lr=5,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9702
  time_since_restore: 786.0762312412262
  time_this_iter_s: 786.0762312412262
  time_total_s: 786.0762312412262
  timestamp: 1616026537
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00088
  
[2m[36m(pid=9702)[0m Finished run with seed 0 - lr 5 - sec_lr 0.1 - bs 256 - mean val auc: 0.6758894920349121
[2m[36m(pid=497)[0m Starting run with seed 0 - lr 0.01 - sec_lr 1 - bs 64
[2m[36m(pid=497)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=497)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=497)[0m GPU available: False, used: False
[2m[36m(pid=497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=497)[0m 
[2m[36m(pid=497)[0m   | Name      | Type              | Params
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 12.0 K    Trainable params
[2m[36m(pid=497)[0m 0         Non-trainable params
[2m[36m(pid=497)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=42052)[0m time to fit was 348.1079902648926
[2m[36m(pid=42052)[0m GPU available: False, used: False
[2m[36m(pid=42052)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=42052)[0m 
[2m[36m(pid=42052)[0m   | Name      | Type              | Params
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=42052)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=42052)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 12.0 K    Trainable params
[2m[36m(pid=42052)[0m 0         Non-trainable params
[2m[36m(pid=42052)[0m 12.0 K    Total params
[2m[36m(pid=15100)[0m time to fit was 465.2256329059601
Result for _inner_e98d6_00070:
  auc: 0.9020448446273803
  date: 2021-03-18_01-16-55
  done: false
  experiment_id: f0790408427b4cd8a8cfad6792a230dd
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15100
  time_since_restore: 2480.1767971515656
  time_this_iter_s: 2480.1767971515656
  time_total_s: 2480.1767971515656
  timestamp: 1616026615
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00070
  
[2m[36m(pid=15100)[0m Finished run with seed 0 - lr 0.1 - sec_lr 0.1 - bs 32 - mean val auc: 0.9020448446273803
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 98/180 (1 PENDING, 26 RUNNING, 71 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00097 | PENDING    |       |          128 |     0 | 0.01  |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 78 more trials not shown (16 RUNNING, 61 TERMINATED)


Result for _inner_e98d6_00070:
  auc: 0.9020448446273803
  date: 2021-03-18_01-16-55
  done: true
  experiment_id: f0790408427b4cd8a8cfad6792a230dd
  experiment_tag: 70_batch_size=32,eta=0.0,lr=0.1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15100
  time_since_restore: 2480.1767971515656
  time_this_iter_s: 2480.1767971515656
  time_total_s: 2480.1767971515656
  timestamp: 1616026615
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00070
  
[2m[36m(pid=21729)[0m time to fit was 5463.568505764008
[2m[36m(pid=21729)[0m GPU available: False, used: False
[2m[36m(pid=21729)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21729)[0m 
[2m[36m(pid=21729)[0m   | Name      | Type              | Params
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21729)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21729)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 12.0 K    Trainable params
[2m[36m(pid=21729)[0m 0         Non-trainable params
[2m[36m(pid=21729)[0m 12.0 K    Total params
[2m[36m(pid=3557)[0m Starting run with seed 0 - lr 0.01 - sec_lr 1 - bs 128
[2m[36m(pid=3557)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3557)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=3557)[0m GPU available: False, used: False
[2m[36m(pid=3557)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3557)[0m 
[2m[36m(pid=3557)[0m   | Name      | Type              | Params
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3557)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3557)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 12.0 K    Trainable params
[2m[36m(pid=3557)[0m 0         Non-trainable params
[2m[36m(pid=3557)[0m 12.0 K    Total params
[2m[36m(pid=3557)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3557)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3557)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3557)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3557)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=3557)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50164)[0m time to fit was 94.3476722240448
[2m[36m(pid=50164)[0m GPU available: False, used: False
[2m[36m(pid=50164)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50164)[0m 
[2m[36m(pid=50164)[0m   | Name      | Type              | Params
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50164)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50164)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 12.0 K    Trainable params
[2m[36m(pid=50164)[0m 0         Non-trainable params
[2m[36m(pid=50164)[0m 12.0 K    Total params
[2m[36m(pid=31590)[0m time to fit was 244.0952136516571
[2m[36m(pid=31590)[0m GPU available: False, used: False
[2m[36m(pid=31590)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31590)[0m 
[2m[36m(pid=31590)[0m   | Name      | Type              | Params
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31590)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31590)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 12.0 K    Trainable params
[2m[36m(pid=31590)[0m 0         Non-trainable params
[2m[36m(pid=31590)[0m 12.0 K    Total params
[2m[36m(pid=49412)[0m time to fit was 192.47884917259216
[2m[36m(pid=49412)[0m GPU available: False, used: False
[2m[36m(pid=49412)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=49412)[0m 
[2m[36m(pid=49412)[0m   | Name      | Type              | Params
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=49412)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=49412)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 12.0 K    Trainable params
[2m[36m(pid=49412)[0m 0         Non-trainable params
[2m[36m(pid=49412)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m time to fit was 856.2619605064392
[2m[36m(pid=9705)[0m GPU available: False, used: False
[2m[36m(pid=9705)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9705)[0m 
[2m[36m(pid=9705)[0m   | Name      | Type              | Params
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9705)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9705)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 12.0 K    Trainable params
[2m[36m(pid=9705)[0m 0         Non-trainable params
[2m[36m(pid=9705)[0m 12.0 K    Total params
[2m[36m(pid=9700)[0m time to fit was 124.6424150466919
[2m[36m(pid=9700)[0m GPU available: False, used: False
[2m[36m(pid=9700)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9700)[0m 
[2m[36m(pid=9700)[0m   | Name      | Type              | Params
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9700)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9700)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9700)[0m ------------------------------------------------
[2m[36m(pid=9700)[0m 12.0 K    Trainable params
[2m[36m(pid=9700)[0m 0         Non-trainable params
[2m[36m(pid=9700)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m time to fit was 459.0821144580841
[2m[36m(pid=38965)[0m GPU available: False, used: False
[2m[36m(pid=38965)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=38965)[0m 
[2m[36m(pid=38965)[0m   | Name      | Type              | Params
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=38965)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=38965)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=38965)[0m ------------------------------------------------
[2m[36m(pid=38965)[0m 12.0 K    Trainable params
[2m[36m(pid=38965)[0m 0         Non-trainable params
[2m[36m(pid=38965)[0m 12.0 K    Total params
[2m[36m(pid=9770)[0m time to fit was 890.7386333942413
[2m[36m(pid=9770)[0m GPU available: False, used: False
[2m[36m(pid=9770)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9770)[0m 
[2m[36m(pid=9770)[0m   | Name      | Type              | Params
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9770)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9770)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 12.0 K    Trainable params
[2m[36m(pid=9770)[0m 0         Non-trainable params
[2m[36m(pid=9770)[0m 12.0 K    Total params
[2m[36m(pid=3557)[0m time to fit was 144.82467412948608
[2m[36m(pid=3557)[0m GPU available: False, used: False
[2m[36m(pid=3557)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3557)[0m 
[2m[36m(pid=3557)[0m   | Name      | Type              | Params
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3557)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3557)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 12.0 K    Trainable params
[2m[36m(pid=3557)[0m 0         Non-trainable params
[2m[36m(pid=3557)[0m 12.0 K    Total params
[2m[36m(pid=42052)[0m time to fit was 190.66745567321777
[2m[36m(pid=42052)[0m GPU available: False, used: False
[2m[36m(pid=42052)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=42052)[0m 
[2m[36m(pid=42052)[0m   | Name      | Type              | Params
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=42052)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=42052)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 12.0 K    Trainable params
[2m[36m(pid=42052)[0m 0         Non-trainable params
[2m[36m(pid=42052)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m time to fit was 243.11279273033142
[2m[36m(pid=497)[0m GPU available: False, used: False
[2m[36m(pid=497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=497)[0m 
[2m[36m(pid=497)[0m   | Name      | Type              | Params
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 12.0 K    Trainable params
[2m[36m(pid=497)[0m 0         Non-trainable params
[2m[36m(pid=497)[0m 12.0 K    Total params
[2m[36m(pid=50164)[0m time to fit was 248.43246269226074
[2m[36m(pid=50164)[0m GPU available: False, used: False
[2m[36m(pid=50164)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50164)[0m 
[2m[36m(pid=50164)[0m   | Name      | Type              | Params
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50164)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50164)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 12.0 K    Trainable params
[2m[36m(pid=50164)[0m 0         Non-trainable params
[2m[36m(pid=50164)[0m 12.0 K    Total params
[2m[36m(pid=26638)[0m time to fit was 388.33746695518494
[2m[36m(pid=26638)[0m GPU available: False, used: False
[2m[36m(pid=26638)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26638)[0m 
[2m[36m(pid=26638)[0m   | Name      | Type              | Params
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26638)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26638)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26638)[0m ------------------------------------------------
[2m[36m(pid=26638)[0m 12.0 K    Trainable params
[2m[36m(pid=26638)[0m 0         Non-trainable params
[2m[36m(pid=26638)[0m 12.0 K    Total params
[2m[36m(pid=43203)[0m time to fit was 1046.9228384494781
[2m[36m(pid=43203)[0m Finished run with seed 0 - lr 0.01 - sec_lr 0.1 - bs 32 - mean val auc: 0.910119640827179
Result for _inner_e98d6_00065:
  auc: 0.910119640827179
  date: 2021-03-18_01-21-54
  done: false
  experiment_id: bb39e8c8fd0348c5b722ad1dafbe0ec4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43203
  time_since_restore: 3454.8045489788055
  time_this_iter_s: 3454.8045489788055
  time_total_s: 3454.8045489788055
  timestamp: 1616026914
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00065
  
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 99/180 (1 PENDING, 26 RUNNING, 72 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00098 | PENDING    |       |          256 |     0 | 0.01  |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 79 more trials not shown (16 RUNNING, 62 TERMINATED)


Result for _inner_e98d6_00065:
  auc: 0.910119640827179
  date: 2021-03-18_01-21-54
  done: true
  experiment_id: bb39e8c8fd0348c5b722ad1dafbe0ec4
  experiment_tag: 65_batch_size=32,eta=0.0,lr=0.01,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43203
  time_since_restore: 3454.8045489788055
  time_this_iter_s: 3454.8045489788055
  time_total_s: 3454.8045489788055
  timestamp: 1616026914
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00065
  
[2m[36m(pid=9700)[0m time to fit was 258.7702920436859
Result for _inner_e98d6_00087:
  auc: 0.6943488597869873
  date: 2021-03-18_01-22-00
  done: false
  experiment_id: ff25137d7864461fb96e2ceba7bf6ce6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9700
  time_since_restore: 1252.1496436595917
  time_this_iter_s: 1252.1496436595917
  time_total_s: 1252.1496436595917
  timestamp: 1616026920
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00087
  
[2m[36m(pid=9700)[0m Finished run with seed 0 - lr 5 - sec_lr 0.1 - bs 128 - mean val auc: 0.6943488597869873
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 100/180 (1 PENDING, 26 RUNNING, 73 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00099 | PENDING    |       |          512 |     0 | 0.01  |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 80 more trials not shown (16 RUNNING, 63 TERMINATED)


Result for _inner_e98d6_00087:
  auc: 0.6943488597869873
  date: 2021-03-18_01-22-00
  done: true
  experiment_id: ff25137d7864461fb96e2ceba7bf6ce6
  experiment_tag: 87_batch_size=128,eta=0.0,lr=5,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9700
  time_since_restore: 1252.1496436595917
  time_this_iter_s: 1252.1496436595917
  time_total_s: 1252.1496436595917
  timestamp: 1616026920
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00087
  
[2m[36m(pid=14933)[0m Starting run with seed 0 - lr 0.01 - sec_lr 1 - bs 256
[2m[36m(pid=14933)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=14933)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=14933)[0m GPU available: False, used: False
[2m[36m(pid=14933)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14933)[0m 
[2m[36m(pid=14933)[0m   | Name      | Type              | Params
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14933)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14933)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 12.0 K    Trainable params
[2m[36m(pid=14933)[0m 0         Non-trainable params
[2m[36m(pid=14933)[0m 12.0 K    Total params
[2m[36m(pid=14933)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14933)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14933)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14933)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14933)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=14933)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15207)[0m Starting run with seed 0 - lr 0.01 - sec_lr 1 - bs 512
[2m[36m(pid=15207)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15207)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=15207)[0m GPU available: False, used: False
[2m[36m(pid=15207)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15207)[0m 
[2m[36m(pid=15207)[0m   | Name      | Type              | Params
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15207)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15207)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 12.0 K    Trainable params
[2m[36m(pid=15207)[0m 0         Non-trainable params
[2m[36m(pid=15207)[0m 12.0 K    Total params
[2m[36m(pid=15207)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15207)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15207)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15207)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15207)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=15207)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3557)[0m time to fit was 165.55614829063416
[2m[36m(pid=3557)[0m GPU available: False, used: False
[2m[36m(pid=3557)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3557)[0m 
[2m[36m(pid=3557)[0m   | Name      | Type              | Params
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3557)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3557)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 12.0 K    Trainable params
[2m[36m(pid=3557)[0m 0         Non-trainable params
[2m[36m(pid=3557)[0m 12.0 K    Total params
[2m[36m(pid=30253)[0m time to fit was 538.0142202377319
[2m[36m(pid=30253)[0m GPU available: False, used: False
[2m[36m(pid=30253)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30253)[0m 
[2m[36m(pid=30253)[0m   | Name      | Type              | Params
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30253)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30253)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 12.0 K    Trainable params
[2m[36m(pid=30253)[0m 0         Non-trainable params
[2m[36m(pid=30253)[0m 12.0 K    Total params
[2m[36m(pid=31590)[0m time to fit was 324.9017655849457
[2m[36m(pid=31590)[0m GPU available: False, used: False
[2m[36m(pid=31590)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31590)[0m 
[2m[36m(pid=31590)[0m   | Name      | Type              | Params
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31590)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31590)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 12.0 K    Trainable params
[2m[36m(pid=31590)[0m 0         Non-trainable params
[2m[36m(pid=31590)[0m 12.0 K    Total params
[2m[36m(pid=50164)[0m time to fit was 82.79288077354431
[2m[36m(pid=50164)[0m GPU available: False, used: False
[2m[36m(pid=50164)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50164)[0m 
[2m[36m(pid=50164)[0m   | Name      | Type              | Params
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50164)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50164)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50164)[0m ------------------------------------------------
[2m[36m(pid=50164)[0m 12.0 K    Trainable params
[2m[36m(pid=50164)[0m 0         Non-trainable params
[2m[36m(pid=50164)[0m 12.0 K    Total params
[2m[36m(pid=52147)[0m time to fit was 620.0715026855469
[2m[36m(pid=52147)[0m GPU available: False, used: False
[2m[36m(pid=52147)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m 
[2m[36m(pid=52147)[0m   | Name      | Type              | Params
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=52147)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=52147)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=52147)[0m ------------------------------------------------
[2m[36m(pid=52147)[0m 12.0 K    Trainable params
[2m[36m(pid=52147)[0m 0         Non-trainable params
[2m[36m(pid=52147)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m time to fit was 225.36880016326904
[2m[36m(pid=497)[0m GPU available: False, used: False
[2m[36m(pid=497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=497)[0m 
[2m[36m(pid=497)[0m   | Name      | Type              | Params
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 12.0 K    Trainable params
[2m[36m(pid=497)[0m 0         Non-trainable params
[2m[36m(pid=497)[0m 12.0 K    Total params
[2m[36m(pid=14933)[0m time to fit was 111.6126708984375
[2m[36m(pid=14933)[0m GPU available: False, used: False
[2m[36m(pid=14933)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14933)[0m 
[2m[36m(pid=14933)[0m   | Name      | Type              | Params
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14933)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14933)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 12.0 K    Trainable params
[2m[36m(pid=14933)[0m 0         Non-trainable params
[2m[36m(pid=14933)[0m 12.0 K    Total params
[2m[36m(pid=42052)[0m time to fit was 295.266982793808
[2m[36m(pid=42052)[0m GPU available: False, used: False
[2m[36m(pid=42052)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=42052)[0m 
[2m[36m(pid=42052)[0m   | Name      | Type              | Params
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=42052)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=42052)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 12.0 K    Trainable params
[2m[36m(pid=42052)[0m 0         Non-trainable params
[2m[36m(pid=42052)[0m 12.0 K    Total params
[2m[36m(pid=50164)[0m time to fit was 133.09601712226868
Result for _inner_e98d6_00094:
  auc: 0.8479088068008422
  date: 2021-03-18_01-24-54
  done: false
  experiment_id: eddb57a646fd43198efd76bfa1c7a074
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 50164
  time_since_restore: 633.5432748794556
  time_this_iter_s: 633.5432748794556
  time_total_s: 633.5432748794556
  timestamp: 1616027094
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00094
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 101/180 (1 PENDING, 26 RUNNING, 74 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00100 | PENDING    |       |           32 |     0 | 0.1   |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 81 more trials not shown (16 RUNNING, 64 TERMINATED)


[2m[36m(pid=50164)[0m Finished run with seed 0 - lr 0.001 - sec_lr 1 - bs 512 - mean val auc: 0.8479088068008422
Result for _inner_e98d6_00094:
  auc: 0.8479088068008422
  date: 2021-03-18_01-24-54
  done: true
  experiment_id: eddb57a646fd43198efd76bfa1c7a074
  experiment_tag: 94_batch_size=512,eta=0.0,lr=0.001,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 50164
  time_since_restore: 633.5432748794556
  time_this_iter_s: 633.5432748794556
  time_total_s: 633.5432748794556
  timestamp: 1616027094
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00094
  
[2m[36m(pid=51143)[0m time to fit was 614.3113050460815
[2m[36m(pid=51143)[0m GPU available: False, used: False
[2m[36m(pid=51143)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51143)[0m 
[2m[36m(pid=51143)[0m   | Name      | Type              | Params
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51143)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51143)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 12.0 K    Trainable params
[2m[36m(pid=51143)[0m 0         Non-trainable params
[2m[36m(pid=51143)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m Starting run with seed 0 - lr 0.1 - sec_lr 1 - bs 32
[2m[36m(pid=22450)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22450)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=22450)[0m GPU available: False, used: False
[2m[36m(pid=22450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22450)[0m 
[2m[36m(pid=22450)[0m   | Name      | Type              | Params
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 12.0 K    Trainable params
[2m[36m(pid=22450)[0m 0         Non-trainable params
[2m[36m(pid=22450)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=22450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3557)[0m time to fit was 193.8445427417755
[2m[36m(pid=3557)[0m GPU available: False, used: False
[2m[36m(pid=3557)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3557)[0m 
[2m[36m(pid=3557)[0m   | Name      | Type              | Params
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3557)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3557)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 12.0 K    Trainable params
[2m[36m(pid=3557)[0m 0         Non-trainable params
[2m[36m(pid=3557)[0m 12.0 K    Total params
[2m[36m(pid=38965)[0m time to fit was 467.9101836681366
Result for _inner_e98d6_00075:
  auc: 0.8898996829986572
  date: 2021-03-18_01-25-50
  done: false
  experiment_id: c1c0628f8f514615970a79c03ffd6db7
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 38965
  time_since_restore: 2395.2896540164948
  time_this_iter_s: 2395.2896540164948
  time_total_s: 2395.2896540164948
  timestamp: 1616027150
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00075
  
[2m[36m(pid=38965)[0m Finished run with seed 0 - lr 1 - sec_lr 0.1 - bs 32 - mean val auc: 0.8898996829986572
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 102/180 (1 PENDING, 26 RUNNING, 75 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00101 | PENDING    |       |           64 |     0 | 0.1   |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 82 more trials not shown (16 RUNNING, 65 TERMINATED)


Result for _inner_e98d6_00075:
  auc: 0.8898996829986572
  date: 2021-03-18_01-25-50
  done: true
  experiment_id: c1c0628f8f514615970a79c03ffd6db7
  experiment_tag: 75_batch_size=32,eta=0.0,lr=1,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 38965
  time_since_restore: 2395.2896540164948
  time_this_iter_s: 2395.2896540164948
  time_total_s: 2395.2896540164948
  timestamp: 1616027150
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00075
  
2021-03-18 01:25:51,801	WARNING worker.py:1034 -- The actor or task with ID fffffffffffffffffcf981a001000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=24654)[0m Starting run with seed 0 - lr 0.1 - sec_lr 1 - bs 64
[2m[36m(pid=24654)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=24654)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=24654)[0m GPU available: False, used: False
[2m[36m(pid=24654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=24654)[0m 
[2m[36m(pid=24654)[0m   | Name      | Type              | Params
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=24654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=24654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 12.0 K    Trainable params
[2m[36m(pid=24654)[0m 0         Non-trainable params
[2m[36m(pid=24654)[0m 12.0 K    Total params
[2m[36m(pid=24654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=24654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=24654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=24654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=24654)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=24654)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=31590)[0m time to fit was 243.76408505439758
[2m[36m(pid=31590)[0m GPU available: False, used: False
[2m[36m(pid=31590)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31590)[0m 
[2m[36m(pid=31590)[0m   | Name      | Type              | Params
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31590)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31590)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31590)[0m ------------------------------------------------
[2m[36m(pid=31590)[0m 12.0 K    Trainable params
[2m[36m(pid=31590)[0m 0         Non-trainable params
[2m[36m(pid=31590)[0m 12.0 K    Total params
[2m[36m(pid=15207)[0m time to fit was 305.50991201400757
[2m[36m(pid=15207)[0m GPU available: False, used: False
[2m[36m(pid=15207)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15207)[0m 
[2m[36m(pid=15207)[0m   | Name      | Type              | Params
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15207)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15207)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 12.0 K    Trainable params
[2m[36m(pid=15207)[0m 0         Non-trainable params
[2m[36m(pid=15207)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m time to fit was 222.06128454208374
[2m[36m(pid=497)[0m GPU available: False, used: False
[2m[36m(pid=497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=497)[0m 
[2m[36m(pid=497)[0m   | Name      | Type              | Params
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 12.0 K    Trainable params
[2m[36m(pid=497)[0m 0         Non-trainable params
[2m[36m(pid=497)[0m 12.0 K    Total params
[2m[36m(pid=42052)[0m time to fit was 167.43375945091248
[2m[36m(pid=42052)[0m GPU available: False, used: False
[2m[36m(pid=42052)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=42052)[0m 
[2m[36m(pid=42052)[0m   | Name      | Type              | Params
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=42052)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=42052)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=42052)[0m ------------------------------------------------
[2m[36m(pid=42052)[0m 12.0 K    Trainable params
[2m[36m(pid=42052)[0m 0         Non-trainable params
[2m[36m(pid=42052)[0m 12.0 K    Total params
[2m[36m(pid=31069)[0m time to fit was 4137.90481877327
[2m[36m(pid=31069)[0m GPU available: False, used: False
[2m[36m(pid=31069)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31069)[0m 
[2m[36m(pid=31069)[0m   | Name      | Type              | Params
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31069)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31069)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 12.0 K    Trainable params
[2m[36m(pid=31069)[0m 0         Non-trainable params
[2m[36m(pid=31069)[0m 12.0 K    Total params
[2m[36m(pid=14933)[0m time to fit was 233.48514795303345
[2m[36m(pid=14933)[0m GPU available: False, used: False
[2m[36m(pid=14933)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14933)[0m 
[2m[36m(pid=14933)[0m   | Name      | Type              | Params
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14933)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14933)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 12.0 K    Trainable params
[2m[36m(pid=14933)[0m 0         Non-trainable params
[2m[36m(pid=14933)[0m 12.0 K    Total params
[2m[36m(pid=3557)[0m time to fit was 157.1842336654663
[2m[36m(pid=3557)[0m GPU available: False, used: False
[2m[36m(pid=3557)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3557)[0m 
[2m[36m(pid=3557)[0m   | Name      | Type              | Params
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3557)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3557)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3557)[0m ------------------------------------------------
[2m[36m(pid=3557)[0m 12.0 K    Trainable params
[2m[36m(pid=3557)[0m 0         Non-trainable params
[2m[36m(pid=3557)[0m 12.0 K    Total params
[2m[36m(pid=15207)[0m time to fit was 94.261545419693
[2m[36m(pid=15207)[0m GPU available: False, used: False
[2m[36m(pid=15207)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15207)[0m 
[2m[36m(pid=15207)[0m   | Name      | Type              | Params
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15207)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15207)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 12.0 K    Trainable params
[2m[36m(pid=15207)[0m 0         Non-trainable params
[2m[36m(pid=15207)[0m 12.0 K    Total params
[2m[36m(pid=14933)[0m time to fit was 85.2560670375824
[2m[36m(pid=14933)[0m GPU available: False, used: False
[2m[36m(pid=14933)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14933)[0m 
[2m[36m(pid=14933)[0m   | Name      | Type              | Params
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14933)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14933)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 12.0 K    Trainable params
[2m[36m(pid=14933)[0m 0         Non-trainable params
[2m[36m(pid=14933)[0m 12.0 K    Total params
[2m[36m(pid=30253)[0m time to fit was 426.04323291778564
[2m[36m(pid=30253)[0m GPU available: False, used: False
[2m[36m(pid=30253)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30253)[0m 
[2m[36m(pid=30253)[0m   | Name      | Type              | Params
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30253)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30253)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 12.0 K    Trainable params
[2m[36m(pid=30253)[0m 0         Non-trainable params
[2m[36m(pid=30253)[0m 12.0 K    Total params
[2m[36m(pid=24654)[0m time to fit was 217.1786606311798
[2m[36m(pid=24654)[0m GPU available: False, used: False
[2m[36m(pid=24654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=24654)[0m 
[2m[36m(pid=24654)[0m   | Name      | Type              | Params
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=24654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=24654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 12.0 K    Trainable params
[2m[36m(pid=24654)[0m 0         Non-trainable params
[2m[36m(pid=24654)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m time to fit was 778.4211981296539
[2m[36m(pid=9705)[0m GPU available: False, used: False
[2m[36m(pid=9705)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9705)[0m 
[2m[36m(pid=9705)[0m   | Name      | Type              | Params
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9705)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9705)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 12.0 K    Trainable params
[2m[36m(pid=9705)[0m 0         Non-trainable params
[2m[36m(pid=9705)[0m 12.0 K    Total params
[2m[36m(pid=15207)[0m time to fit was 98.40722560882568
[2m[36m(pid=15207)[0m GPU available: False, used: False
[2m[36m(pid=15207)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15207)[0m 
[2m[36m(pid=15207)[0m   | Name      | Type              | Params
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15207)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15207)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 12.0 K    Trainable params
[2m[36m(pid=15207)[0m 0         Non-trainable params
[2m[36m(pid=15207)[0m 12.0 K    Total params
[2m[36m(pid=21672)[0m time to fit was 5842.902515172958
[2m[36m(pid=21672)[0m GPU available: False, used: False
[2m[36m(pid=21672)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21672)[0m 
[2m[36m(pid=21672)[0m   | Name      | Type              | Params
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21672)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21672)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 12.0 K    Trainable params
[2m[36m(pid=21672)[0m 0         Non-trainable params
[2m[36m(pid=21672)[0m 12.0 K    Total params
[2m[36m(pid=3557)[0m time to fit was 157.91373777389526
Result for _inner_e98d6_00097:
  auc: 0.9073807597160339
  date: 2021-03-18_01-30-47
  done: false
  experiment_id: 13f6c1e42f1545fc833bcb0e534f6df8
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3557
  time_since_restore: 820.7378723621368
  time_this_iter_s: 820.7378723621368
  time_total_s: 820.7378723621368
  timestamp: 1616027447
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00097
  
[2m[36m(pid=3557)[0m Finished run with seed 0 - lr 0.01 - sec_lr 1 - bs 128 - mean val auc: 0.9073807597160339
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 103/180 (1 PENDING, 26 RUNNING, 76 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00102 | PENDING    |       |          128 |     0 | 0.1   |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 83 more trials not shown (16 RUNNING, 66 TERMINATED)


Result for _inner_e98d6_00097:
  auc: 0.9073807597160339
  date: 2021-03-18_01-30-47
  done: true
  experiment_id: 13f6c1e42f1545fc833bcb0e534f6df8
  experiment_tag: 97_batch_size=128,eta=0.0,lr=0.01,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3557
  time_since_restore: 820.7378723621368
  time_this_iter_s: 820.7378723621368
  time_total_s: 820.7378723621368
  timestamp: 1616027447
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00097
  
[2m[36m(pid=31590)[0m time to fit was 244.09266901016235
Result for _inner_e98d6_00091:
  auc: 0.8671264767646789
  date: 2021-03-18_01-30-48
  done: false
  experiment_id: 0ba377020aa84eb3be7192547b39c601
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 31590
  time_since_restore: 1500.446988582611
  time_this_iter_s: 1500.446988582611
  time_total_s: 1500.446988582611
  timestamp: 1616027448
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00091
  
[2m[36m(pid=31590)[0m Finished run with seed 0 - lr 0.001 - sec_lr 1 - bs 64 - mean val auc: 0.8671264767646789
Result for _inner_e98d6_00091:
  auc: 0.8671264767646789
  date: 2021-03-18_01-30-48
  done: true
  experiment_id: 0ba377020aa84eb3be7192547b39c601
  experiment_tag: 91_batch_size=64,eta=0.0,lr=0.001,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 31590
  time_since_restore: 1500.446988582611
  time_this_iter_s: 1500.446988582611
  time_total_s: 1500.446988582611
  timestamp: 1616027448
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00091
  
[2m[36m(pid=26638)[0m time to fit was 539.5247535705566
Result for _inner_e98d6_00061:
  auc: 0.8890384793281555
  date: 2021-03-18_01-30-50
  done: false
  experiment_id: bb04aa025d834d2cbb702d2f4b5fcfba
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26638
  time_since_restore: 4448.778505086899
  time_this_iter_s: 4448.778505086899
  time_total_s: 4448.778505086899
  timestamp: 1616027450
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00061
  
[2m[36m(pid=26638)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 64 - mean val auc: 0.8890384793281555
Result for _inner_e98d6_00061:
  auc: 0.8890384793281555
  date: 2021-03-18_01-30-50
  done: true
  experiment_id: bb04aa025d834d2cbb702d2f4b5fcfba
  experiment_tag: 61_batch_size=64,eta=0.0,lr=0.001,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26638
  time_since_restore: 4448.778505086899
  time_this_iter_s: 4448.778505086899
  time_total_s: 4448.778505086899
  timestamp: 1616027450
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00061
  
[2m[36m(pid=36028)[0m Starting run with seed 0 - lr 0.1 - sec_lr 1 - bs 512
[2m[36m(pid=36028)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36028)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=35963)[0m Starting run with seed 0 - lr 0.1 - sec_lr 1 - bs 128
[2m[36m(pid=36022)[0m Starting run with seed 0 - lr 0.1 - sec_lr 1 - bs 256
[2m[36m(pid=36028)[0m GPU available: False, used: False
[2m[36m(pid=36028)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35963)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35963)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36022)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36022)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36028)[0m 
[2m[36m(pid=36028)[0m   | Name      | Type              | Params
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36028)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36028)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 12.0 K    Trainable params
[2m[36m(pid=36028)[0m 0         Non-trainable params
[2m[36m(pid=36028)[0m 12.0 K    Total params
[2m[36m(pid=36028)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36028)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35963)[0m GPU available: False, used: False
[2m[36m(pid=35963)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36022)[0m GPU available: False, used: False
[2m[36m(pid=36022)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=52147)[0m time to fit was 466.35463213920593
[2m[36m(pid=35963)[0m 
[2m[36m(pid=35963)[0m   | Name      | Type              | Params
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35963)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35963)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 12.0 K    Trainable params
[2m[36m(pid=35963)[0m 0         Non-trainable params
[2m[36m(pid=35963)[0m 12.0 K    Total params
[2m[36m(pid=35963)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35963)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36022)[0m 
[2m[36m(pid=36022)[0m   | Name      | Type              | Params
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36022)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36022)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 12.0 K    Trainable params
[2m[36m(pid=36022)[0m 0         Non-trainable params
[2m[36m(pid=36022)[0m 12.0 K    Total params
[2m[36m(pid=36022)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36022)[0m   warnings.warn(*args, **kwargs)
Result for _inner_e98d6_00080:
  auc: 0.7620126605033875
  date: 2021-03-18_01-31-00
  done: false
  experiment_id: 28fbbbf77e1a439995e48c333fe8ab1e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 52147
  time_since_restore: 2363.759441137314
  time_this_iter_s: 2363.759441137314
  time_total_s: 2363.759441137314
  timestamp: 1616027460
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00080
  
[2m[36m(pid=52147)[0m Finished run with seed 0 - lr 2 - sec_lr 0.1 - bs 32 - mean val auc: 0.7620126605033875
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 106/180 (1 PENDING, 26 RUNNING, 79 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00105 | PENDING    |       |           32 |     0 | 1     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 86 more trials not shown (16 RUNNING, 69 TERMINATED)


Result for _inner_e98d6_00080:
  auc: 0.7620126605033875
  date: 2021-03-18_01-31-00
  done: true
  experiment_id: 28fbbbf77e1a439995e48c333fe8ab1e
  experiment_tag: 80_batch_size=32,eta=0.0,lr=2,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 52147
  time_since_restore: 2363.759441137314
  time_this_iter_s: 2363.759441137314
  time_total_s: 2363.759441137314
  timestamp: 1616027460
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00080
  
[2m[36m(pid=36028)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36028)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36022)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36022)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35963)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35963)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36022)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36022)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35963)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=35963)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36028)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36028)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=42052)[0m time to fit was 227.48297548294067
Result for _inner_e98d6_00092:
  auc: 0.873279070854187
  date: 2021-03-18_01-31-08
  done: false
  experiment_id: 2e5069fedf00452dad6b3d1e3514fdae
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 42052
  time_since_restore: 1230.2823038101196
  time_this_iter_s: 1230.2823038101196
  time_total_s: 1230.2823038101196
  timestamp: 1616027468
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00092
  
[2m[36m(pid=42052)[0m Finished run with seed 0 - lr 0.001 - sec_lr 1 - bs 128 - mean val auc: 0.873279070854187
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 107/180 (1 PENDING, 26 RUNNING, 80 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00106 | PENDING    |       |           64 |     0 | 1     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 87 more trials not shown (16 RUNNING, 70 TERMINATED)


Result for _inner_e98d6_00092:
  auc: 0.873279070854187
  date: 2021-03-18_01-31-08
  done: true
  experiment_id: 2e5069fedf00452dad6b3d1e3514fdae
  experiment_tag: 92_batch_size=128,eta=0.0,lr=0.001,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 42052
  time_since_restore: 1230.2823038101196
  time_this_iter_s: 1230.2823038101196
  time_total_s: 1230.2823038101196
  timestamp: 1616027468
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00092
  
[2m[36m(pid=36194)[0m Starting run with seed 0 - lr 1 - sec_lr 1 - bs 32
[2m[36m(pid=36194)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36194)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36194)[0m GPU available: False, used: False
[2m[36m(pid=36194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36194)[0m 
[2m[36m(pid=36194)[0m   | Name      | Type              | Params
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 12.0 K    Trainable params
[2m[36m(pid=36194)[0m 0         Non-trainable params
[2m[36m(pid=36194)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36194)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36194)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36174)[0m Starting run with seed 0 - lr 1 - sec_lr 1 - bs 64
[2m[36m(pid=36174)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36174)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36174)[0m GPU available: False, used: False
[2m[36m(pid=36174)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36174)[0m 
[2m[36m(pid=36174)[0m   | Name      | Type              | Params
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36174)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36174)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 12.0 K    Trainable params
[2m[36m(pid=36174)[0m 0         Non-trainable params
[2m[36m(pid=36174)[0m 12.0 K    Total params
[2m[36m(pid=36174)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36174)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36174)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36174)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36174)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36174)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15207)[0m time to fit was 73.51531171798706
[2m[36m(pid=15207)[0m GPU available: False, used: False
[2m[36m(pid=15207)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15207)[0m 
[2m[36m(pid=15207)[0m   | Name      | Type              | Params
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15207)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15207)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15207)[0m ------------------------------------------------
[2m[36m(pid=15207)[0m 12.0 K    Trainable params
[2m[36m(pid=15207)[0m 0         Non-trainable params
[2m[36m(pid=15207)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m time to fit was 268.87638568878174
[2m[36m(pid=497)[0m GPU available: False, used: False
[2m[36m(pid=497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=497)[0m 
[2m[36m(pid=497)[0m   | Name      | Type              | Params
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=497)[0m ------------------------------------------------
[2m[36m(pid=497)[0m 12.0 K    Trainable params
[2m[36m(pid=497)[0m 0         Non-trainable params
[2m[36m(pid=497)[0m 12.0 K    Total params
[2m[36m(pid=51143)[0m time to fit was 423.9504506587982
[2m[36m(pid=51143)[0m GPU available: False, used: False
[2m[36m(pid=51143)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51143)[0m 
[2m[36m(pid=51143)[0m   | Name      | Type              | Params
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51143)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51143)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 12.0 K    Trainable params
[2m[36m(pid=51143)[0m 0         Non-trainable params
[2m[36m(pid=51143)[0m 12.0 K    Total params
[2m[36m(pid=36028)[0m time to fit was 72.58184552192688
[2m[36m(pid=36028)[0m GPU available: False, used: False
[2m[36m(pid=36028)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36028)[0m 
[2m[36m(pid=36028)[0m   | Name      | Type              | Params
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36028)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36028)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 12.0 K    Trainable params
[2m[36m(pid=36028)[0m 0         Non-trainable params
[2m[36m(pid=36028)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m time to fit was 428.79813742637634
[2m[36m(pid=22450)[0m GPU available: False, used: False
[2m[36m(pid=22450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22450)[0m 
[2m[36m(pid=22450)[0m   | Name      | Type              | Params
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 12.0 K    Trainable params
[2m[36m(pid=22450)[0m 0         Non-trainable params
[2m[36m(pid=22450)[0m 12.0 K    Total params
[2m[36m(pid=36022)[0m time to fit was 80.40770864486694
[2m[36m(pid=36022)[0m GPU available: False, used: False
[2m[36m(pid=36022)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36022)[0m 
[2m[36m(pid=36022)[0m   | Name      | Type              | Params
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36022)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36022)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 12.0 K    Trainable params
[2m[36m(pid=36022)[0m 0         Non-trainable params
[2m[36m(pid=36022)[0m 12.0 K    Total params
[2m[36m(pid=31069)[0m time to fit was 301.3837389945984
[2m[36m(pid=31069)[0m GPU available: False, used: False
[2m[36m(pid=31069)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31069)[0m 
[2m[36m(pid=31069)[0m   | Name      | Type              | Params
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31069)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31069)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 12.0 K    Trainable params
[2m[36m(pid=31069)[0m 0         Non-trainable params
[2m[36m(pid=31069)[0m 12.0 K    Total params
[2m[36m(pid=14933)[0m time to fit was 224.73710703849792
[2m[36m(pid=14933)[0m GPU available: False, used: False
[2m[36m(pid=14933)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14933)[0m 
[2m[36m(pid=14933)[0m   | Name      | Type              | Params
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14933)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14933)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14933)[0m ------------------------------------------------
[2m[36m(pid=14933)[0m 12.0 K    Trainable params
[2m[36m(pid=14933)[0m 0         Non-trainable params
[2m[36m(pid=14933)[0m 12.0 K    Total params
[2m[36m(pid=36028)[0m time to fit was 61.22574019432068
[2m[36m(pid=36028)[0m GPU available: False, used: False
[2m[36m(pid=36028)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36028)[0m 
[2m[36m(pid=36028)[0m   | Name      | Type              | Params
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36028)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36028)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 12.0 K    Trainable params
[2m[36m(pid=36028)[0m 0         Non-trainable params
[2m[36m(pid=36028)[0m 12.0 K    Total params
[2m[36m(pid=35963)[0m time to fit was 137.37500023841858
[2m[36m(pid=35963)[0m GPU available: False, used: False
[2m[36m(pid=35963)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35963)[0m 
[2m[36m(pid=35963)[0m   | Name      | Type              | Params
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35963)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35963)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 12.0 K    Trainable params
[2m[36m(pid=35963)[0m 0         Non-trainable params
[2m[36m(pid=35963)[0m 12.0 K    Total params
[2m[36m(pid=24654)[0m time to fit was 225.24648547172546
[2m[36m(pid=24654)[0m GPU available: False, used: False
[2m[36m(pid=24654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=24654)[0m 
[2m[36m(pid=24654)[0m   | Name      | Type              | Params
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=24654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=24654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 12.0 K    Trainable params
[2m[36m(pid=24654)[0m 0         Non-trainable params
[2m[36m(pid=24654)[0m 12.0 K    Total params
[2m[36m(pid=36022)[0m time to fit was 81.16506695747375
[2m[36m(pid=36022)[0m GPU available: False, used: False
[2m[36m(pid=36022)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36022)[0m 
[2m[36m(pid=36022)[0m   | Name      | Type              | Params
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36022)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36022)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 12.0 K    Trainable params
[2m[36m(pid=36022)[0m 0         Non-trainable params
[2m[36m(pid=36022)[0m 12.0 K    Total params
[2m[36m(pid=36028)[0m time to fit was 66.20881056785583
[2m[36m(pid=36028)[0m GPU available: False, used: False
[2m[36m(pid=36028)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36028)[0m 
[2m[36m(pid=36028)[0m   | Name      | Type              | Params
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36028)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36028)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 12.0 K    Trainable params
[2m[36m(pid=36028)[0m 0         Non-trainable params
[2m[36m(pid=36028)[0m 12.0 K    Total params
[2m[36m(pid=36022)[0m time to fit was 80.23032307624817
[2m[36m(pid=36022)[0m GPU available: False, used: False
[2m[36m(pid=36022)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36022)[0m 
[2m[36m(pid=36022)[0m   | Name      | Type              | Params
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36022)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36022)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 12.0 K    Trainable params
[2m[36m(pid=36022)[0m 0         Non-trainable params
[2m[36m(pid=36022)[0m 12.0 K    Total params
[2m[36m(pid=15207)[0m time to fit was 208.11851143836975
Result for _inner_e98d6_00099:
  auc: 0.9071042895317077
  date: 2021-03-18_01-35-13
  done: false
  experiment_id: 580aa03904c14939b929606985fae747
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15207
  time_since_restore: 781.1205444335938
  time_this_iter_s: 781.1205444335938
  time_total_s: 781.1205444335938
  timestamp: 1616027713
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00099
  
[2m[36m(pid=15207)[0m Finished run with seed 0 - lr 0.01 - sec_lr 1 - bs 512 - mean val auc: 0.9071042895317077
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 108/180 (1 PENDING, 26 RUNNING, 81 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00107 | PENDING    |       |          128 |     0 | 1     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 88 more trials not shown (16 RUNNING, 71 TERMINATED)


Result for _inner_e98d6_00099:
  auc: 0.9071042895317077
  date: 2021-03-18_01-35-13
  done: true
  experiment_id: 580aa03904c14939b929606985fae747
  experiment_tag: 99_batch_size=512,eta=0.0,lr=0.01,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15207
  time_since_restore: 781.1205444335938
  time_this_iter_s: 781.1205444335938
  time_total_s: 781.1205444335938
  timestamp: 1616027713
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00099
  
[2m[36m(pid=36028)[0m time to fit was 60.888235330581665
[2m[36m(pid=36028)[0m GPU available: False, used: False
[2m[36m(pid=36028)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36028)[0m 
[2m[36m(pid=36028)[0m   | Name      | Type              | Params
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36028)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36028)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36028)[0m ------------------------------------------------
[2m[36m(pid=36028)[0m 12.0 K    Trainable params
[2m[36m(pid=36028)[0m 0         Non-trainable params
[2m[36m(pid=36028)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m Starting run with seed 0 - lr 1 - sec_lr 1 - bs 128
[2m[36m(pid=36173)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36173)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36173)[0m GPU available: False, used: False
[2m[36m(pid=36173)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m   | Name      | Type              | Params
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36173)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36173)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 12.0 K    Trainable params
[2m[36m(pid=36173)[0m 0         Non-trainable params
[2m[36m(pid=36173)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36173)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35963)[0m time to fit was 125.57309174537659
[2m[36m(pid=35963)[0m GPU available: False, used: False
[2m[36m(pid=35963)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35963)[0m 
[2m[36m(pid=35963)[0m   | Name      | Type              | Params
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35963)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35963)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 12.0 K    Trainable params
[2m[36m(pid=35963)[0m 0         Non-trainable params
[2m[36m(pid=35963)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36173)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36173)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36173)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36174)[0m time to fit was 249.77067804336548
[2m[36m(pid=36174)[0m GPU available: False, used: False
[2m[36m(pid=36174)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36174)[0m 
[2m[36m(pid=36174)[0m   | Name      | Type              | Params
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36174)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36174)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 12.0 K    Trainable params
[2m[36m(pid=36174)[0m 0         Non-trainable params
[2m[36m(pid=36174)[0m 12.0 K    Total params
[2m[36m(pid=497)[0m time to fit was 253.96387577056885
Result for _inner_e98d6_00096:
  auc: 0.9057268619537353
  date: 2021-03-18_01-36-03
  done: false
  experiment_id: 171faa27f23b4c93b399a273e725c306
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 497
  time_since_restore: 1214.731246471405
  time_this_iter_s: 1214.731246471405
  time_total_s: 1214.731246471405
  timestamp: 1616027763
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00096
  
[2m[36m(pid=497)[0m Finished run with seed 0 - lr 0.01 - sec_lr 1 - bs 64 - mean val auc: 0.9057268619537353
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 109/180 (1 PENDING, 26 RUNNING, 82 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00108 | PENDING    |       |          256 |     0 | 1     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 89 more trials not shown (16 RUNNING, 72 TERMINATED)


Result for _inner_e98d6_00096:
  auc: 0.9057268619537353
  date: 2021-03-18_01-36-03
  done: true
  experiment_id: 171faa27f23b4c93b399a273e725c306
  experiment_tag: 96_batch_size=64,eta=0.0,lr=0.01,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 497
  time_since_restore: 1214.731246471405
  time_this_iter_s: 1214.731246471405
  time_total_s: 1214.731246471405
  timestamp: 1616027763
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00096
  
[2m[36m(pid=36171)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36171)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36171)[0m Starting run with seed 0 - lr 1 - sec_lr 1 - bs 256
[2m[36m(pid=36171)[0m GPU available: False, used: False
[2m[36m(pid=36171)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36171)[0m 
[2m[36m(pid=36171)[0m   | Name      | Type              | Params
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36171)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36171)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 12.0 K    Trainable params
[2m[36m(pid=36171)[0m 0         Non-trainable params
[2m[36m(pid=36171)[0m 12.0 K    Total params
[2m[36m(pid=36171)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36171)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36171)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36171)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36171)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36171)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14933)[0m time to fit was 192.00984859466553
Result for _inner_e98d6_00098:
  auc: 0.9070510268211365
  date: 2021-03-18_01-36-15
  done: false
  experiment_id: ecd77e3cfa964f67a127c9ff61d4010c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14933
  time_since_restore: 848.512305021286
  time_this_iter_s: 848.512305021286
  time_total_s: 848.512305021286
  timestamp: 1616027775
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00098
  
[2m[36m(pid=14933)[0m Finished run with seed 0 - lr 0.01 - sec_lr 1 - bs 256 - mean val auc: 0.9070510268211365
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 110/180 (1 PENDING, 26 RUNNING, 83 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00109 | PENDING    |       |          512 |     0 | 1     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 90 more trials not shown (16 RUNNING, 73 TERMINATED)


Result for _inner_e98d6_00098:
  auc: 0.9070510268211365
  date: 2021-03-18_01-36-15
  done: true
  experiment_id: ecd77e3cfa964f67a127c9ff61d4010c
  experiment_tag: 98_batch_size=256,eta=0.0,lr=0.01,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14933
  time_since_restore: 848.512305021286
  time_this_iter_s: 848.512305021286
  time_total_s: 848.512305021286
  timestamp: 1616027775
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00098
  
[2m[36m(pid=36028)[0m time to fit was 59.906827449798584
[2m[36m(pid=36028)[0m Finished run with seed 0 - lr 0.1 - sec_lr 1 - bs 512 - mean val auc: 0.9113589763641358
Result for _inner_e98d6_00104:
  auc: 0.9113589763641358
  date: 2021-03-18_01-36-22
  done: false
  experiment_id: 96e0a3f9501f485aa2d4a7938ad44601
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36028
  time_since_restore: 322.10351157188416
  time_this_iter_s: 322.10351157188416
  time_total_s: 322.10351157188416
  timestamp: 1616027782
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00104
  
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 111/180 (1 PENDING, 26 RUNNING, 84 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00110 | PENDING    |       |           32 |     0 | 2     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 91 more trials not shown (16 RUNNING, 74 TERMINATED)


Result for _inner_e98d6_00104:
  auc: 0.9113589763641358
  date: 2021-03-18_01-36-22
  done: true
  experiment_id: 96e0a3f9501f485aa2d4a7938ad44601
  experiment_tag: 104_batch_size=512,eta=0.0,lr=0.1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36028
  time_since_restore: 322.10351157188416
  time_this_iter_s: 322.10351157188416
  time_total_s: 322.10351157188416
  timestamp: 1616027782
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00104
  
[2m[36m(pid=36167)[0m Starting run with seed 0 - lr 1 - sec_lr 1 - bs 512
[2m[36m(pid=36167)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36167)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36167)[0m GPU available: False, used: False
[2m[36m(pid=36167)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36167)[0m 
[2m[36m(pid=36167)[0m   | Name      | Type              | Params
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36167)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36167)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 12.0 K    Trainable params
[2m[36m(pid=36167)[0m 0         Non-trainable params
[2m[36m(pid=36167)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36167)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36167)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36167)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36167)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36167)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36022)[0m time to fit was 88.25144696235657
[2m[36m(pid=36103)[0m Starting run with seed 0 - lr 2 - sec_lr 1 - bs 32
[2m[36m(pid=36103)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36103)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36103)[0m GPU available: False, used: False
[2m[36m(pid=36103)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36103)[0m 
[2m[36m(pid=36103)[0m   | Name      | Type              | Params
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36103)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36103)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 12.0 K    Trainable params
[2m[36m(pid=36103)[0m 0         Non-trainable params
[2m[36m(pid=36103)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36103)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36022)[0m GPU available: False, used: False
[2m[36m(pid=36022)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36022)[0m 
[2m[36m(pid=36022)[0m   | Name      | Type              | Params
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36022)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36022)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36022)[0m ------------------------------------------------
[2m[36m(pid=36022)[0m 12.0 K    Trainable params
[2m[36m(pid=36022)[0m 0         Non-trainable params
[2m[36m(pid=36022)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36103)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36103)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36103)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=24654)[0m time to fit was 224.39414525032043
[2m[36m(pid=24654)[0m GPU available: False, used: False
[2m[36m(pid=24654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=24654)[0m 
[2m[36m(pid=24654)[0m   | Name      | Type              | Params
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=24654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=24654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 12.0 K    Trainable params
[2m[36m(pid=24654)[0m 0         Non-trainable params
[2m[36m(pid=24654)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m time to fit was 60.62443566322327
[2m[36m(pid=36167)[0m GPU available: False, used: False
[2m[36m(pid=36167)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36167)[0m 
[2m[36m(pid=36167)[0m   | Name      | Type              | Params
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36167)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36167)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 12.0 K    Trainable params
[2m[36m(pid=36167)[0m 0         Non-trainable params
[2m[36m(pid=36167)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m time to fit was 418.53673219680786
[2m[36m(pid=9705)[0m GPU available: False, used: False
[2m[36m(pid=9705)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9705)[0m 
[2m[36m(pid=9705)[0m   | Name      | Type              | Params
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9705)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9705)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9705)[0m ------------------------------------------------
[2m[36m(pid=9705)[0m 12.0 K    Trainable params
[2m[36m(pid=9705)[0m 0         Non-trainable params
[2m[36m(pid=9705)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m time to fit was 125.51242351531982
[2m[36m(pid=36173)[0m GPU available: False, used: False
[2m[36m(pid=36173)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m   | Name      | Type              | Params
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36173)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36173)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 12.0 K    Trainable params
[2m[36m(pid=36173)[0m 0         Non-trainable params
[2m[36m(pid=36173)[0m 12.0 K    Total params
[2m[36m(pid=36171)[0m time to fit was 78.02835702896118
[2m[36m(pid=36171)[0m GPU available: False, used: False
[2m[36m(pid=36171)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36171)[0m 
[2m[36m(pid=36171)[0m   | Name      | Type              | Params
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36171)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36171)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 12.0 K    Trainable params
[2m[36m(pid=36171)[0m 0         Non-trainable params
[2m[36m(pid=36171)[0m 12.0 K    Total params
[2m[36m(pid=35963)[0m time to fit was 137.5409164428711
[2m[36m(pid=35963)[0m GPU available: False, used: False
[2m[36m(pid=35963)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35963)[0m 
[2m[36m(pid=35963)[0m   | Name      | Type              | Params
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35963)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35963)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 12.0 K    Trainable params
[2m[36m(pid=35963)[0m 0         Non-trainable params
[2m[36m(pid=35963)[0m 12.0 K    Total params
[2m[36m(pid=36022)[0m time to fit was 78.38147854804993
Result for _inner_e98d6_00103:
  auc: 0.9110669493675232
  date: 2021-03-18_01-37-50
  done: false
  experiment_id: 7b220b7f46ce4c6a8243229a8d57240c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36022
  time_since_restore: 409.8931095600128
  time_this_iter_s: 409.8931095600128
  time_total_s: 409.8931095600128
  timestamp: 1616027870
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00103
  
[2m[36m(pid=36022)[0m Finished run with seed 0 - lr 0.1 - sec_lr 1 - bs 256 - mean val auc: 0.9110669493675232
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 112/180 (1 PENDING, 26 RUNNING, 85 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00111 | PENDING    |       |           64 |     0 | 2     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 92 more trials not shown (16 RUNNING, 75 TERMINATED)


Result for _inner_e98d6_00103:
  auc: 0.9110669493675232
  date: 2021-03-18_01-37-50
  done: true
  experiment_id: 7b220b7f46ce4c6a8243229a8d57240c
  experiment_tag: 103_batch_size=256,eta=0.0,lr=0.1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36022
  time_since_restore: 409.8931095600128
  time_this_iter_s: 409.8931095600128
  time_total_s: 409.8931095600128
  timestamp: 1616027870
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00103
  
[2m[36m(pid=36034)[0m Starting run with seed 0 - lr 2 - sec_lr 1 - bs 64
[2m[36m(pid=36034)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36034)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36034)[0m GPU available: False, used: False
[2m[36m(pid=36034)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m   | Name      | Type              | Params
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36034)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36034)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 12.0 K    Trainable params
[2m[36m(pid=36034)[0m 0         Non-trainable params
[2m[36m(pid=36034)[0m 12.0 K    Total params
[2m[36m(pid=36034)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36034)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36034)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36034)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36034)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36034)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30253)[0m time to fit was 513.5512866973877
[2m[36m(pid=30253)[0m GPU available: False, used: False
[2m[36m(pid=30253)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30253)[0m 
[2m[36m(pid=30253)[0m   | Name      | Type              | Params
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30253)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30253)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30253)[0m ------------------------------------------------
[2m[36m(pid=30253)[0m 12.0 K    Trainable params
[2m[36m(pid=30253)[0m 0         Non-trainable params
[2m[36m(pid=30253)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m time to fit was 56.0843665599823
[2m[36m(pid=36167)[0m GPU available: False, used: False
[2m[36m(pid=36167)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36167)[0m 
[2m[36m(pid=36167)[0m   | Name      | Type              | Params
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36167)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36167)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 12.0 K    Trainable params
[2m[36m(pid=36167)[0m 0         Non-trainable params
[2m[36m(pid=36167)[0m 12.0 K    Total params
[2m[36m(pid=36171)[0m time to fit was 79.30781841278076
[2m[36m(pid=36171)[0m GPU available: False, used: False
[2m[36m(pid=36171)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36171)[0m 
[2m[36m(pid=36171)[0m   | Name      | Type              | Params
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36171)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36171)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 12.0 K    Trainable params
[2m[36m(pid=36171)[0m 0         Non-trainable params
[2m[36m(pid=36171)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m time to fit was 470.915730714798
[2m[36m(pid=36194)[0m GPU available: False, used: False
[2m[36m(pid=36194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36194)[0m 
[2m[36m(pid=36194)[0m   | Name      | Type              | Params
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 12.0 K    Trainable params
[2m[36m(pid=36194)[0m 0         Non-trainable params
[2m[36m(pid=36194)[0m 12.0 K    Total params
[2m[36m(pid=36174)[0m time to fit was 224.19465565681458
[2m[36m(pid=36174)[0m GPU available: False, used: False
[2m[36m(pid=36174)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36174)[0m 
[2m[36m(pid=36174)[0m   | Name      | Type              | Params
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36174)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36174)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 12.0 K    Trainable params
[2m[36m(pid=36174)[0m 0         Non-trainable params
[2m[36m(pid=36174)[0m 12.0 K    Total params
[2m[36m(pid=51143)[0m time to fit was 429.93533730506897
[2m[36m(pid=51143)[0m GPU available: False, used: False
[2m[36m(pid=51143)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51143)[0m 
[2m[36m(pid=51143)[0m   | Name      | Type              | Params
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51143)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51143)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 12.0 K    Trainable params
[2m[36m(pid=51143)[0m 0         Non-trainable params
[2m[36m(pid=51143)[0m 12.0 K    Total params
[2m[36m(pid=21672)[0m time to fit was 527.4767165184021
[2m[36m(pid=21672)[0m GPU available: False, used: False
[2m[36m(pid=21672)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21672)[0m 
[2m[36m(pid=21672)[0m   | Name      | Type              | Params
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21672)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21672)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 12.0 K    Trainable params
[2m[36m(pid=21672)[0m 0         Non-trainable params
[2m[36m(pid=21672)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m time to fit was 64.60822558403015
[2m[36m(pid=36167)[0m GPU available: False, used: False
[2m[36m(pid=36167)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36167)[0m 
[2m[36m(pid=36167)[0m   | Name      | Type              | Params
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36167)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36167)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 12.0 K    Trainable params
[2m[36m(pid=36167)[0m 0         Non-trainable params
[2m[36m(pid=36167)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m time to fit was 122.15055441856384
[2m[36m(pid=36173)[0m GPU available: False, used: False
[2m[36m(pid=36173)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m   | Name      | Type              | Params
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36173)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36173)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 12.0 K    Trainable params
[2m[36m(pid=36173)[0m 0         Non-trainable params
[2m[36m(pid=36173)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m time to fit was 438.5284147262573
[2m[36m(pid=22450)[0m GPU available: False, used: False
[2m[36m(pid=22450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22450)[0m 
[2m[36m(pid=22450)[0m   | Name      | Type              | Params
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 12.0 K    Trainable params
[2m[36m(pid=22450)[0m 0         Non-trainable params
[2m[36m(pid=22450)[0m 12.0 K    Total params
[2m[36m(pid=35963)[0m time to fit was 124.44304275512695
[2m[36m(pid=35963)[0m GPU available: False, used: False
[2m[36m(pid=35963)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35963)[0m 
[2m[36m(pid=35963)[0m   | Name      | Type              | Params
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35963)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35963)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35963)[0m ------------------------------------------------
[2m[36m(pid=35963)[0m 12.0 K    Trainable params
[2m[36m(pid=35963)[0m 0         Non-trainable params
[2m[36m(pid=35963)[0m 12.0 K    Total params
[2m[36m(pid=36171)[0m time to fit was 78.09755301475525
[2m[36m(pid=36171)[0m GPU available: False, used: False
[2m[36m(pid=36171)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36171)[0m 
[2m[36m(pid=36171)[0m   | Name      | Type              | Params
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36171)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36171)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 12.0 K    Trainable params
[2m[36m(pid=36171)[0m 0         Non-trainable params
[2m[36m(pid=36171)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m time to fit was 64.86437106132507
[2m[36m(pid=36167)[0m GPU available: False, used: False
[2m[36m(pid=36167)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36167)[0m 
[2m[36m(pid=36167)[0m   | Name      | Type              | Params
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36167)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36167)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36167)[0m ------------------------------------------------
[2m[36m(pid=36167)[0m 12.0 K    Trainable params
[2m[36m(pid=36167)[0m 0         Non-trainable params
[2m[36m(pid=36167)[0m 12.0 K    Total params
[2m[36m(pid=9770)[0m time to fit was 1330.7279403209686
[2m[36m(pid=9770)[0m GPU available: False, used: False
[2m[36m(pid=9770)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9770)[0m 
[2m[36m(pid=9770)[0m   | Name      | Type              | Params
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9770)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9770)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 12.0 K    Trainable params
[2m[36m(pid=9770)[0m 0         Non-trainable params
[2m[36m(pid=9770)[0m 12.0 K    Total params
[2m[36m(pid=24654)[0m time to fit was 241.73663568496704
[2m[36m(pid=24654)[0m GPU available: False, used: False
[2m[36m(pid=24654)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=24654)[0m 
[2m[36m(pid=24654)[0m   | Name      | Type              | Params
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=24654)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=24654)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=24654)[0m ------------------------------------------------
[2m[36m(pid=24654)[0m 12.0 K    Trainable params
[2m[36m(pid=24654)[0m 0         Non-trainable params
[2m[36m(pid=24654)[0m 12.0 K    Total params
[2m[36m(pid=36171)[0m time to fit was 79.0221176147461
[2m[36m(pid=36171)[0m GPU available: False, used: False
[2m[36m(pid=36171)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36171)[0m 
[2m[36m(pid=36171)[0m   | Name      | Type              | Params
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36171)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36171)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36171)[0m ------------------------------------------------
[2m[36m(pid=36171)[0m 12.0 K    Trainable params
[2m[36m(pid=36171)[0m 0         Non-trainable params
[2m[36m(pid=36171)[0m 12.0 K    Total params
[2m[36m(pid=36167)[0m time to fit was 63.700899600982666
Result for _inner_e98d6_00109:
  auc: 0.9122966647148132
  date: 2021-03-18_01-41-36
  done: false
  experiment_id: 72287603ed7e4e408a625394d18fe46a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36167
  time_since_restore: 311.2582001686096
  time_this_iter_s: 311.2582001686096
  time_total_s: 311.2582001686096
  timestamp: 1616028096
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00109
  
[2m[36m(pid=36167)[0m Finished run with seed 0 - lr 1 - sec_lr 1 - bs 512 - mean val auc: 0.9122966647148132
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 113/180 (1 PENDING, 26 RUNNING, 86 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00112 | PENDING    |       |          128 |     0 | 2     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 93 more trials not shown (16 RUNNING, 76 TERMINATED)


Result for _inner_e98d6_00109:
  auc: 0.9122966647148132
  date: 2021-03-18_01-41-36
  done: true
  experiment_id: 72287603ed7e4e408a625394d18fe46a
  experiment_tag: 109_batch_size=512,eta=0.0,lr=1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36167
  time_since_restore: 311.2582001686096
  time_this_iter_s: 311.2582001686096
  time_total_s: 311.2582001686096
  timestamp: 1616028096
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00109
  
[2m[36m(pid=36015)[0m Starting run with seed 0 - lr 2 - sec_lr 1 - bs 128
[2m[36m(pid=36015)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36015)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36015)[0m GPU available: False, used: False
[2m[36m(pid=36015)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36015)[0m 
[2m[36m(pid=36015)[0m   | Name      | Type              | Params
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36015)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36015)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 12.0 K    Trainable params
[2m[36m(pid=36015)[0m 0         Non-trainable params
[2m[36m(pid=36015)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36015)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36015)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36015)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36015)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36015)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36034)[0m time to fit was 260.8172423839569
[2m[36m(pid=36034)[0m GPU available: False, used: False
[2m[36m(pid=36034)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m   | Name      | Type              | Params
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36034)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36034)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 12.0 K    Trainable params
[2m[36m(pid=36034)[0m 0         Non-trainable params
[2m[36m(pid=36034)[0m 12.0 K    Total params
[2m[36m(pid=35963)[0m time to fit was 158.68452620506287
Result for _inner_e98d6_00102:
  auc: 0.9099465847015381
  date: 2021-03-18_01-42-25
  done: false
  experiment_id: cba2046f98714334ba82026f962cf626
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35963
  time_since_restore: 685.0348331928253
  time_this_iter_s: 685.0348331928253
  time_total_s: 685.0348331928253
  timestamp: 1616028145
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00102
  
[2m[36m(pid=35963)[0m Finished run with seed 0 - lr 0.1 - sec_lr 1 - bs 128 - mean val auc: 0.9099465847015381
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 114/180 (1 PENDING, 26 RUNNING, 87 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00113 | PENDING    |       |          256 |     0 | 2     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 94 more trials not shown (16 RUNNING, 77 TERMINATED)


Result for _inner_e98d6_00102:
  auc: 0.9099465847015381
  date: 2021-03-18_01-42-25
  done: true
  experiment_id: cba2046f98714334ba82026f962cf626
  experiment_tag: 102_batch_size=128,eta=0.0,lr=0.1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35963
  time_since_restore: 685.0348331928253
  time_this_iter_s: 685.0348331928253
  time_total_s: 685.0348331928253
  timestamp: 1616028145
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00102
  
[2m[36m(pid=36173)[0m time to fit was 178.50108575820923
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m GPU available: False, used: False
[2m[36m(pid=36173)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m   | Name      | Type              | Params
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36173)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36173)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 12.0 K    Trainable params
[2m[36m(pid=36173)[0m 0         Non-trainable params
[2m[36m(pid=36173)[0m 12.0 K    Total params
[2m[36m(pid=11193)[0m Starting run with seed 0 - lr 2 - sec_lr 1 - bs 256
[2m[36m(pid=11193)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11193)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=11193)[0m GPU available: False, used: False
[2m[36m(pid=11193)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11193)[0m 
[2m[36m(pid=11193)[0m   | Name      | Type              | Params
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11193)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11193)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 12.0 K    Trainable params
[2m[36m(pid=11193)[0m 0         Non-trainable params
[2m[36m(pid=11193)[0m 12.0 K    Total params
[2m[36m(pid=11193)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11193)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11193)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11193)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11193)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=11193)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36171)[0m time to fit was 70.72915983200073
Result for _inner_e98d6_00108:
  auc: 0.909921658039093
  date: 2021-03-18_01-42-39
  done: false
  experiment_id: 11dadfeb8a5a4007850f41d393e4efd7
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36171
  time_since_restore: 386.55429434776306
  time_this_iter_s: 386.55429434776306
  time_total_s: 386.55429434776306
  timestamp: 1616028159
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00108
  
[2m[36m(pid=36171)[0m Finished run with seed 0 - lr 1 - sec_lr 1 - bs 256 - mean val auc: 0.909921658039093
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 115/180 (1 PENDING, 26 RUNNING, 88 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00114 | PENDING    |       |          512 |     0 | 2     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 95 more trials not shown (16 RUNNING, 78 TERMINATED)


Result for _inner_e98d6_00108:
  auc: 0.909921658039093
  date: 2021-03-18_01-42-39
  done: true
  experiment_id: 11dadfeb8a5a4007850f41d393e4efd7
  experiment_tag: 108_batch_size=256,eta=0.0,lr=1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36171
  time_since_restore: 386.55429434776306
  time_this_iter_s: 386.55429434776306
  time_total_s: 386.55429434776306
  timestamp: 1616028159
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00108
  
[2m[36m(pid=11723)[0m Starting run with seed 0 - lr 2 - sec_lr 1 - bs 512
[2m[36m(pid=11723)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11723)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=11723)[0m GPU available: False, used: False
[2m[36m(pid=11723)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11723)[0m 
[2m[36m(pid=11723)[0m   | Name      | Type              | Params
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11723)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11723)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 12.0 K    Trainable params
[2m[36m(pid=11723)[0m 0         Non-trainable params
[2m[36m(pid=11723)[0m 12.0 K    Total params
[2m[36m(pid=11723)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11723)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11723)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11723)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11723)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=11723)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36174)[0m time to fit was 224.58758115768433
[2m[36m(pid=36174)[0m GPU available: False, used: False
[2m[36m(pid=36174)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36174)[0m 
[2m[36m(pid=36174)[0m   | Name      | Type              | Params
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36174)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36174)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 12.0 K    Trainable params
[2m[36m(pid=36174)[0m 0         Non-trainable params
[2m[36m(pid=36174)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m time to fit was 420.24266839027405
[2m[36m(pid=36103)[0m GPU available: False, used: False
[2m[36m(pid=36103)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36103)[0m 
[2m[36m(pid=36103)[0m   | Name      | Type              | Params
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36103)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36103)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 12.0 K    Trainable params
[2m[36m(pid=36103)[0m 0         Non-trainable params
[2m[36m(pid=36103)[0m 12.0 K    Total params
[2m[36m(pid=11723)[0m time to fit was 62.93169164657593
[2m[36m(pid=11723)[0m GPU available: False, used: False
[2m[36m(pid=11723)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11723)[0m 
[2m[36m(pid=11723)[0m   | Name      | Type              | Params
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11723)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11723)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 12.0 K    Trainable params
[2m[36m(pid=11723)[0m 0         Non-trainable params
[2m[36m(pid=11723)[0m 12.0 K    Total params
[2m[36m(pid=11193)[0m time to fit was 77.31391024589539
[2m[36m(pid=11193)[0m GPU available: False, used: False
[2m[36m(pid=11193)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11193)[0m 
[2m[36m(pid=11193)[0m   | Name      | Type              | Params
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11193)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11193)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 12.0 K    Trainable params
[2m[36m(pid=11193)[0m 0         Non-trainable params
[2m[36m(pid=11193)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m time to fit was 131.70972084999084
[2m[36m(pid=36015)[0m GPU available: False, used: False
[2m[36m(pid=36015)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36015)[0m 
[2m[36m(pid=36015)[0m   | Name      | Type              | Params
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36015)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36015)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 12.0 K    Trainable params
[2m[36m(pid=36015)[0m 0         Non-trainable params
[2m[36m(pid=36015)[0m 12.0 K    Total params
[2m[36m(pid=36173)[0m time to fit was 121.24740552902222
[2m[36m(pid=36173)[0m GPU available: False, used: False
[2m[36m(pid=36173)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36173)[0m 
[2m[36m(pid=36173)[0m   | Name      | Type              | Params
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36173)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36173)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36173)[0m ------------------------------------------------
[2m[36m(pid=36173)[0m 12.0 K    Trainable params
[2m[36m(pid=36173)[0m 0         Non-trainable params
[2m[36m(pid=36173)[0m 12.0 K    Total params
[2m[36m(pid=24654)[0m time to fit was 218.93495798110962
[2m[36m(pid=24654)[0m Finished run with seed 0 - lr 0.1 - sec_lr 1 - bs 64 - mean val auc: 0.8824906587600708
Result for _inner_e98d6_00101:
  auc: 0.8824906587600708
  date: 2021-03-18_01-44-49
  done: false
  experiment_id: 320b2a343ed0483d94f2317432cf8d01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 24654
  time_since_restore: 1128.7550041675568
  time_this_iter_s: 1128.7550041675568
  time_total_s: 1128.7550041675568
  timestamp: 1616028289
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00101
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 116/180 (1 PENDING, 26 RUNNING, 89 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00115 | PENDING    |       |           32 |     0 | 5     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 96 more trials not shown (16 RUNNING, 79 TERMINATED)


Result for _inner_e98d6_00101:
  auc: 0.8824906587600708
  date: 2021-03-18_01-44-49
  done: true
  experiment_id: 320b2a343ed0483d94f2317432cf8d01
  experiment_tag: 101_batch_size=64,eta=0.0,lr=0.1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 24654
  time_since_restore: 1128.7550041675568
  time_this_iter_s: 1128.7550041675568
  time_total_s: 1128.7550041675568
  timestamp: 1616028289
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00101
  
[2m[36m(pid=11723)[0m time to fit was 58.465635776519775
[2m[36m(pid=11723)[0m GPU available: False, used: False
[2m[36m(pid=11723)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11723)[0m 
[2m[36m(pid=11723)[0m   | Name      | Type              | Params
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11723)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11723)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 12.0 K    Trainable params
[2m[36m(pid=11723)[0m 0         Non-trainable params
[2m[36m(pid=11723)[0m 12.0 K    Total params
[2m[36m(pid=9705)[0m time to fit was 448.68619441986084
Result for _inner_e98d6_00086:
  auc: 0.6325981974601745
  date: 2021-03-18_01-44-56
  done: false
  experiment_id: 38071acb304644a1a0ee0210f1fd847a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9705
  time_since_restore: 2767.13085436821
  time_this_iter_s: 2767.13085436821
  time_total_s: 2767.13085436821
  timestamp: 1616028296
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00086
  
[2m[36m(pid=9705)[0m Finished run with seed 0 - lr 5 - sec_lr 0.1 - bs 64 - mean val auc: 0.6325981974601745
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 117/180 (1 PENDING, 26 RUNNING, 90 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00116 | PENDING    |       |           64 |     0 | 5     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 97 more trials not shown (16 RUNNING, 80 TERMINATED)


Result for _inner_e98d6_00086:
  auc: 0.6325981974601745
  date: 2021-03-18_01-44-56
  done: true
  experiment_id: 38071acb304644a1a0ee0210f1fd847a
  experiment_tag: 86_batch_size=64,eta=0.0,lr=5,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9705
  time_since_restore: 2767.13085436821
  time_this_iter_s: 2767.13085436821
  time_total_s: 2767.13085436821
  timestamp: 1616028296
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00086
  
[2m[36m(pid=16679)[0m Starting run with seed 0 - lr 5 - sec_lr 1 - bs 32
[2m[36m(pid=16679)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16679)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=16679)[0m GPU available: False, used: False
[2m[36m(pid=16679)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16679)[0m 
[2m[36m(pid=16679)[0m   | Name      | Type              | Params
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16679)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16679)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 12.0 K    Trainable params
[2m[36m(pid=16679)[0m 0         Non-trainable params
[2m[36m(pid=16679)[0m 12.0 K    Total params
[2m[36m(pid=16679)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=16679)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16679)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=16679)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16679)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=16679)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16989)[0m Starting run with seed 0 - lr 5 - sec_lr 1 - bs 64
[2m[36m(pid=16989)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16989)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=16989)[0m GPU available: False, used: False
[2m[36m(pid=16989)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16989)[0m 
[2m[36m(pid=16989)[0m   | Name      | Type              | Params
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16989)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16989)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 12.0 K    Trainable params
[2m[36m(pid=16989)[0m 0         Non-trainable params
[2m[36m(pid=16989)[0m 12.0 K    Total params
[2m[36m(pid=16989)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=16989)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16989)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=16989)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16989)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=16989)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11193)[0m time to fit was 78.82695412635803
[2m[36m(pid=11193)[0m GPU available: False, used: False
[2m[36m(pid=11193)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11193)[0m 
[2m[36m(pid=11193)[0m   | Name      | Type              | Params
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11193)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11193)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 12.0 K    Trainable params
[2m[36m(pid=11193)[0m 0         Non-trainable params
[2m[36m(pid=11193)[0m 12.0 K    Total params
[2m[36m(pid=11723)[0m time to fit was 62.512615442276
[2m[36m(pid=11723)[0m GPU available: False, used: False
[2m[36m(pid=11723)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11723)[0m 
[2m[36m(pid=11723)[0m   | Name      | Type              | Params
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11723)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11723)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 12.0 K    Trainable params
[2m[36m(pid=11723)[0m 0         Non-trainable params
[2m[36m(pid=11723)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m time to fit was 2260.780725479126
[2m[36m(pid=21741)[0m GPU available: False, used: False
[2m[36m(pid=21741)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21741)[0m 
[2m[36m(pid=21741)[0m   | Name      | Type              | Params
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21741)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21741)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 12.0 K    Trainable params
[2m[36m(pid=21741)[0m 0         Non-trainable params
[2m[36m(pid=21741)[0m 12.0 K    Total params
[2m[36m(pid=30253)[0m time to fit was 495.8996481895447
Result for _inner_e98d6_00090:
  auc: 0.8736084580421448
  date: 2021-03-18_01-46-22
  done: false
  experiment_id: 4e71995ab99b4ae1bf5dc09bab917ce6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30253
  time_since_restore: 2470.6586530208588
  time_this_iter_s: 2470.6586530208588
  time_total_s: 2470.6586530208588
  timestamp: 1616028382
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00090
  
[2m[36m(pid=30253)[0m Finished run with seed 0 - lr 0.001 - sec_lr 1 - bs 32 - mean val auc: 0.8736084580421448
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 118/180 (1 PENDING, 26 RUNNING, 91 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00117 | PENDING    |       |          128 |     0 | 5     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 98 more trials not shown (16 RUNNING, 81 TERMINATED)


Result for _inner_e98d6_00090:
  auc: 0.8736084580421448
  date: 2021-03-18_01-46-22
  done: true
  experiment_id: 4e71995ab99b4ae1bf5dc09bab917ce6
  experiment_tag: 90_batch_size=32,eta=0.0,lr=0.001,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30253
  time_since_restore: 2470.6586530208588
  time_this_iter_s: 2470.6586530208588
  time_total_s: 2470.6586530208588
  timestamp: 1616028382
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00090
  
[2m[36m(pid=20213)[0m Starting run with seed 0 - lr 5 - sec_lr 1 - bs 128
[2m[36m(pid=20213)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20213)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=20213)[0m GPU available: False, used: False
[2m[36m(pid=20213)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20213)[0m 
[2m[36m(pid=20213)[0m   | Name      | Type              | Params
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20213)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20213)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 12.0 K    Trainable params
[2m[36m(pid=20213)[0m 0         Non-trainable params
[2m[36m(pid=20213)[0m 12.0 K    Total params
[2m[36m(pid=20213)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20213)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20213)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20213)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36173)[0m time to fit was 124.25351691246033
[2m[36m(pid=20213)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=20213)[0m   warnings.warn(*args, **kwargs)
Result for _inner_e98d6_00107:
  auc: 0.9073716163635254
  date: 2021-03-18_01-46-36
  done: false
  experiment_id: 15945f413cc3454394074d6f078c65d8
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36173
  time_since_restore: 673.0454652309418
  time_this_iter_s: 673.0454652309418
  time_total_s: 673.0454652309418
  timestamp: 1616028396
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00107
  
[2m[36m(pid=36173)[0m Finished run with seed 0 - lr 1 - sec_lr 1 - bs 128 - mean val auc: 0.9073716163635254
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 119/180 (1 PENDING, 26 RUNNING, 92 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00118 | PENDING    |       |          256 |     0 | 5     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 99 more trials not shown (16 RUNNING, 82 TERMINATED)


Result for _inner_e98d6_00107:
  auc: 0.9073716163635254
  date: 2021-03-18_01-46-36
  done: true
  experiment_id: 15945f413cc3454394074d6f078c65d8
  experiment_tag: 107_batch_size=128,eta=0.0,lr=1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36173
  time_since_restore: 673.0454652309418
  time_this_iter_s: 673.0454652309418
  time_total_s: 673.0454652309418
  timestamp: 1616028396
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00107
  
[2m[36m(pid=11193)[0m time to fit was 85.28808164596558
[2m[36m(pid=11193)[0m GPU available: False, used: False
[2m[36m(pid=11193)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11193)[0m 
[2m[36m(pid=11193)[0m   | Name      | Type              | Params
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11193)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11193)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 12.0 K    Trainable params
[2m[36m(pid=11193)[0m 0         Non-trainable params
[2m[36m(pid=11193)[0m 12.0 K    Total params
[2m[36m(pid=36174)[0m time to fit was 223.3861699104309
[2m[36m(pid=36174)[0m GPU available: False, used: False
[2m[36m(pid=36174)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36174)[0m 
[2m[36m(pid=36174)[0m   | Name      | Type              | Params
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36174)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36174)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36174)[0m ------------------------------------------------
[2m[36m(pid=36174)[0m 12.0 K    Trainable params
[2m[36m(pid=36174)[0m 0         Non-trainable params
[2m[36m(pid=36174)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m time to fit was 462.5656280517578
[2m[36m(pid=36194)[0m GPU available: False, used: False
[2m[36m(pid=36194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36194)[0m 
[2m[36m(pid=36194)[0m   | Name      | Type              | Params
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 12.0 K    Trainable params
[2m[36m(pid=36194)[0m 0         Non-trainable params
[2m[36m(pid=36194)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m time to fit was 429.57302927970886
[2m[36m(pid=22450)[0m GPU available: False, used: False
[2m[36m(pid=22450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22450)[0m 
[2m[36m(pid=22450)[0m   | Name      | Type              | Params
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 12.0 K    Trainable params
[2m[36m(pid=22450)[0m 0         Non-trainable params
[2m[36m(pid=22450)[0m 12.0 K    Total params
[2m[36m(pid=20722)[0m Starting run with seed 0 - lr 5 - sec_lr 1 - bs 256
[2m[36m(pid=20722)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20722)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=20722)[0m GPU available: False, used: False
[2m[36m(pid=20722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20722)[0m 
[2m[36m(pid=20722)[0m   | Name      | Type              | Params
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 12.0 K    Trainable params
[2m[36m(pid=20722)[0m 0         Non-trainable params
[2m[36m(pid=20722)[0m 12.0 K    Total params
[2m[36m(pid=20722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20722)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=20722)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11723)[0m time to fit was 62.92366623878479
[2m[36m(pid=11723)[0m GPU available: False, used: False
[2m[36m(pid=11723)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11723)[0m 
[2m[36m(pid=11723)[0m   | Name      | Type              | Params
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11723)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11723)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11723)[0m ------------------------------------------------
[2m[36m(pid=11723)[0m 12.0 K    Trainable params
[2m[36m(pid=11723)[0m 0         Non-trainable params
[2m[36m(pid=11723)[0m 12.0 K    Total params
[2m[36m(pid=11723)[0m time to fit was 45.94214940071106
Result for _inner_e98d6_00114:
  auc: 0.8255119442939758
  date: 2021-03-18_01-47-44
  done: false
  experiment_id: 2da55bf055ee412a991e3524fd65288f
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11723
  time_since_restore: 294.04515838623047
  time_this_iter_s: 294.04515838623047
  time_total_s: 294.04515838623047
  timestamp: 1616028464
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00114
  
[2m[36m(pid=11723)[0m Finished run with seed 0 - lr 2 - sec_lr 1 - bs 512 - mean val auc: 0.8255119442939758
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 120/180 (1 PENDING, 26 RUNNING, 93 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00119 | PENDING    |       |          512 |     0 | 5     |    1     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 100 more trials not shown (16 RUNNING, 83 TERMINATED)


Result for _inner_e98d6_00114:
  auc: 0.8255119442939758
  date: 2021-03-18_01-47-44
  done: true
  experiment_id: 2da55bf055ee412a991e3524fd65288f
  experiment_tag: 114_batch_size=512,eta=0.0,lr=2,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11723
  time_since_restore: 294.04515838623047
  time_this_iter_s: 294.04515838623047
  time_total_s: 294.04515838623047
  timestamp: 1616028464
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00114
  
2021-03-18 01:47:45,736	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff68e1e60001000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=23740)[0m Starting run with seed 0 - lr 5 - sec_lr 1 - bs 512
[2m[36m(pid=23740)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23740)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=23740)[0m GPU available: False, used: False
[2m[36m(pid=23740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23740)[0m 
[2m[36m(pid=23740)[0m   | Name      | Type              | Params
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 12.0 K    Trainable params
[2m[36m(pid=23740)[0m 0         Non-trainable params
[2m[36m(pid=23740)[0m 12.0 K    Total params
[2m[36m(pid=23740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23740)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=23740)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20722)[0m time to fit was 79.32442259788513
[2m[36m(pid=20722)[0m GPU available: False, used: False
[2m[36m(pid=20722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20722)[0m 
[2m[36m(pid=20722)[0m   | Name      | Type              | Params
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 12.0 K    Trainable params
[2m[36m(pid=20722)[0m 0         Non-trainable params
[2m[36m(pid=20722)[0m 12.0 K    Total params
[2m[36m(pid=11193)[0m time to fit was 99.503093957901
[2m[36m(pid=11193)[0m GPU available: False, used: False
[2m[36m(pid=11193)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11193)[0m 
[2m[36m(pid=11193)[0m   | Name      | Type              | Params
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11193)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11193)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11193)[0m ------------------------------------------------
[2m[36m(pid=11193)[0m 12.0 K    Trainable params
[2m[36m(pid=11193)[0m 0         Non-trainable params
[2m[36m(pid=11193)[0m 12.0 K    Total params
[2m[36m(pid=51143)[0m time to fit was 544.75412774086
[2m[36m(pid=51143)[0m GPU available: False, used: False
[2m[36m(pid=51143)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=51143)[0m 
[2m[36m(pid=51143)[0m   | Name      | Type              | Params
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=51143)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=51143)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=51143)[0m ------------------------------------------------
[2m[36m(pid=51143)[0m 12.0 K    Trainable params
[2m[36m(pid=51143)[0m 0         Non-trainable params
[2m[36m(pid=51143)[0m 12.0 K    Total params
[2m[36m(pid=36034)[0m time to fit was 385.13944935798645
[2m[36m(pid=36034)[0m GPU available: False, used: False
[2m[36m(pid=36034)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m   | Name      | Type              | Params
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36034)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36034)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 12.0 K    Trainable params
[2m[36m(pid=36034)[0m 0         Non-trainable params
[2m[36m(pid=36034)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m time to fit was 298.63470220565796
[2m[36m(pid=36015)[0m GPU available: False, used: False
[2m[36m(pid=36015)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36015)[0m 
[2m[36m(pid=36015)[0m   | Name      | Type              | Params
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36015)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36015)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 12.0 K    Trainable params
[2m[36m(pid=36015)[0m 0         Non-trainable params
[2m[36m(pid=36015)[0m 12.0 K    Total params
[2m[36m(pid=20722)[0m time to fit was 71.17553377151489
[2m[36m(pid=20722)[0m GPU available: False, used: False
[2m[36m(pid=20722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20722)[0m 
[2m[36m(pid=20722)[0m   | Name      | Type              | Params
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 12.0 K    Trainable params
[2m[36m(pid=20722)[0m 0         Non-trainable params
[2m[36m(pid=20722)[0m 12.0 K    Total params
[2m[36m(pid=23740)[0m time to fit was 92.85700583457947
[2m[36m(pid=23740)[0m GPU available: False, used: False
[2m[36m(pid=23740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23740)[0m 
[2m[36m(pid=23740)[0m   | Name      | Type              | Params
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 12.0 K    Trainable params
[2m[36m(pid=23740)[0m 0         Non-trainable params
[2m[36m(pid=23740)[0m 12.0 K    Total params
[2m[36m(pid=9770)[0m time to fit was 506.73068141937256
[2m[36m(pid=9770)[0m GPU available: False, used: False
[2m[36m(pid=9770)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9770)[0m 
[2m[36m(pid=9770)[0m   | Name      | Type              | Params
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9770)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9770)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9770)[0m ------------------------------------------------
[2m[36m(pid=9770)[0m 12.0 K    Trainable params
[2m[36m(pid=9770)[0m 0         Non-trainable params
[2m[36m(pid=9770)[0m 12.0 K    Total params
[2m[36m(pid=20213)[0m time to fit was 179.27219653129578
[2m[36m(pid=20213)[0m GPU available: False, used: False
[2m[36m(pid=20213)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20213)[0m 
[2m[36m(pid=20213)[0m   | Name      | Type              | Params
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20213)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20213)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 12.0 K    Trainable params
[2m[36m(pid=20213)[0m 0         Non-trainable params
[2m[36m(pid=20213)[0m 12.0 K    Total params
[2m[36m(pid=11193)[0m time to fit was 80.95086431503296
Result for _inner_e98d6_00113:
  auc: 0.8941323399543762
  date: 2021-03-18_01-49-40
  done: false
  experiment_id: 47152446b28941c0adce344677527dd0
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11193
  time_since_restore: 423.2308042049408
  time_this_iter_s: 423.2308042049408
  time_total_s: 423.2308042049408
  timestamp: 1616028580
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00113
  
[2m[36m(pid=11193)[0m Finished run with seed 0 - lr 2 - sec_lr 1 - bs 256 - mean val auc: 0.8941323399543762
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 121/180 (1 PENDING, 26 RUNNING, 94 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00120 | PENDING    |       |           32 |     0 | 0.001 |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 101 more trials not shown (16 RUNNING, 84 TERMINATED)


Result for _inner_e98d6_00113:
  auc: 0.8941323399543762
  date: 2021-03-18_01-49-40
  done: true
  experiment_id: 47152446b28941c0adce344677527dd0
  experiment_tag: 113_batch_size=256,eta=0.0,lr=2,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11193
  time_since_restore: 423.2308042049408
  time_this_iter_s: 423.2308042049408
  time_total_s: 423.2308042049408
  timestamp: 1616028580
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00113
  
[2m[36m(pid=28610)[0m Starting run with seed 0 - lr 0.001 - sec_lr 2 - bs 32
[2m[36m(pid=28610)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28610)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=28610)[0m GPU available: False, used: False
[2m[36m(pid=28610)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28610)[0m 
[2m[36m(pid=28610)[0m   | Name      | Type              | Params
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28610)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28610)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 12.0 K    Trainable params
[2m[36m(pid=28610)[0m 0         Non-trainable params
[2m[36m(pid=28610)[0m 12.0 K    Total params
[2m[36m(pid=28610)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28610)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28610)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28610)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28610)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=28610)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23740)[0m time to fit was 46.12549901008606
[2m[36m(pid=23740)[0m GPU available: False, used: False
[2m[36m(pid=23740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23740)[0m 
[2m[36m(pid=23740)[0m   | Name      | Type              | Params
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 12.0 K    Trainable params
[2m[36m(pid=23740)[0m 0         Non-trainable params
[2m[36m(pid=23740)[0m 12.0 K    Total params
[2m[36m(pid=36174)[0m time to fit was 222.9868950843811
Result for _inner_e98d6_00106:
  auc: 0.8899989247322082
  date: 2021-03-18_01-50-24
  done: false
  experiment_id: cb63d26dc9804816ad8a893b1a7335c2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36174
  time_since_restore: 1146.3108904361725
  time_this_iter_s: 1146.3108904361725
  time_total_s: 1146.3108904361725
  timestamp: 1616028624
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00106
  
[2m[36m(pid=36174)[0m Finished run with seed 0 - lr 1 - sec_lr 1 - bs 64 - mean val auc: 0.8899989247322082
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 122/180 (1 PENDING, 26 RUNNING, 95 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00121 | PENDING    |       |           64 |     0 | 0.001 |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 102 more trials not shown (16 RUNNING, 85 TERMINATED)


Result for _inner_e98d6_00106:
  auc: 0.8899989247322082
  date: 2021-03-18_01-50-24
  done: true
  experiment_id: cb63d26dc9804816ad8a893b1a7335c2
  experiment_tag: 106_batch_size=64,eta=0.0,lr=1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36174
  time_since_restore: 1146.3108904361725
  time_this_iter_s: 1146.3108904361725
  time_total_s: 1146.3108904361725
  timestamp: 1616028624
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00106
  
2021-03-18 01:50:26,241	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff3e59ebde01000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=30205)[0m Starting run with seed 0 - lr 0.001 - sec_lr 2 - bs 64
[2m[36m(pid=30205)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30205)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30205)[0m GPU available: False, used: False
[2m[36m(pid=30205)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30205)[0m 
[2m[36m(pid=30205)[0m   | Name      | Type              | Params
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30205)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30205)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 12.0 K    Trainable params
[2m[36m(pid=30205)[0m 0         Non-trainable params
[2m[36m(pid=30205)[0m 12.0 K    Total params
[2m[36m(pid=30205)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30205)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30205)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30205)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30205)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30205)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20722)[0m time to fit was 79.30716371536255
[2m[36m(pid=20722)[0m GPU available: False, used: False
[2m[36m(pid=20722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20722)[0m 
[2m[36m(pid=20722)[0m   | Name      | Type              | Params
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 12.0 K    Trainable params
[2m[36m(pid=20722)[0m 0         Non-trainable params
[2m[36m(pid=20722)[0m 12.0 K    Total params
[2m[36m(pid=21720)[0m time to fit was 2137.169116973877
[2m[36m(pid=21720)[0m GPU available: False, used: False
[2m[36m(pid=21720)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21720)[0m 
[2m[36m(pid=21720)[0m   | Name      | Type              | Params
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21720)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21720)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21720)[0m ------------------------------------------------
[2m[36m(pid=21720)[0m 12.0 K    Trainable params
[2m[36m(pid=21720)[0m 0         Non-trainable params
[2m[36m(pid=21720)[0m 12.0 K    Total params
[2m[36m(pid=23740)[0m time to fit was 45.088643074035645
[2m[36m(pid=23740)[0m GPU available: False, used: False
[2m[36m(pid=23740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23740)[0m 
[2m[36m(pid=23740)[0m   | Name      | Type              | Params
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 12.0 K    Trainable params
[2m[36m(pid=23740)[0m 0         Non-trainable params
[2m[36m(pid=23740)[0m 12.0 K    Total params
[2m[36m(pid=23740)[0m time to fit was 46.975332260131836
[2m[36m(pid=23740)[0m GPU available: False, used: False
[2m[36m(pid=23740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23740)[0m 
[2m[36m(pid=23740)[0m   | Name      | Type              | Params
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23740)[0m ------------------------------------------------
[2m[36m(pid=23740)[0m 12.0 K    Trainable params
[2m[36m(pid=23740)[0m 0         Non-trainable params
[2m[36m(pid=23740)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m time to fit was 502.84463810920715
[2m[36m(pid=36103)[0m GPU available: False, used: False
[2m[36m(pid=36103)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36103)[0m 
[2m[36m(pid=36103)[0m   | Name      | Type              | Params
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36103)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36103)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 12.0 K    Trainable params
[2m[36m(pid=36103)[0m 0         Non-trainable params
[2m[36m(pid=36103)[0m 12.0 K    Total params
[2m[36m(pid=20213)[0m time to fit was 166.84786319732666
[2m[36m(pid=20213)[0m GPU available: False, used: False
[2m[36m(pid=20213)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20213)[0m 
[2m[36m(pid=20213)[0m   | Name      | Type              | Params
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20213)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20213)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 12.0 K    Trainable params
[2m[36m(pid=20213)[0m 0         Non-trainable params
[2m[36m(pid=20213)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m time to fit was 213.89336681365967
[2m[36m(pid=36015)[0m GPU available: False, used: False
[2m[36m(pid=36015)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36015)[0m 
[2m[36m(pid=36015)[0m   | Name      | Type              | Params
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36015)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36015)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 12.0 K    Trainable params
[2m[36m(pid=36015)[0m 0         Non-trainable params
[2m[36m(pid=36015)[0m 12.0 K    Total params
[2m[36m(pid=23740)[0m time to fit was 45.95637917518616
Result for _inner_e98d6_00119:
  auc: 0.5023159325122833
  date: 2021-03-18_01-52-34
  done: false
  experiment_id: 508698bd85d54224bc413544bd1e3782
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23740
  time_since_restore: 278.40140175819397
  time_this_iter_s: 278.40140175819397
  time_total_s: 278.40140175819397
  timestamp: 1616028754
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00119
  
[2m[36m(pid=23740)[0m Finished run with seed 0 - lr 5 - sec_lr 1 - bs 512 - mean val auc: 0.5023159325122833
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 123/180 (1 PENDING, 26 RUNNING, 96 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00122 | PENDING    |       |          128 |     0 | 0.001 |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 103 more trials not shown (16 RUNNING, 86 TERMINATED)


Result for _inner_e98d6_00119:
  auc: 0.5023159325122833
  date: 2021-03-18_01-52-34
  done: true
  experiment_id: 508698bd85d54224bc413544bd1e3782
  experiment_tag: 119_batch_size=512,eta=0.0,lr=5,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23740
  time_since_restore: 278.40140175819397
  time_this_iter_s: 278.40140175819397
  time_total_s: 278.40140175819397
  timestamp: 1616028754
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00119
  
[2m[36m(pid=35186)[0m Starting run with seed 0 - lr 0.001 - sec_lr 2 - bs 128
[2m[36m(pid=35186)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35186)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=35186)[0m GPU available: False, used: False
[2m[36m(pid=35186)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35186)[0m 
[2m[36m(pid=35186)[0m   | Name      | Type              | Params
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35186)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35186)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 12.0 K    Trainable params
[2m[36m(pid=35186)[0m 0         Non-trainable params
[2m[36m(pid=35186)[0m 12.0 K    Total params
[2m[36m(pid=35186)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35186)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35186)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35186)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35186)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=35186)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16679)[0m time to fit was 497.1549153327942
[2m[36m(pid=16679)[0m GPU available: False, used: False
[2m[36m(pid=16679)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16679)[0m 
[2m[36m(pid=16679)[0m   | Name      | Type              | Params
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16679)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16679)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 12.0 K    Trainable params
[2m[36m(pid=16679)[0m 0         Non-trainable params
[2m[36m(pid=16679)[0m 12.0 K    Total params
[2m[36m(pid=16989)[0m time to fit was 498.62660694122314
[2m[36m(pid=16989)[0m GPU available: False, used: False
[2m[36m(pid=16989)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16989)[0m 
[2m[36m(pid=16989)[0m   | Name      | Type              | Params
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16989)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16989)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 12.0 K    Trainable params
[2m[36m(pid=16989)[0m 0         Non-trainable params
[2m[36m(pid=16989)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m time to fit was 426.4372868537903
[2m[36m(pid=36194)[0m GPU available: False, used: False
[2m[36m(pid=36194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36194)[0m 
[2m[36m(pid=36194)[0m   | Name      | Type              | Params
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 12.0 K    Trainable params
[2m[36m(pid=36194)[0m 0         Non-trainable params
[2m[36m(pid=36194)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m time to fit was 428.8236153125763
[2m[36m(pid=22450)[0m GPU available: False, used: False
[2m[36m(pid=22450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22450)[0m 
[2m[36m(pid=22450)[0m   | Name      | Type              | Params
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22450)[0m ------------------------------------------------
[2m[36m(pid=22450)[0m 12.0 K    Trainable params
[2m[36m(pid=22450)[0m 0         Non-trainable params
[2m[36m(pid=22450)[0m 12.0 K    Total params
[2m[36m(pid=20722)[0m time to fit was 207.2121934890747
[2m[36m(pid=20722)[0m GPU available: False, used: False
[2m[36m(pid=20722)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20722)[0m 
[2m[36m(pid=20722)[0m   | Name      | Type              | Params
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20722)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20722)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20722)[0m ------------------------------------------------
[2m[36m(pid=20722)[0m 12.0 K    Trainable params
[2m[36m(pid=20722)[0m 0         Non-trainable params
[2m[36m(pid=20722)[0m 12.0 K    Total params
[2m[36m(pid=30205)[0m time to fit was 244.55708694458008
[2m[36m(pid=30205)[0m GPU available: False, used: False
[2m[36m(pid=30205)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30205)[0m 
[2m[36m(pid=30205)[0m   | Name      | Type              | Params
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30205)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30205)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 12.0 K    Trainable params
[2m[36m(pid=30205)[0m 0         Non-trainable params
[2m[36m(pid=30205)[0m 12.0 K    Total params
[2m[36m(pid=35186)[0m time to fit was 122.87338972091675
[2m[36m(pid=35186)[0m GPU available: False, used: False
[2m[36m(pid=35186)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35186)[0m 
[2m[36m(pid=35186)[0m   | Name      | Type              | Params
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35186)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35186)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 12.0 K    Trainable params
[2m[36m(pid=35186)[0m 0         Non-trainable params
[2m[36m(pid=35186)[0m 12.0 K    Total params
[2m[36m(pid=20722)[0m time to fit was 70.80535387992859
Result for _inner_e98d6_00118:
  auc: 0.6606003642082214
  date: 2021-03-18_01-55-16
  done: false
  experiment_id: 9f954a9aad4b49f09eeee4560ced6262
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20722
  time_since_restore: 509.04387187957764
  time_this_iter_s: 509.04387187957764
  time_total_s: 509.04387187957764
  timestamp: 1616028916
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00118
  
[2m[36m(pid=20722)[0m Finished run with seed 0 - lr 5 - sec_lr 1 - bs 256 - mean val auc: 0.6606003642082214
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 124/180 (1 PENDING, 26 RUNNING, 97 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00123 | PENDING    |       |          256 |     0 | 0.001 |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 104 more trials not shown (16 RUNNING, 87 TERMINATED)


Result for _inner_e98d6_00118:
  auc: 0.6606003642082214
  date: 2021-03-18_01-55-16
  done: true
  experiment_id: 9f954a9aad4b49f09eeee4560ced6262
  experiment_tag: 118_batch_size=256,eta=0.0,lr=5,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20722
  time_since_restore: 509.04387187957764
  time_this_iter_s: 509.04387187957764
  time_total_s: 509.04387187957764
  timestamp: 1616028916
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00118
  
2021-03-18 01:55:17,073	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffffede18f6401000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=40957)[0m Starting run with seed 0 - lr 0.001 - sec_lr 2 - bs 256
[2m[36m(pid=40957)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=40957)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=40957)[0m GPU available: False, used: False
[2m[36m(pid=40957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=40957)[0m 
[2m[36m(pid=40957)[0m   | Name      | Type              | Params
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=40957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=40957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 12.0 K    Trainable params
[2m[36m(pid=40957)[0m 0         Non-trainable params
[2m[36m(pid=40957)[0m 12.0 K    Total params
[2m[36m(pid=40957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=40957)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=40957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=40957)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=51143)[0m time to fit was 428.03208684921265
[2m[36m(pid=40957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=40957)[0m   warnings.warn(*args, **kwargs)
Result for _inner_e98d6_00095:
  auc: 0.8206873714923859
  date: 2021-03-18_01-55-31
  done: false
  experiment_id: f5e7e7ecb3be43f4b26bcd4809e3d479
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 51143
  time_since_restore: 2442.4436535835266
  time_this_iter_s: 2442.4436535835266
  time_total_s: 2442.4436535835266
  timestamp: 1616028931
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00095
  
[2m[36m(pid=51143)[0m Finished run with seed 0 - lr 0.01 - sec_lr 1 - bs 32 - mean val auc: 0.8206873714923859
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 125/180 (1 PENDING, 26 RUNNING, 98 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00124 | PENDING    |       |          512 |     0 | 0.001 |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 105 more trials not shown (16 RUNNING, 88 TERMINATED)


Result for _inner_e98d6_00095:
  auc: 0.8206873714923859
  date: 2021-03-18_01-55-31
  done: true
  experiment_id: f5e7e7ecb3be43f4b26bcd4809e3d479
  experiment_tag: 95_batch_size=32,eta=0.0,lr=0.01,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 51143
  time_since_restore: 2442.4436535835266
  time_this_iter_s: 2442.4436535835266
  time_total_s: 2442.4436535835266
  timestamp: 1616028931
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00095
  
[2m[36m(pid=36034)[0m time to fit was 411.32747077941895
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m GPU available: False, used: False
[2m[36m(pid=36034)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m   | Name      | Type              | Params
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36034)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36034)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 12.0 K    Trainable params
[2m[36m(pid=36034)[0m 0         Non-trainable params
[2m[36m(pid=36034)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m time to fit was 189.913099527359
[2m[36m(pid=36015)[0m GPU available: False, used: False
[2m[36m(pid=36015)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36015)[0m 
[2m[36m(pid=36015)[0m   | Name      | Type              | Params
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36015)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36015)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36015)[0m ------------------------------------------------
[2m[36m(pid=36015)[0m 12.0 K    Trainable params
[2m[36m(pid=36015)[0m 0         Non-trainable params
[2m[36m(pid=36015)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m Starting run with seed 0 - lr 0.001 - sec_lr 2 - bs 512
[2m[36m(pid=41450)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41450)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=41450)[0m GPU available: False, used: False
[2m[36m(pid=41450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41450)[0m 
[2m[36m(pid=41450)[0m   | Name      | Type              | Params
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 12.0 K    Trainable params
[2m[36m(pid=41450)[0m 0         Non-trainable params
[2m[36m(pid=41450)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41450)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=41450)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20213)[0m time to fit was 220.10849118232727
[2m[36m(pid=20213)[0m GPU available: False, used: False
[2m[36m(pid=20213)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20213)[0m 
[2m[36m(pid=20213)[0m   | Name      | Type              | Params
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20213)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20213)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 12.0 K    Trainable params
[2m[36m(pid=20213)[0m 0         Non-trainable params
[2m[36m(pid=20213)[0m 12.0 K    Total params
[2m[36m(pid=9770)[0m time to fit was 426.92122650146484
Result for _inner_e98d6_00085:
  auc: 0.651221239566803
  date: 2021-03-18_01-56-40
  done: false
  experiment_id: fdb9860db5c74bf687d1bd3d58744822
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9770
  time_since_restore: 3576.049563884735
  time_this_iter_s: 3576.049563884735
  time_total_s: 3576.049563884735
  timestamp: 1616029000
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00085
  
[2m[36m(pid=9770)[0m Finished run with seed 0 - lr 5 - sec_lr 0.1 - bs 32 - mean val auc: 0.651221239566803
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 126/180 (1 PENDING, 26 RUNNING, 99 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00125 | PENDING    |       |           32 |     0 | 0.01  |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 106 more trials not shown (16 RUNNING, 89 TERMINATED)


Result for _inner_e98d6_00085:
  auc: 0.651221239566803
  date: 2021-03-18_01-56-40
  done: true
  experiment_id: fdb9860db5c74bf687d1bd3d58744822
  experiment_tag: 85_batch_size=32,eta=0.0,lr=5,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9770
  time_since_restore: 3576.049563884735
  time_this_iter_s: 3576.049563884735
  time_total_s: 3576.049563884735
  timestamp: 1616029000
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00085
  
[2m[36m(pid=44128)[0m Starting run with seed 0 - lr 0.01 - sec_lr 2 - bs 32
[2m[36m(pid=44128)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44128)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=44128)[0m GPU available: False, used: False
[2m[36m(pid=44128)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44128)[0m 
[2m[36m(pid=44128)[0m   | Name      | Type              | Params
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44128)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44128)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 12.0 K    Trainable params
[2m[36m(pid=44128)[0m 0         Non-trainable params
[2m[36m(pid=44128)[0m 12.0 K    Total params
[2m[36m(pid=44128)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=44128)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=44128)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=44128)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28610)[0m time to fit was 421.9872851371765
[2m[36m(pid=28610)[0m GPU available: False, used: False
[2m[36m(pid=28610)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28610)[0m 
[2m[36m(pid=28610)[0m   | Name      | Type              | Params
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28610)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28610)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 12.0 K    Trainable params
[2m[36m(pid=28610)[0m 0         Non-trainable params
[2m[36m(pid=28610)[0m 12.0 K    Total params
[2m[36m(pid=40957)[0m time to fit was 98.9633047580719
[2m[36m(pid=40957)[0m GPU available: False, used: False
[2m[36m(pid=40957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=40957)[0m 
[2m[36m(pid=40957)[0m   | Name      | Type              | Params
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=40957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=40957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 12.0 K    Trainable params
[2m[36m(pid=40957)[0m 0         Non-trainable params
[2m[36m(pid=40957)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m time to fit was 94.89644289016724
[2m[36m(pid=41450)[0m GPU available: False, used: False
[2m[36m(pid=41450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41450)[0m 
[2m[36m(pid=41450)[0m   | Name      | Type              | Params
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 12.0 K    Trainable params
[2m[36m(pid=41450)[0m 0         Non-trainable params
[2m[36m(pid=41450)[0m 12.0 K    Total params
[2m[36m(pid=16989)[0m time to fit was 238.0004870891571
[2m[36m(pid=16989)[0m GPU available: False, used: False
[2m[36m(pid=16989)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16989)[0m 
[2m[36m(pid=16989)[0m   | Name      | Type              | Params
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16989)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16989)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 12.0 K    Trainable params
[2m[36m(pid=16989)[0m 0         Non-trainable params
[2m[36m(pid=16989)[0m 12.0 K    Total params
[2m[36m(pid=36015)[0m time to fit was 122.62867641448975
Result for _inner_e98d6_00112:
  auc: 0.8198610305786133
  date: 2021-03-18_01-57-43
  done: false
  experiment_id: ecd6e98fc0084ac98a9b4a85b1b3a0e3
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36015
  time_since_restore: 958.038952589035
  time_this_iter_s: 958.038952589035
  time_total_s: 958.038952589035
  timestamp: 1616029063
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00112
  
[2m[36m(pid=36015)[0m Finished run with seed 0 - lr 2 - sec_lr 1 - bs 128 - mean val auc: 0.8198610305786133
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 127/180 (1 PENDING, 26 RUNNING, 100 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00126 | PENDING    |       |           64 |     0 | 0.01  |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 107 more trials not shown (16 RUNNING, 90 TERMINATED)


Result for _inner_e98d6_00112:
  auc: 0.8198610305786133
  date: 2021-03-18_01-57-43
  done: true
  experiment_id: ecd6e98fc0084ac98a9b4a85b1b3a0e3
  experiment_tag: 112_batch_size=128,eta=0.0,lr=2,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36015
  time_since_restore: 958.038952589035
  time_this_iter_s: 958.038952589035
  time_total_s: 958.038952589035
  timestamp: 1616029063
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00112
  
[2m[36m(pid=46560)[0m Starting run with seed 0 - lr 0.01 - sec_lr 2 - bs 64
[2m[36m(pid=46560)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46560)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=46560)[0m GPU available: False, used: False
[2m[36m(pid=46560)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=46560)[0m 
[2m[36m(pid=46560)[0m   | Name      | Type              | Params
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=46560)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=46560)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 12.0 K    Trainable params
[2m[36m(pid=46560)[0m 0         Non-trainable params
[2m[36m(pid=46560)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=46560)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=46560)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=46560)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=46560)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=46560)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20213)[0m time to fit was 124.03318810462952
[2m[36m(pid=20213)[0m GPU available: False, used: False
[2m[36m(pid=20213)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20213)[0m 
[2m[36m(pid=20213)[0m   | Name      | Type              | Params
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20213)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20213)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20213)[0m ------------------------------------------------
[2m[36m(pid=20213)[0m 12.0 K    Trainable params
[2m[36m(pid=20213)[0m 0         Non-trainable params
[2m[36m(pid=20213)[0m 12.0 K    Total params
[2m[36m(pid=30205)[0m time to fit was 243.23908805847168
[2m[36m(pid=30205)[0m GPU available: False, used: False
[2m[36m(pid=30205)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30205)[0m 
[2m[36m(pid=30205)[0m   | Name      | Type              | Params
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30205)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30205)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 12.0 K    Trainable params
[2m[36m(pid=30205)[0m 0         Non-trainable params
[2m[36m(pid=30205)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m time to fit was 88.45782089233398
[2m[36m(pid=41450)[0m GPU available: False, used: False
[2m[36m(pid=41450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41450)[0m 
[2m[36m(pid=41450)[0m   | Name      | Type              | Params
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 12.0 K    Trainable params
[2m[36m(pid=41450)[0m 0         Non-trainable params
[2m[36m(pid=41450)[0m 12.0 K    Total params
[2m[36m(pid=35186)[0m time to fit was 247.70953702926636
[2m[36m(pid=35186)[0m GPU available: False, used: False
[2m[36m(pid=35186)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35186)[0m 
[2m[36m(pid=35186)[0m   | Name      | Type              | Params
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35186)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35186)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 12.0 K    Trainable params
[2m[36m(pid=35186)[0m 0         Non-trainable params
[2m[36m(pid=35186)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m time to fit was 426.26009941101074
[2m[36m(pid=36103)[0m GPU available: False, used: False
[2m[36m(pid=36103)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36103)[0m 
[2m[36m(pid=36103)[0m   | Name      | Type              | Params
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36103)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36103)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 12.0 K    Trainable params
[2m[36m(pid=36103)[0m 0         Non-trainable params
[2m[36m(pid=36103)[0m 12.0 K    Total params
[2m[36m(pid=40957)[0m time to fit was 118.78290367126465
[2m[36m(pid=40957)[0m GPU available: False, used: False
[2m[36m(pid=40957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=40957)[0m 
[2m[36m(pid=40957)[0m   | Name      | Type              | Params
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=40957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=40957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 12.0 K    Trainable params
[2m[36m(pid=40957)[0m 0         Non-trainable params
[2m[36m(pid=40957)[0m 12.0 K    Total params
[2m[36m(pid=16679)[0m time to fit was 425.0238139629364
[2m[36m(pid=16679)[0m GPU available: False, used: False
[2m[36m(pid=16679)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16679)[0m 
[2m[36m(pid=16679)[0m   | Name      | Type              | Params
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16679)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16679)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 12.0 K    Trainable params
[2m[36m(pid=16679)[0m 0         Non-trainable params
[2m[36m(pid=16679)[0m 12.0 K    Total params
[2m[36m(pid=16989)[0m time to fit was 218.2722418308258
[2m[36m(pid=16989)[0m GPU available: False, used: False
[2m[36m(pid=16989)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16989)[0m 
[2m[36m(pid=16989)[0m   | Name      | Type              | Params
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16989)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16989)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 12.0 K    Trainable params
[2m[36m(pid=16989)[0m 0         Non-trainable params
[2m[36m(pid=16989)[0m 12.0 K    Total params
[2m[36m(pid=22450)[0m time to fit was 430.0716495513916
Result for _inner_e98d6_00100:
  auc: 0.8861539602279663
  date: 2021-03-18_02-01-04
  done: false
  experiment_id: 7d961e5241a94a4f8266624bc2b26799
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22450
  time_since_restore: 2157.0419702529907
  time_this_iter_s: 2157.0419702529907
  time_total_s: 2157.0419702529907
  timestamp: 1616029264
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00100
  
[2m[36m(pid=22450)[0m Finished run with seed 0 - lr 0.1 - sec_lr 1 - bs 32 - mean val auc: 0.8861539602279663
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 128/180 (1 PENDING, 26 RUNNING, 101 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00127 | PENDING    |       |          128 |     0 | 0.01  |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 108 more trials not shown (16 RUNNING, 91 TERMINATED)


Result for _inner_e98d6_00100:
  auc: 0.8861539602279663
  date: 2021-03-18_02-01-04
  done: true
  experiment_id: 7d961e5241a94a4f8266624bc2b26799
  experiment_tag: 100_batch_size=32,eta=0.0,lr=0.1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22450
  time_since_restore: 2157.0419702529907
  time_this_iter_s: 2157.0419702529907
  time_total_s: 2157.0419702529907
  timestamp: 1616029264
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00100
  
[2m[36m(pid=1306)[0m Starting run with seed 0 - lr 0.01 - sec_lr 2 - bs 128
[2m[36m(pid=1306)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1306)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=1306)[0m GPU available: False, used: False
[2m[36m(pid=1306)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1306)[0m 
[2m[36m(pid=1306)[0m   | Name      | Type              | Params
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1306)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1306)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 12.0 K    Trainable params
[2m[36m(pid=1306)[0m 0         Non-trainable params
[2m[36m(pid=1306)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=1306)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=1306)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=1306)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=1306)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=1306)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35186)[0m time to fit was 145.41120886802673
[2m[36m(pid=35186)[0m GPU available: False, used: False
[2m[36m(pid=35186)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35186)[0m 
[2m[36m(pid=35186)[0m   | Name      | Type              | Params
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35186)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35186)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 12.0 K    Trainable params
[2m[36m(pid=35186)[0m 0         Non-trainable params
[2m[36m(pid=35186)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m time to fit was 217.56051683425903
[2m[36m(pid=46560)[0m GPU available: False, used: False
[2m[36m(pid=46560)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=46560)[0m 
[2m[36m(pid=46560)[0m   | Name      | Type              | Params
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=46560)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=46560)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 12.0 K    Trainable params
[2m[36m(pid=46560)[0m 0         Non-trainable params
[2m[36m(pid=46560)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m time to fit was 179.30909085273743
[2m[36m(pid=41450)[0m GPU available: False, used: False
[2m[36m(pid=41450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41450)[0m 
[2m[36m(pid=41450)[0m   | Name      | Type              | Params
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 12.0 K    Trainable params
[2m[36m(pid=41450)[0m 0         Non-trainable params
[2m[36m(pid=41450)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m time to fit was 512.4143481254578
[2m[36m(pid=36194)[0m GPU available: False, used: False
[2m[36m(pid=36194)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36194)[0m 
[2m[36m(pid=36194)[0m   | Name      | Type              | Params
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36194)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36194)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36194)[0m ------------------------------------------------
[2m[36m(pid=36194)[0m 12.0 K    Trainable params
[2m[36m(pid=36194)[0m 0         Non-trainable params
[2m[36m(pid=36194)[0m 12.0 K    Total params
[2m[36m(pid=30205)[0m time to fit was 250.05948758125305
[2m[36m(pid=30205)[0m GPU available: False, used: False
[2m[36m(pid=30205)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30205)[0m 
[2m[36m(pid=30205)[0m   | Name      | Type              | Params
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30205)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30205)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 12.0 K    Trainable params
[2m[36m(pid=30205)[0m 0         Non-trainable params
[2m[36m(pid=30205)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m time to fit was 89.61287188529968
[2m[36m(pid=41450)[0m GPU available: False, used: False
[2m[36m(pid=41450)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41450)[0m 
[2m[36m(pid=41450)[0m   | Name      | Type              | Params
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41450)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41450)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41450)[0m ------------------------------------------------
[2m[36m(pid=41450)[0m 12.0 K    Trainable params
[2m[36m(pid=41450)[0m 0         Non-trainable params
[2m[36m(pid=41450)[0m 12.0 K    Total params
[2m[36m(pid=20213)[0m time to fit was 314.00991129875183
Result for _inner_e98d6_00117:
  auc: 0.7051670551300049
  date: 2021-03-18_02-03-19
  done: false
  experiment_id: b1206db8f8c8496d8ec1eb1de963f98c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20213
  time_since_restore: 1005.639458656311
  time_this_iter_s: 1005.639458656311
  time_total_s: 1005.639458656311
  timestamp: 1616029399
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00117
  
[2m[36m(pid=20213)[0m Finished run with seed 0 - lr 5 - sec_lr 1 - bs 128 - mean val auc: 0.7051670551300049
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 129/180 (1 PENDING, 26 RUNNING, 102 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00128 | PENDING    |       |          256 |     0 | 0.01  |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 109 more trials not shown (16 RUNNING, 92 TERMINATED)


Result for _inner_e98d6_00117:
  auc: 0.7051670551300049
  date: 2021-03-18_02-03-19
  done: true
  experiment_id: b1206db8f8c8496d8ec1eb1de963f98c
  experiment_tag: 117_batch_size=128,eta=0.0,lr=5,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20213
  time_since_restore: 1005.639458656311
  time_this_iter_s: 1005.639458656311
  time_total_s: 1005.639458656311
  timestamp: 1616029399
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00117
  
[2m[36m(pid=35186)[0m time to fit was 124.92495656013489
[2m[36m(pid=35186)[0m GPU available: False, used: False
[2m[36m(pid=35186)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35186)[0m 
[2m[36m(pid=35186)[0m   | Name      | Type              | Params
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35186)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35186)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35186)[0m ------------------------------------------------
[2m[36m(pid=35186)[0m 12.0 K    Trainable params
[2m[36m(pid=35186)[0m 0         Non-trainable params
[2m[36m(pid=35186)[0m 12.0 K    Total params
[2m[36m(pid=6601)[0m Starting run with seed 0 - lr 0.01 - sec_lr 2 - bs 256
[2m[36m(pid=6601)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=6601)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=6601)[0m GPU available: False, used: False
[2m[36m(pid=6601)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6601)[0m 
[2m[36m(pid=6601)[0m   | Name      | Type              | Params
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6601)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6601)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 12.0 K    Trainable params
[2m[36m(pid=6601)[0m 0         Non-trainable params
[2m[36m(pid=6601)[0m 12.0 K    Total params
[2m[36m(pid=6601)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6601)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6601)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6601)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6601)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=6601)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m time to fit was 416.78164196014404
[2m[36m(pid=44128)[0m GPU available: False, used: False
[2m[36m(pid=44128)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44128)[0m 
[2m[36m(pid=44128)[0m   | Name      | Type              | Params
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44128)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44128)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 12.0 K    Trainable params
[2m[36m(pid=44128)[0m 0         Non-trainable params
[2m[36m(pid=44128)[0m 12.0 K    Total params
[2m[36m(pid=36034)[0m time to fit was 492.7593185901642
[2m[36m(pid=36034)[0m GPU available: False, used: False
[2m[36m(pid=36034)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36034)[0m 
[2m[36m(pid=36034)[0m   | Name      | Type              | Params
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36034)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36034)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36034)[0m ------------------------------------------------
[2m[36m(pid=36034)[0m 12.0 K    Trainable params
[2m[36m(pid=36034)[0m 0         Non-trainable params
[2m[36m(pid=36034)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m time to fit was 155.20688390731812
[2m[36m(pid=1306)[0m GPU available: False, used: False
[2m[36m(pid=1306)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1306)[0m 
[2m[36m(pid=1306)[0m   | Name      | Type              | Params
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1306)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1306)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 12.0 K    Trainable params
[2m[36m(pid=1306)[0m 0         Non-trainable params
[2m[36m(pid=1306)[0m 12.0 K    Total params
[2m[36m(pid=28610)[0m time to fit was 425.81807923316956
[2m[36m(pid=28610)[0m GPU available: False, used: False
[2m[36m(pid=28610)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28610)[0m 
[2m[36m(pid=28610)[0m   | Name      | Type              | Params
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28610)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28610)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 12.0 K    Trainable params
[2m[36m(pid=28610)[0m 0         Non-trainable params
[2m[36m(pid=28610)[0m 12.0 K    Total params
[2m[36m(pid=41450)[0m time to fit was 104.5036039352417
Result for _inner_e98d6_00124:
  auc: 0.8333420872688293
  date: 2021-03-18_02-05-00
  done: false
  experiment_id: 38984e57a847495e9ff17dab39c27c50
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41450
  time_since_restore: 558.085987329483
  time_this_iter_s: 558.085987329483
  time_total_s: 558.085987329483
  timestamp: 1616029500
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00124
  
[2m[36m(pid=41450)[0m Finished run with seed 0 - lr 0.001 - sec_lr 2 - bs 512 - mean val auc: 0.8333420872688293
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 130/180 (1 PENDING, 26 RUNNING, 103 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00129 | PENDING    |       |          512 |     0 | 0.01  |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 110 more trials not shown (16 RUNNING, 93 TERMINATED)


Result for _inner_e98d6_00124:
  auc: 0.8333420872688293
  date: 2021-03-18_02-05-00
  done: true
  experiment_id: 38984e57a847495e9ff17dab39c27c50
  experiment_tag: 124_batch_size=512,eta=0.0,lr=0.001,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41450
  time_since_restore: 558.085987329483
  time_this_iter_s: 558.085987329483
  time_total_s: 558.085987329483
  timestamp: 1616029500
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00124
  
[2m[36m(pid=10988)[0m Starting run with seed 0 - lr 0.01 - sec_lr 2 - bs 512
[2m[36m(pid=10988)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10988)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=10988)[0m GPU available: False, used: False
[2m[36m(pid=10988)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10988)[0m 
[2m[36m(pid=10988)[0m   | Name      | Type              | Params
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10988)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10988)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 12.0 K    Trainable params
[2m[36m(pid=10988)[0m 0         Non-trainable params
[2m[36m(pid=10988)[0m 12.0 K    Total params
[2m[36m(pid=10988)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=10988)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=10988)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=10988)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=10988)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=10988)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=16989)[0m time to fit was 281.69614839553833
[2m[36m(pid=16989)[0m GPU available: False, used: False
[2m[36m(pid=16989)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16989)[0m 
[2m[36m(pid=16989)[0m   | Name      | Type              | Params
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16989)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16989)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16989)[0m ------------------------------------------------
[2m[36m(pid=16989)[0m 12.0 K    Trainable params
[2m[36m(pid=16989)[0m 0         Non-trainable params
[2m[36m(pid=16989)[0m 12.0 K    Total params
[2m[36m(pid=35186)[0m time to fit was 136.84333729743958
Result for _inner_e98d6_00122:
  auc: 0.7957388997077942
  date: 2021-03-18_02-05-46
  done: false
  experiment_id: b96094f7aa194975a9c34f2b2f52ec8c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35186
  time_since_restore: 778.9540493488312
  time_this_iter_s: 778.9540493488312
  time_total_s: 778.9540493488312
  timestamp: 1616029546
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00122
  
[2m[36m(pid=35186)[0m Finished run with seed 0 - lr 0.001 - sec_lr 2 - bs 128 - mean val auc: 0.7957388997077942
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 131/180 (1 PENDING, 26 RUNNING, 104 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00130 | PENDING    |       |           32 |     0 | 0.1   |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 111 more trials not shown (16 RUNNING, 94 TERMINATED)


Result for _inner_e98d6_00122:
  auc: 0.7957388997077942
  date: 2021-03-18_02-05-46
  done: true
  experiment_id: b96094f7aa194975a9c34f2b2f52ec8c
  experiment_tag: 122_batch_size=128,eta=0.0,lr=0.001,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35186
  time_since_restore: 778.9540493488312
  time_this_iter_s: 778.9540493488312
  time_total_s: 778.9540493488312
  timestamp: 1616029546
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00122
  
[2m[36m(pid=12738)[0m Starting run with seed 0 - lr 0.1 - sec_lr 2 - bs 32
[2m[36m(pid=12738)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12738)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=12738)[0m GPU available: False, used: False
[2m[36m(pid=12738)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12738)[0m 
[2m[36m(pid=12738)[0m   | Name      | Type              | Params
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12738)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12738)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 12.0 K    Trainable params
[2m[36m(pid=12738)[0m 0         Non-trainable params
[2m[36m(pid=12738)[0m 12.0 K    Total params
[2m[36m(pid=12738)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=12738)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12738)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=12738)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12738)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=12738)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30205)[0m time to fit was 226.07510328292847
[2m[36m(pid=30205)[0m GPU available: False, used: False
[2m[36m(pid=30205)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30205)[0m 
[2m[36m(pid=30205)[0m   | Name      | Type              | Params
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30205)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30205)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30205)[0m ------------------------------------------------
[2m[36m(pid=30205)[0m 12.0 K    Trainable params
[2m[36m(pid=30205)[0m 0         Non-trainable params
[2m[36m(pid=30205)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m time to fit was 464.71267795562744
[2m[36m(pid=36103)[0m GPU available: False, used: False
[2m[36m(pid=36103)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36103)[0m 
[2m[36m(pid=36103)[0m   | Name      | Type              | Params
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36103)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36103)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36103)[0m ------------------------------------------------
[2m[36m(pid=36103)[0m 12.0 K    Trainable params
[2m[36m(pid=36103)[0m 0         Non-trainable params
[2m[36m(pid=36103)[0m 12.0 K    Total params
[2m[36m(pid=10988)[0m time to fit was 105.11131715774536
[2m[36m(pid=10988)[0m GPU available: False, used: False
[2m[36m(pid=10988)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10988)[0m 
[2m[36m(pid=10988)[0m   | Name      | Type              | Params
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10988)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10988)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 12.0 K    Trainable params
[2m[36m(pid=10988)[0m 0         Non-trainable params
[2m[36m(pid=10988)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m time to fit was 340.3570976257324
[2m[36m(pid=46560)[0m GPU available: False, used: False
[2m[36m(pid=46560)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=46560)[0m 
[2m[36m(pid=46560)[0m   | Name      | Type              | Params
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=46560)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=46560)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 12.0 K    Trainable params
[2m[36m(pid=46560)[0m 0         Non-trainable params
[2m[36m(pid=46560)[0m 12.0 K    Total params
[2m[36m(pid=21672)[0m time to fit was 1697.1360654830933
[2m[36m(pid=21672)[0m GPU available: False, used: False
[2m[36m(pid=21672)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21672)[0m 
[2m[36m(pid=21672)[0m   | Name      | Type              | Params
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21672)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21672)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21672)[0m ------------------------------------------------
[2m[36m(pid=21672)[0m 12.0 K    Trainable params
[2m[36m(pid=21672)[0m 0         Non-trainable params
[2m[36m(pid=21672)[0m 12.0 K    Total params
[2m[36m(pid=10988)[0m time to fit was 64.623366355896
[2m[36m(pid=10988)[0m GPU available: False, used: False
[2m[36m(pid=10988)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10988)[0m 
[2m[36m(pid=10988)[0m   | Name      | Type              | Params
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10988)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10988)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 12.0 K    Trainable params
[2m[36m(pid=10988)[0m 0         Non-trainable params
[2m[36m(pid=10988)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m time to fit was 255.28856563568115
[2m[36m(pid=1306)[0m GPU available: False, used: False
[2m[36m(pid=1306)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1306)[0m 
[2m[36m(pid=1306)[0m   | Name      | Type              | Params
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1306)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1306)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 12.0 K    Trainable params
[2m[36m(pid=1306)[0m 0         Non-trainable params
[2m[36m(pid=1306)[0m 12.0 K    Total params
[2m[36m(pid=6601)[0m time to fit was 281.81374621391296
[2m[36m(pid=6601)[0m GPU available: False, used: False
[2m[36m(pid=6601)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6601)[0m 
[2m[36m(pid=6601)[0m   | Name      | Type              | Params
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6601)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6601)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 12.0 K    Trainable params
[2m[36m(pid=6601)[0m 0         Non-trainable params
[2m[36m(pid=6601)[0m 12.0 K    Total params
[2m[36m(pid=36194)[0m time to fit was 427.1703338623047
[2m[36m(pid=36194)[0m Finished run with seed 0 - lr 1 - sec_lr 1 - bs 32 - mean val auc: 0.8842577338218689
Result for _inner_e98d6_00105:
  auc: 0.8842577338218689
  date: 2021-03-18_02-09-31
  done: false
  experiment_id: 95106a7e948044f8a6ee5d3d7ddfe32d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36194
  time_since_restore: 2300.77232837677
  time_this_iter_s: 2300.77232837677
  time_total_s: 2300.77232837677
  timestamp: 1616029771
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00105
  
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 132/180 (1 PENDING, 26 RUNNING, 105 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00131 | PENDING    |       |           64 |     0 | 0.1   |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 112 more trials not shown (16 RUNNING, 95 TERMINATED)


Result for _inner_e98d6_00105:
  auc: 0.8842577338218689
  date: 2021-03-18_02-09-31
  done: true
  experiment_id: 95106a7e948044f8a6ee5d3d7ddfe32d
  experiment_tag: 105_batch_size=32,eta=0.0,lr=1,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36194
  time_since_restore: 2300.77232837677
  time_this_iter_s: 2300.77232837677
  time_total_s: 2300.77232837677
  timestamp: 1616029771
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00105
  
[2m[36m(pid=10988)[0m time to fit was 99.60798907279968
[2m[36m(pid=10988)[0m GPU available: False, used: False
[2m[36m(pid=10988)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10988)[0m 
[2m[36m(pid=10988)[0m   | Name      | Type              | Params
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10988)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10988)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 12.0 K    Trainable params
[2m[36m(pid=10988)[0m 0         Non-trainable params
[2m[36m(pid=10988)[0m 12.0 K    Total params
[2m[36m(pid=21475)[0m Starting run with seed 0 - lr 0.1 - sec_lr 2 - bs 64
[2m[36m(pid=21475)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21475)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=21475)[0m GPU available: False, used: False
[2m[36m(pid=21475)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21475)[0m 
[2m[36m(pid=21475)[0m   | Name      | Type              | Params
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21475)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21475)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 12.0 K    Trainable params
[2m[36m(pid=21475)[0m 0         Non-trainable params
[2m[36m(pid=21475)[0m 12.0 K    Total params
[2m[36m(pid=21475)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21475)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21475)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=21475)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21475)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=21475)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6601)[0m time to fit was 113.68058252334595
[2m[36m(pid=6601)[0m GPU available: False, used: False
[2m[36m(pid=6601)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6601)[0m 
[2m[36m(pid=6601)[0m   | Name      | Type              | Params
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6601)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6601)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 12.0 K    Trainable params
[2m[36m(pid=6601)[0m 0         Non-trainable params
[2m[36m(pid=6601)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m time to fit was 132.04316973686218
[2m[36m(pid=1306)[0m GPU available: False, used: False
[2m[36m(pid=1306)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1306)[0m 
[2m[36m(pid=1306)[0m   | Name      | Type              | Params
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1306)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1306)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 12.0 K    Trainable params
[2m[36m(pid=1306)[0m 0         Non-trainable params
[2m[36m(pid=1306)[0m 12.0 K    Total params
[2m[36m(pid=30205)[0m time to fit was 225.40573072433472
Result for _inner_e98d6_00121:
  auc: 0.8312929511070252
  date: 2021-03-18_02-10-26
  done: false
  experiment_id: a2c171f337904c538e6275eba1109c63
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30205
  time_since_restore: 1190.7171759605408
  time_this_iter_s: 1190.7171759605408
  time_total_s: 1190.7171759605408
  timestamp: 1616029826
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00121
  
[2m[36m(pid=30205)[0m Finished run with seed 0 - lr 0.001 - sec_lr 2 - bs 64 - mean val auc: 0.8312929511070252
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 133/180 (1 PENDING, 26 RUNNING, 106 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00132 | PENDING    |       |          128 |     0 | 0.1   |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 113 more trials not shown (16 RUNNING, 96 TERMINATED)


Result for _inner_e98d6_00121:
  auc: 0.8312929511070252
  date: 2021-03-18_02-10-26
  done: true
  experiment_id: a2c171f337904c538e6275eba1109c63
  experiment_tag: 121_batch_size=64,eta=0.0,lr=0.001,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30205
  time_since_restore: 1190.7171759605408
  time_this_iter_s: 1190.7171759605408
  time_total_s: 1190.7171759605408
  timestamp: 1616029826
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00121
  
[2m[36m(pid=23882)[0m Starting run with seed 0 - lr 0.1 - sec_lr 2 - bs 128
[2m[36m(pid=23882)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23882)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=23882)[0m GPU available: False, used: False
[2m[36m(pid=23882)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23882)[0m 
[2m[36m(pid=23882)[0m   | Name      | Type              | Params
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23882)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23882)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 12.0 K    Trainable params
[2m[36m(pid=23882)[0m 0         Non-trainable params
[2m[36m(pid=23882)[0m 12.0 K    Total params
[2m[36m(pid=23882)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23882)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23882)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23882)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23882)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=23882)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m time to fit was 420.1302649974823
[2m[36m(pid=44128)[0m GPU available: False, used: False
[2m[36m(pid=44128)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44128)[0m 
[2m[36m(pid=44128)[0m   | Name      | Type              | Params
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44128)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44128)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 12.0 K    Trainable params
[2m[36m(pid=44128)[0m 0         Non-trainable params
[2m[36m(pid=44128)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m time to fit was 221.4382781982422
[2m[36m(pid=46560)[0m GPU available: False, used: False
[2m[36m(pid=46560)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=46560)[0m 
[2m[36m(pid=46560)[0m   | Name      | Type              | Params
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=46560)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=46560)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 12.0 K    Trainable params
[2m[36m(pid=46560)[0m 0         Non-trainable params
[2m[36m(pid=46560)[0m 12.0 K    Total params
[2m[36m(pid=10988)[0m time to fit was 76.9010317325592
[2m[36m(pid=10988)[0m GPU available: False, used: False
[2m[36m(pid=10988)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10988)[0m 
[2m[36m(pid=10988)[0m   | Name      | Type              | Params
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10988)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10988)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10988)[0m ------------------------------------------------
[2m[36m(pid=10988)[0m 12.0 K    Trainable params
[2m[36m(pid=10988)[0m 0         Non-trainable params
[2m[36m(pid=10988)[0m 12.0 K    Total params
[2m[36m(pid=36034)[0m time to fit was 433.8705577850342
Result for _inner_e98d6_00111:
  auc: 0.8039749026298523
  date: 2021-03-18_02-11-04
  done: false
  experiment_id: 6c30b9c633cd4804b2a2aa3f705b3a67
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36034
  time_since_restore: 1985.0721898078918
  time_this_iter_s: 1985.0721898078918
  time_total_s: 1985.0721898078918
  timestamp: 1616029864
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00111
  
[2m[36m(pid=36034)[0m Finished run with seed 0 - lr 2 - sec_lr 1 - bs 64 - mean val auc: 0.8039749026298523
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 134/180 (1 PENDING, 26 RUNNING, 107 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00133 | PENDING    |       |          256 |     0 | 0.1   |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 114 more trials not shown (16 RUNNING, 97 TERMINATED)


Result for _inner_e98d6_00111:
  auc: 0.8039749026298523
  date: 2021-03-18_02-11-04
  done: true
  experiment_id: 6c30b9c633cd4804b2a2aa3f705b3a67
  experiment_tag: 111_batch_size=64,eta=0.0,lr=2,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36034
  time_since_restore: 1985.0721898078918
  time_this_iter_s: 1985.0721898078918
  time_total_s: 1985.0721898078918
  timestamp: 1616029864
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00111
  
[2m[36m(pid=40957)[0m time to fit was 725.4740586280823
[2m[36m(pid=40957)[0m GPU available: False, used: False
[2m[36m(pid=40957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=40957)[0m 
[2m[36m(pid=40957)[0m   | Name      | Type              | Params
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=40957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=40957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 12.0 K    Trainable params
[2m[36m(pid=40957)[0m 0         Non-trainable params
[2m[36m(pid=40957)[0m 12.0 K    Total params
[2m[36m(pid=28610)[0m time to fit was 434.11664390563965
[2m[36m(pid=28610)[0m GPU available: False, used: False
[2m[36m(pid=28610)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28610)[0m 
[2m[36m(pid=28610)[0m   | Name      | Type              | Params
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28610)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28610)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 12.0 K    Trainable params
[2m[36m(pid=28610)[0m 0         Non-trainable params
[2m[36m(pid=28610)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m Starting run with seed 0 - lr 0.1 - sec_lr 2 - bs 256
[2m[36m(pid=25379)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25379)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=25379)[0m GPU available: False, used: False
[2m[36m(pid=25379)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m   | Name      | Type              | Params
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25379)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25379)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 12.0 K    Trainable params
[2m[36m(pid=25379)[0m 0         Non-trainable params
[2m[36m(pid=25379)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25379)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25379)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25379)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25379)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=25379)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6601)[0m time to fit was 101.48949980735779
[2m[36m(pid=6601)[0m GPU available: False, used: False
[2m[36m(pid=6601)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6601)[0m 
[2m[36m(pid=6601)[0m   | Name      | Type              | Params
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6601)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6601)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 12.0 K    Trainable params
[2m[36m(pid=6601)[0m 0         Non-trainable params
[2m[36m(pid=6601)[0m 12.0 K    Total params
[2m[36m(pid=16679)[0m time to fit was 693.7561600208282
[2m[36m(pid=16679)[0m GPU available: False, used: False
[2m[36m(pid=16679)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16679)[0m 
[2m[36m(pid=16679)[0m   | Name      | Type              | Params
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16679)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16679)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 12.0 K    Trainable params
[2m[36m(pid=16679)[0m 0         Non-trainable params
[2m[36m(pid=16679)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m time to fit was 85.71864247322083
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m GPU available: False, used: False
[2m[36m(pid=25379)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m   | Name      | Type              | Params
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25379)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25379)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 12.0 K    Trainable params
[2m[36m(pid=25379)[0m 0         Non-trainable params
[2m[36m(pid=25379)[0m 12.0 K    Total params
[2m[36m(pid=40957)[0m time to fit was 93.69221997261047
[2m[36m(pid=40957)[0m GPU available: False, used: False
[2m[36m(pid=40957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=40957)[0m 
[2m[36m(pid=40957)[0m   | Name      | Type              | Params
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=40957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=40957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=40957)[0m ------------------------------------------------
[2m[36m(pid=40957)[0m 12.0 K    Trainable params
[2m[36m(pid=40957)[0m 0         Non-trainable params
[2m[36m(pid=40957)[0m 12.0 K    Total params
[2m[36m(pid=23882)[0m time to fit was 135.14780855178833
[2m[36m(pid=23882)[0m GPU available: False, used: False
[2m[36m(pid=23882)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23882)[0m 
[2m[36m(pid=23882)[0m   | Name      | Type              | Params
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23882)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23882)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 12.0 K    Trainable params
[2m[36m(pid=23882)[0m 0         Non-trainable params
[2m[36m(pid=23882)[0m 12.0 K    Total params
[2m[36m(pid=12738)[0m time to fit was 422.2321135997772
[2m[36m(pid=12738)[0m GPU available: False, used: False
[2m[36m(pid=12738)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12738)[0m 
[2m[36m(pid=12738)[0m   | Name      | Type              | Params
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12738)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12738)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 12.0 K    Trainable params
[2m[36m(pid=12738)[0m 0         Non-trainable params
[2m[36m(pid=12738)[0m 12.0 K    Total params
[2m[36m(pid=10988)[0m time to fit was 131.02639985084534
Result for _inner_e98d6_00129:
  auc: 0.9023216485977172
  date: 2021-03-18_02-13-10
  done: false
  experiment_id: bd20541aa8924a57a1b7294aab8f5408
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 10988
  time_since_restore: 478.6191987991333
  time_this_iter_s: 478.6191987991333
  time_total_s: 478.6191987991333
  timestamp: 1616029990
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00129
  
[2m[36m(pid=10988)[0m Finished run with seed 0 - lr 0.01 - sec_lr 2 - bs 512 - mean val auc: 0.9023216485977172
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 135/180 (1 PENDING, 26 RUNNING, 108 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00134 | PENDING    |       |          512 |     0 | 0.1   |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 115 more trials not shown (16 RUNNING, 98 TERMINATED)


Result for _inner_e98d6_00129:
  auc: 0.9023216485977172
  date: 2021-03-18_02-13-10
  done: true
  experiment_id: bd20541aa8924a57a1b7294aab8f5408
  experiment_tag: 129_batch_size=512,eta=0.0,lr=0.01,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 10988
  time_since_restore: 478.6191987991333
  time_this_iter_s: 478.6191987991333
  time_total_s: 478.6191987991333
  timestamp: 1616029990
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00129
  
[2m[36m(pid=30571)[0m Starting run with seed 0 - lr 0.1 - sec_lr 2 - bs 512
[2m[36m(pid=30571)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30571)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30571)[0m GPU available: False, used: False
[2m[36m(pid=30571)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30571)[0m 
[2m[36m(pid=30571)[0m   | Name      | Type              | Params
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30571)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30571)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 12.0 K    Trainable params
[2m[36m(pid=30571)[0m 0         Non-trainable params
[2m[36m(pid=30571)[0m 12.0 K    Total params
[2m[36m(pid=30571)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30571)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30571)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30571)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30571)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30571)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21475)[0m time to fit was 224.49823021888733
[2m[36m(pid=21475)[0m GPU available: False, used: False
[2m[36m(pid=21475)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21475)[0m 
[2m[36m(pid=21475)[0m   | Name      | Type              | Params
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21475)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21475)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 12.0 K    Trainable params
[2m[36m(pid=21475)[0m 0         Non-trainable params
[2m[36m(pid=21475)[0m 12.0 K    Total params
[2m[36m(pid=36103)[0m time to fit was 429.87991213798523
Result for _inner_e98d6_00110:
  auc: 0.8040920495986938
  date: 2021-03-18_02-13-56
  done: false
  experiment_id: 263e1a1958cb44fda87f84abfcc2554e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36103
  time_since_restore: 2245.231014728546
  time_this_iter_s: 2245.231014728546
  time_total_s: 2245.231014728546
  timestamp: 1616030036
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00110
  
[2m[36m(pid=36103)[0m Finished run with seed 0 - lr 2 - sec_lr 1 - bs 32 - mean val auc: 0.8040920495986938
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 136/180 (1 PENDING, 26 RUNNING, 109 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00135 | PENDING    |       |           32 |     0 | 1     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 116 more trials not shown (16 RUNNING, 99 TERMINATED)


Result for _inner_e98d6_00110:
  auc: 0.8040920495986938
  date: 2021-03-18_02-13-56
  done: true
  experiment_id: 263e1a1958cb44fda87f84abfcc2554e
  experiment_tag: 110_batch_size=32,eta=0.0,lr=2,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36103
  time_since_restore: 2245.231014728546
  time_this_iter_s: 2245.231014728546
  time_total_s: 2245.231014728546
  timestamp: 1616030036
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00110
  
[2m[36m(pid=6601)[0m time to fit was 128.75075101852417
[2m[36m(pid=6601)[0m GPU available: False, used: False
[2m[36m(pid=6601)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6601)[0m 
[2m[36m(pid=6601)[0m   | Name      | Type              | Params
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6601)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6601)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6601)[0m ------------------------------------------------
[2m[36m(pid=6601)[0m 12.0 K    Trainable params
[2m[36m(pid=6601)[0m 0         Non-trainable params
[2m[36m(pid=6601)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m Starting run with seed 0 - lr 1 - sec_lr 2 - bs 32
[2m[36m(pid=32429)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=32429)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=32429)[0m GPU available: False, used: False
[2m[36m(pid=32429)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=32429)[0m 
[2m[36m(pid=32429)[0m   | Name      | Type              | Params
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=32429)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=32429)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 12.0 K    Trainable params
[2m[36m(pid=32429)[0m 0         Non-trainable params
[2m[36m(pid=32429)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=32429)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=32429)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=32429)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=32429)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=32429)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=40957)[0m time to fit was 100.4384777545929
Result for _inner_e98d6_00123:
  auc: 0.8625359892845154
  date: 2021-03-18_02-14-27
  done: false
  experiment_id: cb91d966a910401281f8e2220aa6c400
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 40957
  time_since_restore: 1138.832204580307
  time_this_iter_s: 1138.832204580307
  time_total_s: 1138.832204580307
  timestamp: 1616030067
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00123
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 137/180 (1 PENDING, 26 RUNNING, 110 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00136 | PENDING    |       |           64 |     0 | 1     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 117 more trials not shown (16 RUNNING, 100 TERMINATED)


[2m[36m(pid=40957)[0m Finished run with seed 0 - lr 0.001 - sec_lr 2 - bs 256 - mean val auc: 0.8625359892845154
Result for _inner_e98d6_00123:
  auc: 0.8625359892845154
  date: 2021-03-18_02-14-27
  done: true
  experiment_id: cb91d966a910401281f8e2220aa6c400
  experiment_tag: 123_batch_size=256,eta=0.0,lr=0.001,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 40957
  time_since_restore: 1138.832204580307
  time_this_iter_s: 1138.832204580307
  time_total_s: 1138.832204580307
  timestamp: 1616030067
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00123
  
[2m[36m(pid=30571)[0m time to fit was 65.1501693725586
[2m[36m(pid=30571)[0m GPU available: False, used: False
[2m[36m(pid=30571)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m time to fit was 105.23148226737976
[2m[36m(pid=30571)[0m 
[2m[36m(pid=30571)[0m   | Name      | Type              | Params
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30571)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30571)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 12.0 K    Trainable params
[2m[36m(pid=30571)[0m 0         Non-trainable params
[2m[36m(pid=30571)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m GPU available: False, used: False
[2m[36m(pid=25379)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m   | Name      | Type              | Params
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25379)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25379)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 12.0 K    Trainable params
[2m[36m(pid=25379)[0m 0         Non-trainable params
[2m[36m(pid=25379)[0m 12.0 K    Total params
[2m[36m(pid=33698)[0m Starting run with seed 0 - lr 1 - sec_lr 2 - bs 64
[2m[36m(pid=33698)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=33698)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=33698)[0m GPU available: False, used: False
[2m[36m(pid=33698)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33698)[0m 
[2m[36m(pid=33698)[0m   | Name      | Type              | Params
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33698)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33698)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 12.0 K    Trainable params
[2m[36m(pid=33698)[0m 0         Non-trainable params
[2m[36m(pid=33698)[0m 12.0 K    Total params
[2m[36m(pid=33698)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=33698)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33698)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=33698)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33698)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=33698)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23882)[0m time to fit was 122.99564218521118
[2m[36m(pid=23882)[0m GPU available: False, used: False
[2m[36m(pid=23882)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23882)[0m 
[2m[36m(pid=23882)[0m   | Name      | Type              | Params
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23882)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23882)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 12.0 K    Trainable params
[2m[36m(pid=23882)[0m 0         Non-trainable params
[2m[36m(pid=23882)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m time to fit was 306.64716506004333
[2m[36m(pid=1306)[0m GPU available: False, used: False
[2m[36m(pid=1306)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1306)[0m 
[2m[36m(pid=1306)[0m   | Name      | Type              | Params
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1306)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1306)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1306)[0m ------------------------------------------------
[2m[36m(pid=1306)[0m 12.0 K    Trainable params
[2m[36m(pid=1306)[0m 0         Non-trainable params
[2m[36m(pid=1306)[0m 12.0 K    Total params
[2m[36m(pid=30571)[0m time to fit was 60.10804891586304
[2m[36m(pid=30571)[0m GPU available: False, used: False
[2m[36m(pid=30571)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30571)[0m 
[2m[36m(pid=30571)[0m   | Name      | Type              | Params
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30571)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30571)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 12.0 K    Trainable params
[2m[36m(pid=30571)[0m 0         Non-trainable params
[2m[36m(pid=30571)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m time to fit was 79.03265166282654
[2m[36m(pid=25379)[0m GPU available: False, used: False
[2m[36m(pid=25379)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m   | Name      | Type              | Params
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25379)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25379)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 12.0 K    Trainable params
[2m[36m(pid=25379)[0m 0         Non-trainable params
[2m[36m(pid=25379)[0m 12.0 K    Total params
[2m[36m(pid=6601)[0m time to fit was 121.12271499633789
Result for _inner_e98d6_00128:
  auc: 0.9075439810752869
  date: 2021-03-18_02-16-00
  done: false
  experiment_id: 2858ae32ee7a498aa04d2b906c8975c5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6601
  time_since_restore: 748.2791199684143
  time_this_iter_s: 748.2791199684143
  time_total_s: 748.2791199684143
  timestamp: 1616030160
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00128
  
[2m[36m(pid=6601)[0m Finished run with seed 0 - lr 0.01 - sec_lr 2 - bs 256 - mean val auc: 0.9075439810752869
== Status ==
Memory usage on this node: 11.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 138/180 (1 PENDING, 26 RUNNING, 111 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00137 | PENDING    |       |          128 |     0 | 1     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 118 more trials not shown (16 RUNNING, 101 TERMINATED)


Result for _inner_e98d6_00128:
  auc: 0.9075439810752869
  date: 2021-03-18_02-16-00
  done: true
  experiment_id: 2858ae32ee7a498aa04d2b906c8975c5
  experiment_tag: 128_batch_size=256,eta=0.0,lr=0.01,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6601
  time_since_restore: 748.2791199684143
  time_this_iter_s: 748.2791199684143
  time_total_s: 748.2791199684143
  timestamp: 1616030160
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00128
  
[2m[36m(pid=37425)[0m Starting run with seed 0 - lr 1 - sec_lr 2 - bs 128
[2m[36m(pid=37425)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37425)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=37425)[0m GPU available: False, used: False
[2m[36m(pid=37425)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37425)[0m 
[2m[36m(pid=37425)[0m   | Name      | Type              | Params
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37425)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37425)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 12.0 K    Trainable params
[2m[36m(pid=37425)[0m 0         Non-trainable params
[2m[36m(pid=37425)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=37425)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=37425)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=37425)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=37425)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=37425)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30571)[0m time to fit was 63.00918173789978
[2m[36m(pid=30571)[0m GPU available: False, used: False
[2m[36m(pid=30571)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30571)[0m 
[2m[36m(pid=30571)[0m   | Name      | Type              | Params
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30571)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30571)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 12.0 K    Trainable params
[2m[36m(pid=30571)[0m 0         Non-trainable params
[2m[36m(pid=30571)[0m 12.0 K    Total params
[2m[36m(pid=23882)[0m time to fit was 123.79912614822388
[2m[36m(pid=23882)[0m GPU available: False, used: False
[2m[36m(pid=23882)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23882)[0m 
[2m[36m(pid=23882)[0m   | Name      | Type              | Params
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23882)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23882)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 12.0 K    Trainable params
[2m[36m(pid=23882)[0m 0         Non-trainable params
[2m[36m(pid=23882)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m time to fit was 79.30103468894958
[2m[36m(pid=25379)[0m GPU available: False, used: False
[2m[36m(pid=25379)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25379)[0m 
[2m[36m(pid=25379)[0m   | Name      | Type              | Params
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25379)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25379)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25379)[0m ------------------------------------------------
[2m[36m(pid=25379)[0m 12.0 K    Trainable params
[2m[36m(pid=25379)[0m 0         Non-trainable params
[2m[36m(pid=25379)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m time to fit was 1859.2701878547668
[2m[36m(pid=21741)[0m GPU available: False, used: False
[2m[36m(pid=21741)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21741)[0m 
[2m[36m(pid=21741)[0m   | Name      | Type              | Params
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21741)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21741)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21741)[0m ------------------------------------------------
[2m[36m(pid=21741)[0m 12.0 K    Trainable params
[2m[36m(pid=21741)[0m 0         Non-trainable params
[2m[36m(pid=21741)[0m 12.0 K    Total params
[2m[36m(pid=21475)[0m time to fit was 245.02731466293335
[2m[36m(pid=21475)[0m GPU available: False, used: False
[2m[36m(pid=21475)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21475)[0m 
[2m[36m(pid=21475)[0m   | Name      | Type              | Params
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21475)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21475)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 12.0 K    Trainable params
[2m[36m(pid=21475)[0m 0         Non-trainable params
[2m[36m(pid=21475)[0m 12.0 K    Total params
[2m[36m(pid=30571)[0m time to fit was 64.00577664375305
[2m[36m(pid=30571)[0m GPU available: False, used: False
[2m[36m(pid=30571)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30571)[0m 
[2m[36m(pid=30571)[0m   | Name      | Type              | Params
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30571)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30571)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30571)[0m ------------------------------------------------
[2m[36m(pid=30571)[0m 12.0 K    Trainable params
[2m[36m(pid=30571)[0m 0         Non-trainable params
[2m[36m(pid=30571)[0m 12.0 K    Total params
[2m[36m(pid=1306)[0m time to fit was 134.69224095344543
Result for _inner_e98d6_00127:
  auc: 0.9063852429389954
  date: 2021-03-18_02-17-42
  done: false
  experiment_id: 1b55d10a05e54187b73a02771e9312fe
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 1306
  time_since_restore: 985.3548965454102
  time_this_iter_s: 985.3548965454102
  time_total_s: 985.3548965454102
  timestamp: 1616030262
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00127
  
[2m[36m(pid=1306)[0m Finished run with seed 0 - lr 0.01 - sec_lr 2 - bs 128 - mean val auc: 0.9063852429389954
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 139/180 (1 PENDING, 26 RUNNING, 112 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00138 | PENDING    |       |          256 |     0 | 1     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 119 more trials not shown (16 RUNNING, 102 TERMINATED)


Result for _inner_e98d6_00127:
  auc: 0.9063852429389954
  date: 2021-03-18_02-17-42
  done: true
  experiment_id: 1b55d10a05e54187b73a02771e9312fe
  experiment_tag: 127_batch_size=128,eta=0.0,lr=0.01,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 1306
  time_since_restore: 985.3548965454102
  time_this_iter_s: 985.3548965454102
  time_total_s: 985.3548965454102
  timestamp: 1616030262
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00127
  
[2m[36m(pid=41421)[0m Starting run with seed 0 - lr 1 - sec_lr 2 - bs 256
[2m[36m(pid=41421)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41421)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=41421)[0m GPU available: False, used: False
[2m[36m(pid=41421)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41421)[0m 
[2m[36m(pid=41421)[0m   | Name      | Type              | Params
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41421)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41421)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 12.0 K    Trainable params
[2m[36m(pid=41421)[0m 0         Non-trainable params
[2m[36m(pid=41421)[0m 12.0 K    Total params
[2m[36m(pid=41421)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41421)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41421)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41421)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41421)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=41421)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m time to fit was 427.04468727111816
[2m[36m(pid=44128)[0m GPU available: False, used: False
[2m[36m(pid=44128)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44128)[0m 
[2m[36m(pid=44128)[0m   | Name      | Type              | Params
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44128)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44128)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 12.0 K    Trainable params
[2m[36m(pid=44128)[0m 0         Non-trainable params
[2m[36m(pid=44128)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m time to fit was 429.06961846351624
[2m[36m(pid=46560)[0m GPU available: False, used: False
[2m[36m(pid=46560)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=46560)[0m 
[2m[36m(pid=46560)[0m   | Name      | Type              | Params
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=46560)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=46560)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=46560)[0m ------------------------------------------------
[2m[36m(pid=46560)[0m 12.0 K    Trainable params
[2m[36m(pid=46560)[0m 0         Non-trainable params
[2m[36m(pid=46560)[0m 12.0 K    Total params
[2m[36m(pid=25379)[0m time to fit was 78.72892260551453
Result for _inner_e98d6_00133:
  auc: 0.9115354895591736
  date: 2021-03-18_02-18-26
  done: false
  experiment_id: 41e5dfb12cae4fdca5e09cc4fbf3e60e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25379
  time_since_restore: 429.38119864463806
  time_this_iter_s: 429.38119864463806
  time_total_s: 429.38119864463806
  timestamp: 1616030306
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00133
  
[2m[36m(pid=25379)[0m Finished run with seed 0 - lr 0.1 - sec_lr 2 - bs 256 - mean val auc: 0.9115354895591736
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 140/180 (1 PENDING, 26 RUNNING, 113 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00139 | PENDING    |       |          512 |     0 | 1     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 120 more trials not shown (16 RUNNING, 103 TERMINATED)


Result for _inner_e98d6_00133:
  auc: 0.9115354895591736
  date: 2021-03-18_02-18-26
  done: true
  experiment_id: 41e5dfb12cae4fdca5e09cc4fbf3e60e
  experiment_tag: 133_batch_size=256,eta=0.0,lr=0.1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25379
  time_since_restore: 429.38119864463806
  time_this_iter_s: 429.38119864463806
  time_total_s: 429.38119864463806
  timestamp: 1616030306
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00133
  
[2m[36m(pid=33698)[0m time to fit was 227.06855463981628
[2m[36m(pid=37425)[0m time to fit was 133.6468334197998
[2m[36m(pid=33698)[0m GPU available: False, used: False
[2m[36m(pid=33698)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33698)[0m 
[2m[36m(pid=33698)[0m   | Name      | Type              | Params
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33698)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33698)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 12.0 K    Trainable params
[2m[36m(pid=33698)[0m 0         Non-trainable params
[2m[36m(pid=33698)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m GPU available: False, used: False
[2m[36m(pid=37425)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37425)[0m 
[2m[36m(pid=37425)[0m   | Name      | Type              | Params
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37425)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37425)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 12.0 K    Trainable params
[2m[36m(pid=37425)[0m 0         Non-trainable params
[2m[36m(pid=37425)[0m 12.0 K    Total params
[2m[36m(pid=28610)[0m time to fit was 437.34766149520874
[2m[36m(pid=30571)[0m time to fit was 55.748151540756226
[2m[36m(pid=28610)[0m GPU available: False, used: False
[2m[36m(pid=28610)[0m TPU available: None, using: 0 TPU cores
Result for _inner_e98d6_00134:
  auc: 0.9123380303382873
  date: 2021-03-18_02-18-32
  done: false
  experiment_id: 4cac58f5534e4b7c9a266d4985474f61
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30571
  time_since_restore: 309.45053601264954
  time_this_iter_s: 309.45053601264954
  time_total_s: 309.45053601264954
  timestamp: 1616030312
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00134
  
[2m[36m(pid=30571)[0m Finished run with seed 0 - lr 0.1 - sec_lr 2 - bs 512 - mean val auc: 0.9123380303382873
[2m[36m(pid=28610)[0m 
[2m[36m(pid=28610)[0m   | Name      | Type              | Params
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28610)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28610)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28610)[0m ------------------------------------------------
[2m[36m(pid=28610)[0m 12.0 K    Trainable params
[2m[36m(pid=28610)[0m 0         Non-trainable params
[2m[36m(pid=28610)[0m 12.0 K    Total params
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 141/180 (1 PENDING, 26 RUNNING, 114 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00140 | PENDING    |       |           32 |     0 | 2     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 121 more trials not shown (16 RUNNING, 104 TERMINATED)


Result for _inner_e98d6_00134:
  auc: 0.9123380303382873
  date: 2021-03-18_02-18-32
  done: true
  experiment_id: 4cac58f5534e4b7c9a266d4985474f61
  experiment_tag: 134_batch_size=512,eta=0.0,lr=0.1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30571
  time_since_restore: 309.45053601264954
  time_this_iter_s: 309.45053601264954
  time_total_s: 309.45053601264954
  timestamp: 1616030312
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00134
  
[2m[36m(pid=43134)[0m Starting run with seed 0 - lr 1 - sec_lr 2 - bs 512
[2m[36m(pid=43134)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43134)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43134)[0m GPU available: False, used: False
[2m[36m(pid=43134)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43134)[0m 
[2m[36m(pid=43134)[0m   | Name      | Type              | Params
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43134)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43134)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 12.0 K    Trainable params
[2m[36m(pid=43134)[0m 0         Non-trainable params
[2m[36m(pid=43134)[0m 12.0 K    Total params
[2m[36m(pid=43134)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43134)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43134)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43134)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43134)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43134)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43402)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43402)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43402)[0m Starting run with seed 0 - lr 2 - sec_lr 2 - bs 32
[2m[36m(pid=43402)[0m GPU available: False, used: False
[2m[36m(pid=43402)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43402)[0m 
[2m[36m(pid=43402)[0m   | Name      | Type              | Params
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43402)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43402)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 12.0 K    Trainable params
[2m[36m(pid=43402)[0m 0         Non-trainable params
[2m[36m(pid=43402)[0m 12.0 K    Total params
[2m[36m(pid=43402)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43402)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43402)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43402)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43402)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43402)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23882)[0m time to fit was 122.20626950263977
[2m[36m(pid=23882)[0m GPU available: False, used: False
[2m[36m(pid=23882)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23882)[0m 
[2m[36m(pid=23882)[0m   | Name      | Type              | Params
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23882)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23882)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23882)[0m ------------------------------------------------
[2m[36m(pid=23882)[0m 12.0 K    Trainable params
[2m[36m(pid=23882)[0m 0         Non-trainable params
[2m[36m(pid=23882)[0m 12.0 K    Total params
[2m[36m(pid=41421)[0m time to fit was 84.81611251831055
[2m[36m(pid=41421)[0m GPU available: False, used: False
[2m[36m(pid=41421)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41421)[0m 
[2m[36m(pid=41421)[0m   | Name      | Type              | Params
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41421)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41421)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 12.0 K    Trainable params
[2m[36m(pid=41421)[0m 0         Non-trainable params
[2m[36m(pid=41421)[0m 12.0 K    Total params
[2m[36m(pid=43134)[0m time to fit was 60.818995237350464
[2m[36m(pid=43134)[0m GPU available: False, used: False
[2m[36m(pid=43134)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43134)[0m 
[2m[36m(pid=43134)[0m   | Name      | Type              | Params
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43134)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43134)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 12.0 K    Trainable params
[2m[36m(pid=43134)[0m 0         Non-trainable params
[2m[36m(pid=43134)[0m 12.0 K    Total params
[2m[36m(pid=12738)[0m time to fit was 424.9290552139282
[2m[36m(pid=12738)[0m GPU available: False, used: False
[2m[36m(pid=12738)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12738)[0m 
[2m[36m(pid=12738)[0m   | Name      | Type              | Params
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12738)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12738)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 12.0 K    Trainable params
[2m[36m(pid=12738)[0m 0         Non-trainable params
[2m[36m(pid=12738)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m time to fit was 121.34945297241211
[2m[36m(pid=37425)[0m GPU available: False, used: False
[2m[36m(pid=37425)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37425)[0m 
[2m[36m(pid=37425)[0m   | Name      | Type              | Params
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37425)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37425)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 12.0 K    Trainable params
[2m[36m(pid=37425)[0m 0         Non-trainable params
[2m[36m(pid=37425)[0m 12.0 K    Total params
[2m[36m(pid=41421)[0m time to fit was 77.68253636360168
[2m[36m(pid=41421)[0m GPU available: False, used: False
[2m[36m(pid=41421)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41421)[0m 
[2m[36m(pid=41421)[0m   | Name      | Type              | Params
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41421)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41421)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 12.0 K    Trainable params
[2m[36m(pid=41421)[0m 0         Non-trainable params
[2m[36m(pid=41421)[0m 12.0 K    Total params
[2m[36m(pid=43134)[0m time to fit was 65.03924536705017
[2m[36m(pid=43134)[0m GPU available: False, used: False
[2m[36m(pid=43134)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43134)[0m 
[2m[36m(pid=43134)[0m   | Name      | Type              | Params
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43134)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43134)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 12.0 K    Trainable params
[2m[36m(pid=43134)[0m 0         Non-trainable params
[2m[36m(pid=43134)[0m 12.0 K    Total params
[2m[36m(pid=23882)[0m time to fit was 123.9847822189331
Result for _inner_e98d6_00132:
  auc: 0.9092411398887634
  date: 2021-03-18_02-21-07
  done: false
  experiment_id: f7009842a80049e0ba71e6c810cdc3c8
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23882
  time_since_restore: 629.484215259552
  time_this_iter_s: 629.484215259552
  time_total_s: 629.484215259552
  timestamp: 1616030467
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00132
  
[2m[36m(pid=23882)[0m Finished run with seed 0 - lr 0.1 - sec_lr 2 - bs 128 - mean val auc: 0.9092411398887634
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 142/180 (1 PENDING, 26 RUNNING, 115 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00141 | PENDING    |       |           64 |     0 | 2     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 122 more trials not shown (16 RUNNING, 105 TERMINATED)


Result for _inner_e98d6_00132:
  auc: 0.9092411398887634
  date: 2021-03-18_02-21-07
  done: true
  experiment_id: f7009842a80049e0ba71e6c810cdc3c8
  experiment_tag: 132_batch_size=128,eta=0.0,lr=0.1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23882
  time_since_restore: 629.484215259552
  time_this_iter_s: 629.484215259552
  time_total_s: 629.484215259552
  timestamp: 1616030467
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00132
  
[2m[36m(pid=32429)[0m time to fit was 421.0455017089844
[2m[36m(pid=32429)[0m GPU available: False, used: False
[2m[36m(pid=32429)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=32429)[0m 
[2m[36m(pid=32429)[0m   | Name      | Type              | Params
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=32429)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=32429)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 12.0 K    Trainable params
[2m[36m(pid=32429)[0m 0         Non-trainable params
[2m[36m(pid=32429)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m Starting run with seed 0 - lr 2 - sec_lr 2 - bs 64
[2m[36m(pid=50284)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50284)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=50284)[0m GPU available: False, used: False
[2m[36m(pid=50284)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50284)[0m 
[2m[36m(pid=50284)[0m   | Name      | Type              | Params
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50284)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50284)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 12.0 K    Trainable params
[2m[36m(pid=50284)[0m 0         Non-trainable params
[2m[36m(pid=50284)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=50284)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50284)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=50284)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50284)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=50284)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21475)[0m time to fit was 246.16228699684143
[2m[36m(pid=21475)[0m GPU available: False, used: False
[2m[36m(pid=21475)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21475)[0m 
[2m[36m(pid=21475)[0m   | Name      | Type              | Params
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21475)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21475)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 12.0 K    Trainable params
[2m[36m(pid=21475)[0m 0         Non-trainable params
[2m[36m(pid=21475)[0m 12.0 K    Total params
[2m[36m(pid=43134)[0m time to fit was 59.502270460128784
[2m[36m(pid=43134)[0m GPU available: False, used: False
[2m[36m(pid=43134)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43134)[0m 
[2m[36m(pid=43134)[0m   | Name      | Type              | Params
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43134)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43134)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 12.0 K    Trainable params
[2m[36m(pid=43134)[0m 0         Non-trainable params
[2m[36m(pid=43134)[0m 12.0 K    Total params
[2m[36m(pid=41421)[0m time to fit was 84.14586663246155
[2m[36m(pid=41421)[0m GPU available: False, used: False
[2m[36m(pid=41421)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41421)[0m 
[2m[36m(pid=41421)[0m   | Name      | Type              | Params
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41421)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41421)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 12.0 K    Trainable params
[2m[36m(pid=41421)[0m 0         Non-trainable params
[2m[36m(pid=41421)[0m 12.0 K    Total params
[2m[36m(pid=33698)[0m time to fit was 224.54482412338257
[2m[36m(pid=33698)[0m GPU available: False, used: False
[2m[36m(pid=33698)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33698)[0m 
[2m[36m(pid=33698)[0m   | Name      | Type              | Params
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33698)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33698)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 12.0 K    Trainable params
[2m[36m(pid=33698)[0m 0         Non-trainable params
[2m[36m(pid=33698)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m time to fit was 125.78352451324463
[2m[36m(pid=37425)[0m GPU available: False, used: False
[2m[36m(pid=37425)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37425)[0m 
[2m[36m(pid=37425)[0m   | Name      | Type              | Params
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37425)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37425)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 12.0 K    Trainable params
[2m[36m(pid=37425)[0m 0         Non-trainable params
[2m[36m(pid=37425)[0m 12.0 K    Total params
[2m[36m(pid=46560)[0m time to fit was 281.454745054245
Result for _inner_e98d6_00126:
  auc: 0.9064125061035156
  date: 2021-03-18_02-22-46
  done: false
  experiment_id: 538a3793665545fbb309d3190d15de3a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 46560
  time_since_restore: 1491.2729902267456
  time_this_iter_s: 1491.2729902267456
  time_total_s: 1491.2729902267456
  timestamp: 1616030566
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00126
  
[2m[36m(pid=46560)[0m Finished run with seed 0 - lr 0.01 - sec_lr 2 - bs 64 - mean val auc: 0.9064125061035156
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 143/180 (1 PENDING, 26 RUNNING, 116 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00142 | PENDING    |       |          128 |     0 | 2     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 123 more trials not shown (16 RUNNING, 106 TERMINATED)


Result for _inner_e98d6_00126:
  auc: 0.9064125061035156
  date: 2021-03-18_02-22-46
  done: true
  experiment_id: 538a3793665545fbb309d3190d15de3a
  experiment_tag: 126_batch_size=64,eta=0.0,lr=0.01,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 46560
  time_since_restore: 1491.2729902267456
  time_this_iter_s: 1491.2729902267456
  time_total_s: 1491.2729902267456
  timestamp: 1616030566
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00126
  
[2m[36m(pid=43134)[0m time to fit was 67.89669108390808
[2m[36m(pid=43134)[0m GPU available: False, used: False
[2m[36m(pid=43134)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43134)[0m 
[2m[36m(pid=43134)[0m   | Name      | Type              | Params
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43134)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43134)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43134)[0m ------------------------------------------------
[2m[36m(pid=43134)[0m 12.0 K    Trainable params
[2m[36m(pid=43134)[0m 0         Non-trainable params
[2m[36m(pid=43134)[0m 12.0 K    Total params
[2m[36m(pid=1133)[0m Starting run with seed 0 - lr 2 - sec_lr 2 - bs 128
[2m[36m(pid=1133)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1133)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=1133)[0m GPU available: False, used: False
[2m[36m(pid=1133)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1133)[0m 
[2m[36m(pid=1133)[0m   | Name      | Type              | Params
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1133)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1133)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 12.0 K    Trainable params
[2m[36m(pid=1133)[0m 0         Non-trainable params
[2m[36m(pid=1133)[0m 12.0 K    Total params
[2m[36m(pid=1133)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=1133)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=1133)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=1133)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=1133)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=1133)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41421)[0m time to fit was 78.97889518737793
[2m[36m(pid=41421)[0m GPU available: False, used: False
[2m[36m(pid=41421)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41421)[0m 
[2m[36m(pid=41421)[0m   | Name      | Type              | Params
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41421)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41421)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41421)[0m ------------------------------------------------
[2m[36m(pid=41421)[0m 12.0 K    Trainable params
[2m[36m(pid=41421)[0m 0         Non-trainable params
[2m[36m(pid=41421)[0m 12.0 K    Total params
[2m[36m(pid=16679)[0m time to fit was 701.8826932907104
[2m[36m(pid=16679)[0m GPU available: False, used: False
[2m[36m(pid=16679)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=16679)[0m 
[2m[36m(pid=16679)[0m   | Name      | Type              | Params
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=16679)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=16679)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=16679)[0m ------------------------------------------------
[2m[36m(pid=16679)[0m 12.0 K    Trainable params
[2m[36m(pid=16679)[0m 0         Non-trainable params
[2m[36m(pid=16679)[0m 12.0 K    Total params
[2m[36m(pid=43134)[0m time to fit was 54.80546045303345
Result for _inner_e98d6_00139:
  auc: 0.9114285349845886
  date: 2021-03-18_02-23-47
  done: false
  experiment_id: 99069ab82c4a415a8c917f75c6bd8253
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43134
  time_since_restore: 309.3600287437439
  time_this_iter_s: 309.3600287437439
  time_total_s: 309.3600287437439
  timestamp: 1616030627
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00139
  
[2m[36m(pid=43134)[0m Finished run with seed 0 - lr 1 - sec_lr 2 - bs 512 - mean val auc: 0.9114285349845886
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 144/180 (1 PENDING, 26 RUNNING, 117 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00143 | PENDING    |       |          256 |     0 | 2     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 124 more trials not shown (16 RUNNING, 107 TERMINATED)


Result for _inner_e98d6_00139:
  auc: 0.9114285349845886
  date: 2021-03-18_02-23-47
  done: true
  experiment_id: 99069ab82c4a415a8c917f75c6bd8253
  experiment_tag: 139_batch_size=512,eta=0.0,lr=1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43134
  time_since_restore: 309.3600287437439
  time_this_iter_s: 309.3600287437439
  time_total_s: 309.3600287437439
  timestamp: 1616030627
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00139
  
[2m[36m(pid=3572)[0m Starting run with seed 0 - lr 2 - sec_lr 2 - bs 256
[2m[36m(pid=3572)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3572)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=3572)[0m GPU available: False, used: False
[2m[36m(pid=3572)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3572)[0m 
[2m[36m(pid=3572)[0m   | Name      | Type              | Params
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3572)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3572)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 12.0 K    Trainable params
[2m[36m(pid=3572)[0m 0         Non-trainable params
[2m[36m(pid=3572)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3572)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3572)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=3572)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=3572)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=3572)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41421)[0m time to fit was 77.70146703720093
Result for _inner_e98d6_00138:
  auc: 0.9100112795829773
  date: 2021-03-18_02-24-38
  done: false
  experiment_id: d7446bdf30204d56a18ef97c8cb6ee16
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41421
  time_since_restore: 404.5790648460388
  time_this_iter_s: 404.5790648460388
  time_total_s: 404.5790648460388
  timestamp: 1616030678
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00138
  
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 145/180 (1 PENDING, 26 RUNNING, 118 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00144 | PENDING    |       |          512 |     0 | 2     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 125 more trials not shown (16 RUNNING, 108 TERMINATED)


[2m[36m(pid=41421)[0m Finished run with seed 0 - lr 1 - sec_lr 2 - bs 256 - mean val auc: 0.9100112795829773
Result for _inner_e98d6_00138:
  auc: 0.9100112795829773
  date: 2021-03-18_02-24-38
  done: true
  experiment_id: d7446bdf30204d56a18ef97c8cb6ee16
  experiment_tag: 138_batch_size=256,eta=0.0,lr=1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41421
  time_since_restore: 404.5790648460388
  time_this_iter_s: 404.5790648460388
  time_total_s: 404.5790648460388
  timestamp: 1616030678
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00138
  
[2m[36m(pid=21639)[0m time to fit was 4524.817825078964
[2m[36m(pid=21639)[0m GPU available: False, used: False
[2m[36m(pid=21639)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21639)[0m 
[2m[36m(pid=21639)[0m   | Name      | Type              | Params
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21639)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21639)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 12.0 K    Trainable params
[2m[36m(pid=21639)[0m 0         Non-trainable params
[2m[36m(pid=21639)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m time to fit was 134.4312822818756
[2m[36m(pid=37425)[0m GPU available: False, used: False
[2m[36m(pid=37425)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=37425)[0m 
[2m[36m(pid=37425)[0m   | Name      | Type              | Params
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=37425)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=37425)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=37425)[0m ------------------------------------------------
[2m[36m(pid=37425)[0m 12.0 K    Trainable params
[2m[36m(pid=37425)[0m 0         Non-trainable params
[2m[36m(pid=37425)[0m 12.0 K    Total params
[2m[36m(pid=5485)[0m Starting run with seed 0 - lr 2 - sec_lr 2 - bs 512
[2m[36m(pid=5485)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=5485)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=5485)[0m GPU available: False, used: False
[2m[36m(pid=5485)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5485)[0m 
[2m[36m(pid=5485)[0m   | Name      | Type              | Params
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5485)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5485)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 12.0 K    Trainable params
[2m[36m(pid=5485)[0m 0         Non-trainable params
[2m[36m(pid=5485)[0m 12.0 K    Total params
[2m[36m(pid=5485)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5485)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5485)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=5485)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=5485)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=5485)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=44128)[0m time to fit was 426.8581266403198
[2m[36m(pid=44128)[0m GPU available: False, used: False
[2m[36m(pid=44128)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=44128)[0m 
[2m[36m(pid=44128)[0m   | Name      | Type              | Params
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=44128)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=44128)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=44128)[0m ------------------------------------------------
[2m[36m(pid=44128)[0m 12.0 K    Trainable params
[2m[36m(pid=44128)[0m 0         Non-trainable params
[2m[36m(pid=44128)[0m 12.0 K    Total params
[2m[36m(pid=16989)[0m time to fit was 1163.7827651500702
Result for _inner_e98d6_00116:
  auc: 0.6228992342948914
  date: 2021-03-18_02-25-09
  done: false
  experiment_id: ba8373cba2ca4876b51da60e346b144d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 16989
  time_since_restore: 2401.798475265503
  time_this_iter_s: 2401.798475265503
  time_total_s: 2401.798475265503
  timestamp: 1616030709
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00116
  
[2m[36m(pid=16989)[0m Finished run with seed 0 - lr 5 - sec_lr 1 - bs 64 - mean val auc: 0.6228992342948914
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 146/180 (1 PENDING, 26 RUNNING, 119 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00145 | PENDING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 126 more trials not shown (16 RUNNING, 109 TERMINATED)


Result for _inner_e98d6_00116:
  auc: 0.6228992342948914
  date: 2021-03-18_02-25-09
  done: true
  experiment_id: ba8373cba2ca4876b51da60e346b144d
  experiment_tag: 116_batch_size=64,eta=0.0,lr=5,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 16989
  time_since_restore: 2401.798475265503
  time_this_iter_s: 2401.798475265503
  time_total_s: 2401.798475265503
  timestamp: 1616030709
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00116
  
[2m[36m(pid=6614)[0m Starting run with seed 0 - lr 5 - sec_lr 2 - bs 32
[2m[36m(pid=6614)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=6614)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=6614)[0m GPU available: False, used: False
[2m[36m(pid=6614)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6614)[0m 
[2m[36m(pid=6614)[0m   | Name      | Type              | Params
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6614)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6614)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 12.0 K    Trainable params
[2m[36m(pid=6614)[0m 0         Non-trainable params
[2m[36m(pid=6614)[0m 12.0 K    Total params
[2m[36m(pid=6614)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6614)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6614)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=6614)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6614)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=6614)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21475)[0m time to fit was 224.37099599838257
[2m[36m(pid=21475)[0m GPU available: False, used: False
[2m[36m(pid=21475)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21475)[0m 
[2m[36m(pid=21475)[0m   | Name      | Type              | Params
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21475)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21475)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21475)[0m ------------------------------------------------
[2m[36m(pid=21475)[0m 12.0 K    Trainable params
[2m[36m(pid=21475)[0m 0         Non-trainable params
[2m[36m(pid=21475)[0m 12.0 K    Total params
[2m[36m(pid=1133)[0m time to fit was 146.36621642112732
[2m[36m(pid=1133)[0m GPU available: False, used: False
[2m[36m(pid=1133)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1133)[0m 
[2m[36m(pid=1133)[0m   | Name      | Type              | Params
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1133)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1133)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 12.0 K    Trainable params
[2m[36m(pid=1133)[0m 0         Non-trainable params
[2m[36m(pid=1133)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m time to fit was 92.22716355323792
[2m[36m(pid=3572)[0m GPU available: False, used: False
[2m[36m(pid=3572)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3572)[0m 
[2m[36m(pid=3572)[0m   | Name      | Type              | Params
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3572)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3572)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 12.0 K    Trainable params
[2m[36m(pid=3572)[0m 0         Non-trainable params
[2m[36m(pid=3572)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m time to fit was 262.7875933647156
[2m[36m(pid=50284)[0m GPU available: False, used: False
[2m[36m(pid=50284)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50284)[0m 
[2m[36m(pid=50284)[0m   | Name      | Type              | Params
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50284)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50284)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 12.0 K    Trainable params
[2m[36m(pid=50284)[0m 0         Non-trainable params
[2m[36m(pid=50284)[0m 12.0 K    Total params
[2m[36m(pid=28610)[0m time to fit was 433.0617380142212
Result for _inner_e98d6_00120:
  auc: 0.4986472845077515
  date: 2021-03-18_02-25-45
  done: false
  experiment_id: db45d6bc067d433cb3caec128529f25c
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28610
  time_since_restore: 2153.639340162277
  time_this_iter_s: 2153.639340162277
  time_total_s: 2153.639340162277
  timestamp: 1616030745
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00120
  
[2m[36m(pid=28610)[0m Finished run with seed 0 - lr 0.001 - sec_lr 2 - bs 32 - mean val auc: 0.4986472845077515
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 147/180 (1 PENDING, 26 RUNNING, 120 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    |       |          512 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00146 | PENDING    |       |           64 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 127 more trials not shown (16 RUNNING, 110 TERMINATED)


Result for _inner_e98d6_00120:
  auc: 0.4986472845077515
  date: 2021-03-18_02-25-45
  done: true
  experiment_id: db45d6bc067d433cb3caec128529f25c
  experiment_tag: 120_batch_size=32,eta=0.0,lr=0.001,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28610
  time_since_restore: 2153.639340162277
  time_this_iter_s: 2153.639340162277
  time_total_s: 2153.639340162277
  timestamp: 1616030745
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00120
  
[2m[36m(pid=43402)[0m time to fit was 428.464688539505
[2m[36m(pid=43402)[0m GPU available: False, used: False
[2m[36m(pid=43402)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43402)[0m 
[2m[36m(pid=43402)[0m   | Name      | Type              | Params
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43402)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43402)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 12.0 K    Trainable params
[2m[36m(pid=43402)[0m 0         Non-trainable params
[2m[36m(pid=43402)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m Starting run with seed 0 - lr 5 - sec_lr 2 - bs 64
[2m[36m(pid=8006)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8006)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=8006)[0m GPU available: False, used: False
[2m[36m(pid=8006)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8006)[0m 
[2m[36m(pid=8006)[0m   | Name      | Type              | Params
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8006)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8006)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 12.0 K    Trainable params
[2m[36m(pid=8006)[0m 0         Non-trainable params
[2m[36m(pid=8006)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=8006)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=8006)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=8006)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=8006)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=8006)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=21720)[0m time to fit was 2116.592992544174
Result for _inner_e98d6_00004:
  auc: 0.9099510312080383
  date: 2021-03-18_02-25-59
  done: false
  experiment_id: 8efc0898371c4f8f8fe5f6787253f0de
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21720
  time_since_restore: 12013.660897731781
  time_this_iter_s: 12013.660897731781
  time_total_s: 12013.660897731781
  timestamp: 1616030759
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00004
  
[2m[36m(pid=21720)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 512 - mean val auc: 0.9099510312080383
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 148/180 (1 PENDING, 26 RUNNING, 121 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |                     |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00004 | RUNNING    | 145.101.32.82:21720 |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |                     |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00147 | PENDING    |                     |          128 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 128 more trials not shown (16 RUNNING, 111 TERMINATED)


Result for _inner_e98d6_00004:
  auc: 0.9099510312080383
  date: 2021-03-18_02-25-59
  done: true
  experiment_id: 8efc0898371c4f8f8fe5f6787253f0de
  experiment_tag: 4_batch_size=512,eta=0.0,lr=0.001,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21720
  time_since_restore: 12013.660897731781
  time_this_iter_s: 12013.660897731781
  time_total_s: 12013.660897731781
  timestamp: 1616030759
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00004
  
[2m[36m(pid=5485)[0m time to fit was 69.6664445400238
[2m[36m(pid=5485)[0m GPU available: False, used: False
[2m[36m(pid=5485)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5485)[0m 
[2m[36m(pid=5485)[0m   | Name      | Type              | Params
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5485)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5485)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 12.0 K    Trainable params
[2m[36m(pid=5485)[0m 0         Non-trainable params
[2m[36m(pid=5485)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m Starting run with seed 0 - lr 5 - sec_lr 2 - bs 128
[2m[36m(pid=8554)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8554)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=8554)[0m GPU available: False, used: False
[2m[36m(pid=8554)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8554)[0m 
[2m[36m(pid=8554)[0m   | Name      | Type              | Params
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8554)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8554)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 12.0 K    Trainable params
[2m[36m(pid=8554)[0m 0         Non-trainable params
[2m[36m(pid=8554)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=8554)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=8554)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=8554)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=8554)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=8554)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33698)[0m time to fit was 249.14746570587158
[2m[36m(pid=33698)[0m GPU available: False, used: False
[2m[36m(pid=33698)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33698)[0m 
[2m[36m(pid=33698)[0m   | Name      | Type              | Params
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33698)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33698)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 12.0 K    Trainable params
[2m[36m(pid=33698)[0m 0         Non-trainable params
[2m[36m(pid=33698)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m time to fit was 78.32275557518005
[2m[36m(pid=3572)[0m GPU available: False, used: False
[2m[36m(pid=3572)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3572)[0m 
[2m[36m(pid=3572)[0m   | Name      | Type              | Params
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3572)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3572)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 12.0 K    Trainable params
[2m[36m(pid=3572)[0m 0         Non-trainable params
[2m[36m(pid=3572)[0m 12.0 K    Total params
[2m[36m(pid=37425)[0m time to fit was 124.34008145332336
Result for _inner_e98d6_00137:
  auc: 0.9080030679702759
  date: 2021-03-18_02-26-54
  done: false
  experiment_id: 1217c207cf074cbdb3d2125b3115291e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 37425
  time_since_restore: 640.9017899036407
  time_this_iter_s: 640.9017899036407
  time_total_s: 640.9017899036407
  timestamp: 1616030814
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00137
  
[2m[36m(pid=37425)[0m Finished run with seed 0 - lr 1 - sec_lr 2 - bs 128 - mean val auc: 0.9080030679702759
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 149/180 (1 PENDING, 26 RUNNING, 122 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00148 | PENDING    |       |          256 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 129 more trials not shown (16 RUNNING, 112 TERMINATED)


Result for _inner_e98d6_00137:
  auc: 0.9080030679702759
  date: 2021-03-18_02-26-54
  done: true
  experiment_id: 1217c207cf074cbdb3d2125b3115291e
  experiment_tag: 137_batch_size=128,eta=0.0,lr=1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 37425
  time_since_restore: 640.9017899036407
  time_this_iter_s: 640.9017899036407
  time_total_s: 640.9017899036407
  timestamp: 1616030814
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00137
  
[2m[36m(pid=10532)[0m Starting run with seed 0 - lr 5 - sec_lr 2 - bs 256
[2m[36m(pid=10532)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10532)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=10532)[0m GPU available: False, used: False
[2m[36m(pid=10532)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10532)[0m 
[2m[36m(pid=10532)[0m   | Name      | Type              | Params
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10532)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10532)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 12.0 K    Trainable params
[2m[36m(pid=10532)[0m 0         Non-trainable params
[2m[36m(pid=10532)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=10532)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=10532)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=10532)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=10532)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=10532)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12738)[0m time to fit was 427.4635398387909
[2m[36m(pid=12738)[0m GPU available: False, used: False
[2m[36m(pid=12738)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12738)[0m 
[2m[36m(pid=12738)[0m   | Name      | Type              | Params
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12738)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12738)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 12.0 K    Trainable params
[2m[36m(pid=12738)[0m 0         Non-trainable params
[2m[36m(pid=12738)[0m 12.0 K    Total params
[2m[36m(pid=21661)[0m time to fit was 8043.474358558655
[2m[36m(pid=21661)[0m GPU available: False, used: False
[2m[36m(pid=21661)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21661)[0m 
[2m[36m(pid=21661)[0m   | Name      | Type              | Params
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21661)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21661)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 12.0 K    Trainable params
[2m[36m(pid=21661)[0m 0         Non-trainable params
[2m[36m(pid=21661)[0m 12.0 K    Total params
[2m[36m(pid=5485)[0m time to fit was 115.45589089393616
[2m[36m(pid=5485)[0m GPU available: False, used: False
[2m[36m(pid=5485)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5485)[0m 
[2m[36m(pid=5485)[0m   | Name      | Type              | Params
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5485)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5485)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 12.0 K    Trainable params
[2m[36m(pid=5485)[0m 0         Non-trainable params
[2m[36m(pid=5485)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m time to fit was 71.97933030128479
[2m[36m(pid=3572)[0m GPU available: False, used: False
[2m[36m(pid=3572)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3572)[0m 
[2m[36m(pid=3572)[0m   | Name      | Type              | Params
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3572)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3572)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 12.0 K    Trainable params
[2m[36m(pid=3572)[0m 0         Non-trainable params
[2m[36m(pid=3572)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m time to fit was 419.5987629890442
[2m[36m(pid=32429)[0m GPU available: False, used: False
[2m[36m(pid=32429)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=32429)[0m 
[2m[36m(pid=32429)[0m   | Name      | Type              | Params
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=32429)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=32429)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 12.0 K    Trainable params
[2m[36m(pid=32429)[0m 0         Non-trainable params
[2m[36m(pid=32429)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m time to fit was 121.91537189483643
[2m[36m(pid=8554)[0m GPU available: False, used: False
[2m[36m(pid=8554)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8554)[0m 
[2m[36m(pid=8554)[0m   | Name      | Type              | Params
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8554)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8554)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 12.0 K    Trainable params
[2m[36m(pid=8554)[0m 0         Non-trainable params
[2m[36m(pid=8554)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m time to fit was 77.33476853370667
[2m[36m(pid=10532)[0m GPU available: False, used: False
[2m[36m(pid=10532)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10532)[0m 
[2m[36m(pid=10532)[0m   | Name      | Type              | Params
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10532)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10532)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 12.0 K    Trainable params
[2m[36m(pid=10532)[0m 0         Non-trainable params
[2m[36m(pid=10532)[0m 12.0 K    Total params
[2m[36m(pid=21475)[0m time to fit was 224.3583688735962
Result for _inner_e98d6_00131:
  auc: 0.9028991460800171
  date: 2021-03-18_02-29-09
  done: false
  experiment_id: c98aa6b96a08412dbf563b3f0eeabcb5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21475
  time_since_restore: 1165.7936747074127
  time_this_iter_s: 1165.7936747074127
  time_total_s: 1165.7936747074127
  timestamp: 1616030949
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00131
  
[2m[36m(pid=21475)[0m Finished run with seed 0 - lr 0.1 - sec_lr 2 - bs 64 - mean val auc: 0.9028991460800171
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 150/180 (1 PENDING, 26 RUNNING, 123 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00149 | PENDING    |       |          512 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 130 more trials not shown (16 RUNNING, 113 TERMINATED)


Result for _inner_e98d6_00131:
  auc: 0.9028991460800171
  date: 2021-03-18_02-29-09
  done: true
  experiment_id: c98aa6b96a08412dbf563b3f0eeabcb5
  experiment_tag: 131_batch_size=64,eta=0.0,lr=0.1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21475
  time_since_restore: 1165.7936747074127
  time_this_iter_s: 1165.7936747074127
  time_total_s: 1165.7936747074127
  timestamp: 1616030949
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00131
  
[2m[36m(pid=5485)[0m time to fit was 75.92848777770996
[2m[36m(pid=5485)[0m GPU available: False, used: False
[2m[36m(pid=5485)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5485)[0m 
[2m[36m(pid=5485)[0m   | Name      | Type              | Params
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5485)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5485)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 12.0 K    Trainable params
[2m[36m(pid=5485)[0m 0         Non-trainable params
[2m[36m(pid=5485)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m Starting run with seed 0 - lr 5 - sec_lr 2 - bs 512
[2m[36m(pid=15530)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15530)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=15530)[0m GPU available: False, used: False
[2m[36m(pid=15530)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15530)[0m 
[2m[36m(pid=15530)[0m   | Name      | Type              | Params
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15530)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15530)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 12.0 K    Trainable params
[2m[36m(pid=15530)[0m 0         Non-trainable params
[2m[36m(pid=15530)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15530)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15530)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=15530)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15530)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=15530)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=50284)[0m time to fit was 223.0393831729889
[2m[36m(pid=50284)[0m GPU available: False, used: False
[2m[36m(pid=50284)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50284)[0m 
[2m[36m(pid=50284)[0m   | Name      | Type              | Params
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50284)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50284)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 12.0 K    Trainable params
[2m[36m(pid=50284)[0m 0         Non-trainable params
[2m[36m(pid=50284)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m time to fit was 220.5928611755371
[2m[36m(pid=8006)[0m GPU available: False, used: False
[2m[36m(pid=8006)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8006)[0m 
[2m[36m(pid=8006)[0m   | Name      | Type              | Params
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8006)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8006)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 12.0 K    Trainable params
[2m[36m(pid=8006)[0m 0         Non-trainable params
[2m[36m(pid=8006)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m time to fit was 78.98332715034485
[2m[36m(pid=10532)[0m GPU available: False, used: False
[2m[36m(pid=10532)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10532)[0m 
[2m[36m(pid=10532)[0m   | Name      | Type              | Params
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10532)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10532)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 12.0 K    Trainable params
[2m[36m(pid=10532)[0m 0         Non-trainable params
[2m[36m(pid=10532)[0m 12.0 K    Total params
[2m[36m(pid=33698)[0m time to fit was 226.6525218486786
[2m[36m(pid=15530)[0m time to fit was 46.493085861206055
[2m[36m(pid=33698)[0m GPU available: False, used: False
[2m[36m(pid=33698)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=33698)[0m 
[2m[36m(pid=33698)[0m   | Name      | Type              | Params
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=33698)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=33698)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=33698)[0m ------------------------------------------------
[2m[36m(pid=33698)[0m 12.0 K    Trainable params
[2m[36m(pid=33698)[0m 0         Non-trainable params
[2m[36m(pid=33698)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m GPU available: False, used: False
[2m[36m(pid=15530)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15530)[0m 
[2m[36m(pid=15530)[0m   | Name      | Type              | Params
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15530)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15530)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 12.0 K    Trainable params
[2m[36m(pid=15530)[0m 0         Non-trainable params
[2m[36m(pid=15530)[0m 12.0 K    Total params
[2m[36m(pid=5485)[0m time to fit was 63.86799144744873
[2m[36m(pid=5485)[0m GPU available: False, used: False
[2m[36m(pid=5485)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=5485)[0m 
[2m[36m(pid=5485)[0m   | Name      | Type              | Params
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=5485)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=5485)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=5485)[0m ------------------------------------------------
[2m[36m(pid=5485)[0m 12.0 K    Trainable params
[2m[36m(pid=5485)[0m 0         Non-trainable params
[2m[36m(pid=5485)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m time to fit was 63.222899436950684
[2m[36m(pid=15530)[0m GPU available: False, used: False
[2m[36m(pid=15530)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15530)[0m 
[2m[36m(pid=15530)[0m   | Name      | Type              | Params
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15530)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15530)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 12.0 K    Trainable params
[2m[36m(pid=15530)[0m 0         Non-trainable params
[2m[36m(pid=15530)[0m 12.0 K    Total params
[2m[36m(pid=5485)[0m time to fit was 56.41844725608826
Result for _inner_e98d6_00144:
  auc: 0.8266710758209228
  date: 2021-03-18_02-31-12
  done: false
  experiment_id: ee12890ee2e64b7b8ebcfca939e42dac
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5485
  time_since_restore: 382.638991355896
  time_this_iter_s: 382.638991355896
  time_total_s: 382.638991355896
  timestamp: 1616031072
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00144
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 151/180 (1 PENDING, 26 RUNNING, 124 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00150 | PENDING    |       |           32 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 131 more trials not shown (16 RUNNING, 114 TERMINATED)


Result for _inner_e98d6_00144:
  auc: 0.8266710758209228
  date: 2021-03-18_02-31-12
  done: true
  experiment_id: ee12890ee2e64b7b8ebcfca939e42dac
  experiment_tag: 144_batch_size=512,eta=0.0,lr=2,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 5485
  time_since_restore: 382.638991355896
  time_this_iter_s: 382.638991355896
  time_total_s: 382.638991355896
  timestamp: 1616031072
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00144
  
[2m[36m(pid=5485)[0m Finished run with seed 0 - lr 2 - sec_lr 2 - bs 512 - mean val auc: 0.8266710758209228
2021-03-18 02:31:13,427	WARNING worker.py:1034 -- The actor or task with ID ffffffffffffffff5562713101000000 cannot be scheduled right now. It requires {CPU: 2.000000} for placement, but this node only has remaining {CPU: 2.000000}, {memory: 252.441406 GiB}, {node:145.101.32.82: 1.000000}, {object_store_memory: 77.392578 GiB}. In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
[2m[36m(pid=10532)[0m time to fit was 93.0356719493866
[2m[36m(pid=21667)[0m time to fit was 4855.351283550262
[2m[36m(pid=10532)[0m GPU available: False, used: False
[2m[36m(pid=10532)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m GPU available: False, used: False
[2m[36m(pid=21667)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m 
[2m[36m(pid=21667)[0m   | Name      | Type              | Params
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21667)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21667)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 12.0 K    Trainable params
[2m[36m(pid=21667)[0m 0         Non-trainable params
[2m[36m(pid=21667)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m 
[2m[36m(pid=10532)[0m   | Name      | Type              | Params
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10532)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10532)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 12.0 K    Trainable params
[2m[36m(pid=10532)[0m 0         Non-trainable params
[2m[36m(pid=10532)[0m 12.0 K    Total params
[2m[36m(pid=16679)[0m time to fit was 463.6866283416748
Result for _inner_e98d6_00115:
  auc: 0.6092783212661743
  date: 2021-03-18_02-31-24
  done: false
  experiment_id: 4bbb4f4752ac48da89d1e32cff93edcb
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 16679
  time_since_restore: 2782.9430191516876
  time_this_iter_s: 2782.9430191516876
  time_total_s: 2782.9430191516876
  timestamp: 1616031084
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00115
  
[2m[36m(pid=16679)[0m Finished run with seed 0 - lr 5 - sec_lr 1 - bs 32 - mean val auc: 0.6092783212661743
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 152/180 (1 PENDING, 26 RUNNING, 125 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00151 | PENDING    |       |           64 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 132 more trials not shown (16 RUNNING, 115 TERMINATED)


Result for _inner_e98d6_00115:
  auc: 0.6092783212661743
  date: 2021-03-18_02-31-24
  done: true
  experiment_id: 4bbb4f4752ac48da89d1e32cff93edcb
  experiment_tag: 115_batch_size=32,eta=0.0,lr=5,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 16679
  time_since_restore: 2782.9430191516876
  time_this_iter_s: 2782.9430191516876
  time_total_s: 2782.9430191516876
  timestamp: 1616031084
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00115
  
[2m[36m(pid=20347)[0m Starting run with seed 0 - lr 0.001 - sec_lr 5 - bs 32
[2m[36m(pid=20347)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20347)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=20347)[0m GPU available: False, used: False
[2m[36m(pid=20347)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20347)[0m 
[2m[36m(pid=20347)[0m   | Name      | Type              | Params
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20347)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20347)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 12.0 K    Trainable params
[2m[36m(pid=20347)[0m 0         Non-trainable params
[2m[36m(pid=20347)[0m 12.0 K    Total params
[2m[36m(pid=20347)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20347)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20347)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20347)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20347)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=20347)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20802)[0m Starting run with seed 0 - lr 0.001 - sec_lr 5 - bs 64
[2m[36m(pid=20802)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20802)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=20802)[0m GPU available: False, used: False
[2m[36m(pid=20802)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20802)[0m 
[2m[36m(pid=20802)[0m   | Name      | Type              | Params
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20802)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20802)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 12.0 K    Trainable params
[2m[36m(pid=20802)[0m 0         Non-trainable params
[2m[36m(pid=20802)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20802)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20802)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20802)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20802)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=20802)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=1133)[0m time to fit was 377.3855504989624
[2m[36m(pid=1133)[0m GPU available: False, used: False
[2m[36m(pid=1133)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1133)[0m 
[2m[36m(pid=1133)[0m   | Name      | Type              | Params
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1133)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1133)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 12.0 K    Trainable params
[2m[36m(pid=1133)[0m 0         Non-trainable params
[2m[36m(pid=1133)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m time to fit was 234.02340579032898
[2m[36m(pid=3572)[0m GPU available: False, used: False
[2m[36m(pid=3572)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=3572)[0m 
[2m[36m(pid=3572)[0m   | Name      | Type              | Params
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=3572)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=3572)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=3572)[0m ------------------------------------------------
[2m[36m(pid=3572)[0m 12.0 K    Trainable params
[2m[36m(pid=3572)[0m 0         Non-trainable params
[2m[36m(pid=3572)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m time to fit was 45.7603542804718
[2m[36m(pid=15530)[0m GPU available: False, used: False
[2m[36m(pid=15530)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15530)[0m 
[2m[36m(pid=15530)[0m   | Name      | Type              | Params
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15530)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15530)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 12.0 K    Trainable params
[2m[36m(pid=15530)[0m 0         Non-trainable params
[2m[36m(pid=15530)[0m 12.0 K    Total params
[2m[36m(pid=44128)[0m time to fit was 421.9789514541626
[2m[36m(pid=44128)[0m Finished run with seed 0 - lr 0.01 - sec_lr 2 - bs 32 - mean val auc: 0.4986472845077515
Result for _inner_e98d6_00125:
  auc: 0.4986472845077515
  date: 2021-03-18_02-32-06
  done: false
  experiment_id: 04e97765fa1740e38b1c9c4ecc715d0a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 44128
  time_since_restore: 2114.142745256424
  time_this_iter_s: 2114.142745256424
  time_total_s: 2114.142745256424
  timestamp: 1616031126
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00125
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 153/180 (1 PENDING, 26 RUNNING, 126 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00152 | PENDING    |       |          128 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 133 more trials not shown (16 RUNNING, 116 TERMINATED)


Result for _inner_e98d6_00125:
  auc: 0.4986472845077515
  date: 2021-03-18_02-32-06
  done: true
  experiment_id: 04e97765fa1740e38b1c9c4ecc715d0a
  experiment_tag: 125_batch_size=32,eta=0.0,lr=0.01,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 44128
  time_since_restore: 2114.142745256424
  time_this_iter_s: 2114.142745256424
  time_total_s: 2114.142745256424
  timestamp: 1616031126
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00125
  
[2m[36m(pid=20824)[0m Starting run with seed 0 - lr 0.001 - sec_lr 5 - bs 128
[2m[36m(pid=20824)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20824)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=20824)[0m GPU available: False, used: False
[2m[36m(pid=20824)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20824)[0m 
[2m[36m(pid=20824)[0m   | Name      | Type              | Params
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20824)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20824)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 12.0 K    Trainable params
[2m[36m(pid=20824)[0m 0         Non-trainable params
[2m[36m(pid=20824)[0m 12.0 K    Total params
[2m[36m(pid=20824)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20824)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20824)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=20824)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20824)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=20824)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6614)[0m time to fit was 422.84284830093384
[2m[36m(pid=6614)[0m GPU available: False, used: False
[2m[36m(pid=6614)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6614)[0m 
[2m[36m(pid=6614)[0m   | Name      | Type              | Params
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6614)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6614)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 12.0 K    Trainable params
[2m[36m(pid=6614)[0m 0         Non-trainable params
[2m[36m(pid=6614)[0m 12.0 K    Total params
[2m[36m(pid=43402)[0m time to fit was 429.37816739082336
[2m[36m(pid=43402)[0m GPU available: False, used: False
[2m[36m(pid=43402)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43402)[0m 
[2m[36m(pid=43402)[0m   | Name      | Type              | Params
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43402)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43402)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 12.0 K    Trainable params
[2m[36m(pid=43402)[0m 0         Non-trainable params
[2m[36m(pid=43402)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m time to fit was 226.13713121414185
[2m[36m(pid=50284)[0m GPU available: False, used: False
[2m[36m(pid=50284)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50284)[0m 
[2m[36m(pid=50284)[0m   | Name      | Type              | Params
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50284)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50284)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 12.0 K    Trainable params
[2m[36m(pid=50284)[0m 0         Non-trainable params
[2m[36m(pid=50284)[0m 12.0 K    Total params
[2m[36m(pid=3572)[0m time to fit was 78.68623685836792
Result for _inner_e98d6_00143:
  auc: 0.8213481068611145
  date: 2021-03-18_02-33-14
  done: false
  experiment_id: 39d0b5b692a7481297e101f0545e995b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3572
  time_since_restore: 556.5445551872253
  time_this_iter_s: 556.5445551872253
  time_total_s: 556.5445551872253
  timestamp: 1616031194
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00143
  
[2m[36m(pid=3572)[0m Finished run with seed 0 - lr 2 - sec_lr 2 - bs 256 - mean val auc: 0.8213481068611145
== Status ==
Memory usage on this node: 11.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 154/180 (1 PENDING, 26 RUNNING, 127 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00153 | PENDING    |       |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 134 more trials not shown (16 RUNNING, 117 TERMINATED)


Result for _inner_e98d6_00143:
  auc: 0.8213481068611145
  date: 2021-03-18_02-33-14
  done: true
  experiment_id: 39d0b5b692a7481297e101f0545e995b
  experiment_tag: 143_batch_size=256,eta=0.0,lr=2,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 3572
  time_since_restore: 556.5445551872253
  time_this_iter_s: 556.5445551872253
  time_total_s: 556.5445551872253
  timestamp: 1616031194
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00143
  
[2m[36m(pid=25233)[0m Starting run with seed 0 - lr 0.001 - sec_lr 5 - bs 256
[2m[36m(pid=25233)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25233)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=25233)[0m GPU available: False, used: False
[2m[36m(pid=25233)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25233)[0m 
[2m[36m(pid=25233)[0m   | Name      | Type              | Params
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25233)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25233)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 12.0 K    Trainable params
[2m[36m(pid=25233)[0m 0         Non-trainable params
[2m[36m(pid=25233)[0m 12.0 K    Total params
[2m[36m(pid=25233)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25233)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25233)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=25233)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25233)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=25233)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=33698)[0m time to fit was 225.34417462348938
Result for _inner_e98d6_00136:
  auc: 0.8802610278129578
  date: 2021-03-18_02-33-54
  done: false
  experiment_id: 3af1c65342b344b69edc87d1413a1456
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 33698
  time_since_restore: 1154.1340563297272
  time_this_iter_s: 1154.1340563297272
  time_total_s: 1154.1340563297272
  timestamp: 1616031234
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00136
  
[2m[36m(pid=33698)[0m Finished run with seed 0 - lr 1 - sec_lr 2 - bs 64 - mean val auc: 0.8802610278129578
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 155/180 (1 PENDING, 26 RUNNING, 128 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00154 | PENDING    |       |          512 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 135 more trials not shown (16 RUNNING, 118 TERMINATED)


Result for _inner_e98d6_00136:
  auc: 0.8802610278129578
  date: 2021-03-18_02-33-54
  done: true
  experiment_id: 3af1c65342b344b69edc87d1413a1456
  experiment_tag: 136_batch_size=64,eta=0.0,lr=1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 33698
  time_since_restore: 1154.1340563297272
  time_this_iter_s: 1154.1340563297272
  time_total_s: 1154.1340563297272
  timestamp: 1616031234
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00136
  
[2m[36m(pid=26683)[0m Starting run with seed 0 - lr 0.001 - sec_lr 5 - bs 512
[2m[36m(pid=26683)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26683)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=26683)[0m GPU available: False, used: False
[2m[36m(pid=26683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26683)[0m 
[2m[36m(pid=26683)[0m   | Name      | Type              | Params
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 12.0 K    Trainable params
[2m[36m(pid=26683)[0m 0         Non-trainable params
[2m[36m(pid=26683)[0m 12.0 K    Total params
[2m[36m(pid=26683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26683)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=26683)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20824)[0m time to fit was 122.99786067008972
[2m[36m(pid=20824)[0m GPU available: False, used: False
[2m[36m(pid=20824)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20824)[0m 
[2m[36m(pid=20824)[0m   | Name      | Type              | Params
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20824)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20824)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 12.0 K    Trainable params
[2m[36m(pid=20824)[0m 0         Non-trainable params
[2m[36m(pid=20824)[0m 12.0 K    Total params
[2m[36m(pid=12738)[0m time to fit was 431.3540768623352
[2m[36m(pid=12738)[0m GPU available: False, used: False
[2m[36m(pid=12738)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=12738)[0m 
[2m[36m(pid=12738)[0m   | Name      | Type              | Params
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=12738)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=12738)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=12738)[0m ------------------------------------------------
[2m[36m(pid=12738)[0m 12.0 K    Trainable params
[2m[36m(pid=12738)[0m 0         Non-trainable params
[2m[36m(pid=12738)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m time to fit was 201.28257751464844
[2m[36m(pid=10532)[0m GPU available: False, used: False
[2m[36m(pid=10532)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=10532)[0m 
[2m[36m(pid=10532)[0m   | Name      | Type              | Params
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=10532)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=10532)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=10532)[0m ------------------------------------------------
[2m[36m(pid=10532)[0m 12.0 K    Trainable params
[2m[36m(pid=10532)[0m 0         Non-trainable params
[2m[36m(pid=10532)[0m 12.0 K    Total params
[2m[36m(pid=25233)[0m time to fit was 86.36614036560059
[2m[36m(pid=25233)[0m GPU available: False, used: False
[2m[36m(pid=25233)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25233)[0m 
[2m[36m(pid=25233)[0m   | Name      | Type              | Params
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25233)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25233)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 12.0 K    Trainable params
[2m[36m(pid=25233)[0m 0         Non-trainable params
[2m[36m(pid=25233)[0m 12.0 K    Total params
[2m[36m(pid=26683)[0m time to fit was 64.4852032661438
[2m[36m(pid=26683)[0m GPU available: False, used: False
[2m[36m(pid=26683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26683)[0m 
[2m[36m(pid=26683)[0m   | Name      | Type              | Params
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 12.0 K    Trainable params
[2m[36m(pid=26683)[0m 0         Non-trainable params
[2m[36m(pid=26683)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m time to fit was 219.19642448425293
[2m[36m(pid=20802)[0m GPU available: False, used: False
[2m[36m(pid=20802)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20802)[0m 
[2m[36m(pid=20802)[0m   | Name      | Type              | Params
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20802)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20802)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 12.0 K    Trainable params
[2m[36m(pid=20802)[0m 0         Non-trainable params
[2m[36m(pid=20802)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m time to fit was 427.0511746406555
[2m[36m(pid=32429)[0m GPU available: False, used: False
[2m[36m(pid=32429)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=32429)[0m 
[2m[36m(pid=32429)[0m   | Name      | Type              | Params
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=32429)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=32429)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 12.0 K    Trainable params
[2m[36m(pid=32429)[0m 0         Non-trainable params
[2m[36m(pid=32429)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m time to fit was 393.81960248947144
[2m[36m(pid=8006)[0m GPU available: False, used: False
[2m[36m(pid=8006)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8006)[0m 
[2m[36m(pid=8006)[0m   | Name      | Type              | Params
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8006)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8006)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 12.0 K    Trainable params
[2m[36m(pid=8006)[0m 0         Non-trainable params
[2m[36m(pid=8006)[0m 12.0 K    Total params
[2m[36m(pid=26683)[0m time to fit was 79.27413940429688
[2m[36m(pid=26683)[0m GPU available: False, used: False
[2m[36m(pid=26683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26683)[0m 
[2m[36m(pid=26683)[0m   | Name      | Type              | Params
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 12.0 K    Trainable params
[2m[36m(pid=26683)[0m 0         Non-trainable params
[2m[36m(pid=26683)[0m 12.0 K    Total params
[2m[36m(pid=1133)[0m time to fit was 286.76624631881714
[2m[36m(pid=1133)[0m GPU available: False, used: False
[2m[36m(pid=1133)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1133)[0m 
[2m[36m(pid=1133)[0m   | Name      | Type              | Params
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1133)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1133)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 12.0 K    Trainable params
[2m[36m(pid=1133)[0m 0         Non-trainable params
[2m[36m(pid=1133)[0m 12.0 K    Total params
[2m[36m(pid=15530)[0m time to fit was 288.43979001045227
[2m[36m(pid=15530)[0m GPU available: False, used: False
[2m[36m(pid=15530)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=15530)[0m 
[2m[36m(pid=15530)[0m   | Name      | Type              | Params
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=15530)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=15530)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=15530)[0m ------------------------------------------------
[2m[36m(pid=15530)[0m 12.0 K    Trainable params
[2m[36m(pid=15530)[0m 0         Non-trainable params
[2m[36m(pid=15530)[0m 12.0 K    Total params
[2m[36m(pid=20824)[0m time to fit was 148.9374966621399
[2m[36m(pid=20824)[0m GPU available: False, used: False
[2m[36m(pid=20824)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20824)[0m 
[2m[36m(pid=20824)[0m   | Name      | Type              | Params
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20824)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20824)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 12.0 K    Trainable params
[2m[36m(pid=20824)[0m 0         Non-trainable params
[2m[36m(pid=20824)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m time to fit was 224.07389116287231
[2m[36m(pid=50284)[0m GPU available: False, used: False
[2m[36m(pid=50284)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=50284)[0m 
[2m[36m(pid=50284)[0m   | Name      | Type              | Params
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=50284)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=50284)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=50284)[0m ------------------------------------------------
[2m[36m(pid=50284)[0m 12.0 K    Trainable params
[2m[36m(pid=50284)[0m 0         Non-trainable params
[2m[36m(pid=50284)[0m 12.0 K    Total params
[2m[36m(pid=10532)[0m time to fit was 168.6318702697754
[2m[36m(pid=10532)[0m Finished run with seed 0 - lr 5 - sec_lr 2 - bs 256 - mean val auc: 0.6766778886318207
Result for _inner_e98d6_00148:
  auc: 0.6766778886318207
  date: 2021-03-18_02-37-26
  done: false
  experiment_id: 94410f54c64f46b5b570f4308b5aaa88
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 10532
  time_since_restore: 620.552357673645
  time_this_iter_s: 620.552357673645
  time_total_s: 620.552357673645
  timestamp: 1616031446
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00148
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 156/180 (1 PENDING, 26 RUNNING, 129 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00155 | PENDING    |       |           32 |     0 | 0.01  |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 136 more trials not shown (16 RUNNING, 119 TERMINATED)


Result for _inner_e98d6_00148:
  auc: 0.6766778886318207
  date: 2021-03-18_02-37-26
  done: true
  experiment_id: 94410f54c64f46b5b570f4308b5aaa88
  experiment_tag: 148_batch_size=256,eta=0.0,lr=5,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 10532
  time_since_restore: 620.552357673645
  time_this_iter_s: 620.552357673645
  time_total_s: 620.552357673645
  timestamp: 1616031446
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00148
  
[2m[36m(pid=26683)[0m time to fit was 63.960127115249634
[2m[36m(pid=26683)[0m GPU available: False, used: False
[2m[36m(pid=26683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26683)[0m 
[2m[36m(pid=26683)[0m   | Name      | Type              | Params
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 12.0 K    Trainable params
[2m[36m(pid=26683)[0m 0         Non-trainable params
[2m[36m(pid=26683)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m Starting run with seed 0 - lr 0.01 - sec_lr 5 - bs 32
[2m[36m(pid=35505)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35505)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=35505)[0m GPU available: False, used: False
[2m[36m(pid=35505)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35505)[0m 
[2m[36m(pid=35505)[0m   | Name      | Type              | Params
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35505)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35505)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 12.0 K    Trainable params
[2m[36m(pid=35505)[0m 0         Non-trainable params
[2m[36m(pid=35505)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35505)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35505)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=35505)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=35505)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=35505)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=15530)[0m time to fit was 68.27347111701965
Result for _inner_e98d6_00149:
  auc: 0.6298695206642151
  date: 2021-03-18_02-37-55
  done: false
  experiment_id: c65d6ad00eb64c7a9029ca6e9435b5ce
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15530
  time_since_restore: 513.6342422962189
  time_this_iter_s: 513.6342422962189
  time_total_s: 513.6342422962189
  timestamp: 1616031475
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00149
  
[2m[36m(pid=15530)[0m Finished run with seed 0 - lr 5 - sec_lr 2 - bs 512 - mean val auc: 0.6298695206642151
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 157/180 (1 PENDING, 26 RUNNING, 130 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00156 | PENDING    |       |           64 |     0 | 0.01  |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 137 more trials not shown (16 RUNNING, 120 TERMINATED)


Result for _inner_e98d6_00149:
  auc: 0.6298695206642151
  date: 2021-03-18_02-37-55
  done: true
  experiment_id: c65d6ad00eb64c7a9029ca6e9435b5ce
  experiment_tag: 149_batch_size=512,eta=0.0,lr=5,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 15530
  time_since_restore: 513.6342422962189
  time_this_iter_s: 513.6342422962189
  time_total_s: 513.6342422962189
  timestamp: 1616031475
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00149
  
[2m[36m(pid=36606)[0m Starting run with seed 0 - lr 0.01 - sec_lr 5 - bs 64
[2m[36m(pid=36606)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=36606)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=36606)[0m GPU available: False, used: False
[2m[36m(pid=36606)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36606)[0m 
[2m[36m(pid=36606)[0m   | Name      | Type              | Params
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36606)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36606)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 12.0 K    Trainable params
[2m[36m(pid=36606)[0m 0         Non-trainable params
[2m[36m(pid=36606)[0m 12.0 K    Total params
[2m[36m(pid=36606)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36606)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36606)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=36606)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36606)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=36606)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=20347)[0m time to fit was 425.7513608932495
[2m[36m(pid=20347)[0m GPU available: False, used: False
[2m[36m(pid=20347)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20347)[0m 
[2m[36m(pid=20347)[0m   | Name      | Type              | Params
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20347)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20347)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 12.0 K    Trainable params
[2m[36m(pid=20347)[0m 0         Non-trainable params
[2m[36m(pid=20347)[0m 12.0 K    Total params
[2m[36m(pid=1133)[0m time to fit was 146.80021381378174
[2m[36m(pid=1133)[0m GPU available: False, used: False
[2m[36m(pid=1133)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=1133)[0m 
[2m[36m(pid=1133)[0m   | Name      | Type              | Params
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=1133)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=1133)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=1133)[0m ------------------------------------------------
[2m[36m(pid=1133)[0m 12.0 K    Trainable params
[2m[36m(pid=1133)[0m 0         Non-trainable params
[2m[36m(pid=1133)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m time to fit was 224.02703738212585
[2m[36m(pid=20802)[0m GPU available: False, used: False
[2m[36m(pid=20802)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20802)[0m 
[2m[36m(pid=20802)[0m   | Name      | Type              | Params
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20802)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20802)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 12.0 K    Trainable params
[2m[36m(pid=20802)[0m 0         Non-trainable params
[2m[36m(pid=20802)[0m 12.0 K    Total params
[2m[36m(pid=20824)[0m time to fit was 135.13138604164124
[2m[36m(pid=20824)[0m GPU available: False, used: False
[2m[36m(pid=20824)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20824)[0m 
[2m[36m(pid=20824)[0m   | Name      | Type              | Params
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20824)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20824)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 12.0 K    Trainable params
[2m[36m(pid=20824)[0m 0         Non-trainable params
[2m[36m(pid=20824)[0m 12.0 K    Total params
[2m[36m(pid=26683)[0m time to fit was 101.17014932632446
[2m[36m(pid=26683)[0m GPU available: False, used: False
[2m[36m(pid=26683)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26683)[0m 
[2m[36m(pid=26683)[0m   | Name      | Type              | Params
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26683)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26683)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26683)[0m ------------------------------------------------
[2m[36m(pid=26683)[0m 12.0 K    Trainable params
[2m[36m(pid=26683)[0m 0         Non-trainable params
[2m[36m(pid=26683)[0m 12.0 K    Total params
[2m[36m(pid=6614)[0m time to fit was 419.630352973938
[2m[36m(pid=6614)[0m GPU available: False, used: False
[2m[36m(pid=6614)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6614)[0m 
[2m[36m(pid=6614)[0m   | Name      | Type              | Params
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6614)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6614)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 12.0 K    Trainable params
[2m[36m(pid=6614)[0m 0         Non-trainable params
[2m[36m(pid=6614)[0m 12.0 K    Total params
[2m[36m(pid=25233)[0m time to fit was 278.18302845954895
[2m[36m(pid=25233)[0m GPU available: False, used: False
[2m[36m(pid=25233)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25233)[0m 
[2m[36m(pid=25233)[0m   | Name      | Type              | Params
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25233)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25233)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 12.0 K    Trainable params
[2m[36m(pid=25233)[0m 0         Non-trainable params
[2m[36m(pid=25233)[0m 12.0 K    Total params
[2m[36m(pid=43402)[0m time to fit was 424.51599764823914
[2m[36m(pid=43402)[0m GPU available: False, used: False
[2m[36m(pid=43402)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43402)[0m 
[2m[36m(pid=43402)[0m   | Name      | Type              | Params
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43402)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43402)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 12.0 K    Trainable params
[2m[36m(pid=43402)[0m 0         Non-trainable params
[2m[36m(pid=43402)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m time to fit was 715.1184301376343
[2m[36m(pid=8554)[0m GPU available: False, used: False
[2m[36m(pid=8554)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8554)[0m 
[2m[36m(pid=8554)[0m   | Name      | Type              | Params
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8554)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8554)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 12.0 K    Trainable params
[2m[36m(pid=8554)[0m 0         Non-trainable params
[2m[36m(pid=8554)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m time to fit was 244.332768201828
[2m[36m(pid=8006)[0m GPU available: False, used: False
[2m[36m(pid=8006)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8006)[0m 
[2m[36m(pid=8006)[0m   | Name      | Type              | Params
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8006)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8006)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 12.0 K    Trainable params
[2m[36m(pid=8006)[0m 0         Non-trainable params
[2m[36m(pid=8006)[0m 12.0 K    Total params
[2m[36m(pid=26683)[0m time to fit was 62.602481842041016
Result for _inner_e98d6_00154:
  auc: 0.7923456907272339
  date: 2021-03-18_02-40-17
  done: false
  experiment_id: eea8113c296141c5b492eda2a7ce9881
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26683
  time_since_restore: 372.79749870300293
  time_this_iter_s: 372.79749870300293
  time_total_s: 372.79749870300293
  timestamp: 1616031617
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00154
  
[2m[36m(pid=26683)[0m Finished run with seed 0 - lr 0.001 - sec_lr 5 - bs 512 - mean val auc: 0.7923456907272339
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 158/180 (1 PENDING, 26 RUNNING, 131 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00157 | PENDING    |       |          128 |     0 | 0.01  |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 138 more trials not shown (16 RUNNING, 121 TERMINATED)


Result for _inner_e98d6_00154:
  auc: 0.7923456907272339
  date: 2021-03-18_02-40-17
  done: true
  experiment_id: eea8113c296141c5b492eda2a7ce9881
  experiment_tag: 154_batch_size=512,eta=0.0,lr=0.001,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26683
  time_since_restore: 372.79749870300293
  time_this_iter_s: 372.79749870300293
  time_total_s: 372.79749870300293
  timestamp: 1616031617
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00154
  
[2m[36m(pid=41807)[0m Starting run with seed 0 - lr 0.01 - sec_lr 5 - bs 128
[2m[36m(pid=41807)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41807)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=41807)[0m GPU available: False, used: False
[2m[36m(pid=41807)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41807)[0m 
[2m[36m(pid=41807)[0m   | Name      | Type              | Params
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41807)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41807)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 12.0 K    Trainable params
[2m[36m(pid=41807)[0m 0         Non-trainable params
[2m[36m(pid=41807)[0m 12.0 K    Total params
[2m[36m(pid=41807)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41807)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41807)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=41807)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41807)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=41807)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=25233)[0m time to fit was 90.99673914909363
[2m[36m(pid=25233)[0m GPU available: False, used: False
[2m[36m(pid=25233)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25233)[0m 
[2m[36m(pid=25233)[0m   | Name      | Type              | Params
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25233)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25233)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 12.0 K    Trainable params
[2m[36m(pid=25233)[0m 0         Non-trainable params
[2m[36m(pid=25233)[0m 12.0 K    Total params
[2m[36m(pid=20824)[0m time to fit was 121.36203646659851
[2m[36m(pid=20824)[0m GPU available: False, used: False
[2m[36m(pid=20824)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20824)[0m 
[2m[36m(pid=20824)[0m   | Name      | Type              | Params
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20824)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20824)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20824)[0m ------------------------------------------------
[2m[36m(pid=20824)[0m 12.0 K    Trainable params
[2m[36m(pid=20824)[0m 0         Non-trainable params
[2m[36m(pid=20824)[0m 12.0 K    Total params
[2m[36m(pid=50284)[0m time to fit was 263.78355836868286
[2m[36m(pid=50284)[0m Finished run with seed 0 - lr 2 - sec_lr 2 - bs 64 - mean val auc: 0.7509201049804688
Result for _inner_e98d6_00141:
  auc: 0.7509201049804688
  date: 2021-03-18_02-41-20
  done: false
  experiment_id: 449c76fbf5264820991cb105baa0721f
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 50284
  time_since_restore: 1201.3647665977478
  time_this_iter_s: 1201.3647665977478
  time_total_s: 1201.3647665977478
  timestamp: 1616031680
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00141
  
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 159/180 (1 PENDING, 26 RUNNING, 132 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00158 | PENDING    |       |          256 |     0 | 0.01  |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 139 more trials not shown (16 RUNNING, 122 TERMINATED)


Result for _inner_e98d6_00141:
  auc: 0.7509201049804688
  date: 2021-03-18_02-41-20
  done: true
  experiment_id: 449c76fbf5264820991cb105baa0721f
  experiment_tag: 141_batch_size=64,eta=0.0,lr=2,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 50284
  time_since_restore: 1201.3647665977478
  time_this_iter_s: 1201.3647665977478
  time_total_s: 1201.3647665977478
  timestamp: 1616031680
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00141
  
[2m[36m(pid=1133)[0m time to fit was 144.2130036354065
Result for _inner_e98d6_00142:
  auc: 0.9050185203552246
  date: 2021-03-18_02-41-21
  done: false
  experiment_id: 1cc25bd79c65443e884eda55e3789e50
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 1133
  time_since_restore: 1102.9499440193176
  time_this_iter_s: 1102.9499440193176
  time_total_s: 1102.9499440193176
  timestamp: 1616031681
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00142
  
[2m[36m(pid=1133)[0m Finished run with seed 0 - lr 2 - sec_lr 2 - bs 128 - mean val auc: 0.9050185203552246
Result for _inner_e98d6_00142:
  auc: 0.9050185203552246
  date: 2021-03-18_02-41-21
  done: true
  experiment_id: 1cc25bd79c65443e884eda55e3789e50
  experiment_tag: 142_batch_size=128,eta=0.0,lr=2,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 1133
  time_since_restore: 1102.9499440193176
  time_this_iter_s: 1102.9499440193176
  time_total_s: 1102.9499440193176
  timestamp: 1616031681
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00142
  
[2m[36m(pid=43951)[0m Starting run with seed 0 - lr 0.01 - sec_lr 5 - bs 512
[2m[36m(pid=43951)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43951)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43919)[0m Starting run with seed 0 - lr 0.01 - sec_lr 5 - bs 256
[2m[36m(pid=43951)[0m GPU available: False, used: False
[2m[36m(pid=43951)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43919)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43919)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43919)[0m GPU available: False, used: False
[2m[36m(pid=43919)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43951)[0m 
[2m[36m(pid=43951)[0m   | Name      | Type              | Params
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43951)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43951)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 12.0 K    Trainable params
[2m[36m(pid=43951)[0m 0         Non-trainable params
[2m[36m(pid=43951)[0m 12.0 K    Total params
[2m[36m(pid=43951)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43951)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m   | Name      | Type              | Params
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43919)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43919)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 12.0 K    Trainable params
[2m[36m(pid=43919)[0m 0         Non-trainable params
[2m[36m(pid=43919)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43919)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43951)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43951)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43919)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43919)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43951)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43951)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43919)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43919)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=12738)[0m time to fit was 430.94832038879395
Result for _inner_e98d6_00130:
  auc: 0.7453914165496827
  date: 2021-03-18_02-41-35
  done: false
  experiment_id: e8dc29761a8d4264b18ff70e40fcc1f9
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 12738
  time_since_restore: 2138.244337797165
  time_this_iter_s: 2138.244337797165
  time_total_s: 2138.244337797165
  timestamp: 1616031695
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00130
  
[2m[36m(pid=12738)[0m Finished run with seed 0 - lr 0.1 - sec_lr 2 - bs 32 - mean val auc: 0.7453914165496827
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 161/180 (1 PENDING, 26 RUNNING, 134 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00160 | PENDING    |       |           32 |     0 | 0.1   |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 141 more trials not shown (16 RUNNING, 124 TERMINATED)


Result for _inner_e98d6_00130:
  auc: 0.7453914165496827
  date: 2021-03-18_02-41-35
  done: true
  experiment_id: e8dc29761a8d4264b18ff70e40fcc1f9
  experiment_tag: 130_batch_size=32,eta=0.0,lr=0.1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 12738
  time_since_restore: 2138.244337797165
  time_this_iter_s: 2138.244337797165
  time_total_s: 2138.244337797165
  timestamp: 1616031695
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00130
  
[2m[36m(pid=43993)[0m Starting run with seed 0 - lr 0.1 - sec_lr 5 - bs 32
[2m[36m(pid=43993)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43993)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43993)[0m GPU available: False, used: False
[2m[36m(pid=43993)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43993)[0m 
[2m[36m(pid=43993)[0m   | Name      | Type              | Params
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43993)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43993)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 12.0 K    Trainable params
[2m[36m(pid=43993)[0m 0         Non-trainable params
[2m[36m(pid=43993)[0m 12.0 K    Total params
[2m[36m(pid=43993)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43993)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43993)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43993)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36606)[0m time to fit was 219.29136991500854
[2m[36m(pid=43993)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43993)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=36606)[0m GPU available: False, used: False
[2m[36m(pid=36606)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36606)[0m 
[2m[36m(pid=36606)[0m   | Name      | Type              | Params
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36606)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36606)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 12.0 K    Trainable params
[2m[36m(pid=36606)[0m 0         Non-trainable params
[2m[36m(pid=36606)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m time to fit was 424.08014273643494
[2m[36m(pid=32429)[0m GPU available: False, used: False
[2m[36m(pid=32429)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=32429)[0m 
[2m[36m(pid=32429)[0m   | Name      | Type              | Params
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=32429)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=32429)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=32429)[0m ------------------------------------------------
[2m[36m(pid=32429)[0m 12.0 K    Trainable params
[2m[36m(pid=32429)[0m 0         Non-trainable params
[2m[36m(pid=32429)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m time to fit was 134.39912462234497
[2m[36m(pid=8554)[0m GPU available: False, used: False
[2m[36m(pid=8554)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8554)[0m 
[2m[36m(pid=8554)[0m   | Name      | Type              | Params
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8554)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8554)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 12.0 K    Trainable params
[2m[36m(pid=8554)[0m 0         Non-trainable params
[2m[36m(pid=8554)[0m 12.0 K    Total params
[2m[36m(pid=25233)[0m time to fit was 99.36034417152405
[2m[36m(pid=25233)[0m GPU available: False, used: False
[2m[36m(pid=25233)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=25233)[0m 
[2m[36m(pid=25233)[0m   | Name      | Type              | Params
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=25233)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=25233)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=25233)[0m ------------------------------------------------
[2m[36m(pid=25233)[0m 12.0 K    Trainable params
[2m[36m(pid=25233)[0m 0         Non-trainable params
[2m[36m(pid=25233)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m time to fit was 222.83723855018616
[2m[36m(pid=20802)[0m GPU available: False, used: False
[2m[36m(pid=20802)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20802)[0m 
[2m[36m(pid=20802)[0m   | Name      | Type              | Params
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20802)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20802)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 12.0 K    Trainable params
[2m[36m(pid=20802)[0m 0         Non-trainable params
[2m[36m(pid=20802)[0m 12.0 K    Total params
[2m[36m(pid=43951)[0m time to fit was 78.67635107040405
[2m[36m(pid=43951)[0m GPU available: False, used: False
[2m[36m(pid=43951)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43951)[0m 
[2m[36m(pid=43951)[0m   | Name      | Type              | Params
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43951)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43951)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 12.0 K    Trainable params
[2m[36m(pid=43951)[0m 0         Non-trainable params
[2m[36m(pid=43951)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m time to fit was 92.57164311408997
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m GPU available: False, used: False
[2m[36m(pid=43919)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m   | Name      | Type              | Params
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43919)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43919)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 12.0 K    Trainable params
[2m[36m(pid=43919)[0m 0         Non-trainable params
[2m[36m(pid=43919)[0m 12.0 K    Total params
[2m[36m(pid=20824)[0m time to fit was 123.60919189453125
Result for _inner_e98d6_00152:
  auc: 0.7566665291786194
  date: 2021-03-18_02-43-08
  done: false
  experiment_id: 614db0d95e244a20a739eedb62ad89d6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20824
  time_since_restore: 653.3611783981323
  time_this_iter_s: 653.3611783981323
  time_total_s: 653.3611783981323
  timestamp: 1616031788
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00152
  
[2m[36m(pid=20824)[0m Finished run with seed 0 - lr 0.001 - sec_lr 5 - bs 128 - mean val auc: 0.7566665291786194
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 162/180 (1 PENDING, 26 RUNNING, 135 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00161 | PENDING    |       |           64 |     0 | 0.1   |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 142 more trials not shown (16 RUNNING, 125 TERMINATED)


Result for _inner_e98d6_00152:
  auc: 0.7566665291786194
  date: 2021-03-18_02-43-08
  done: true
  experiment_id: 614db0d95e244a20a739eedb62ad89d6
  experiment_tag: 152_batch_size=128,eta=0.0,lr=0.001,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20824
  time_since_restore: 653.3611783981323
  time_this_iter_s: 653.3611783981323
  time_total_s: 653.3611783981323
  timestamp: 1616031788
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00152
  
[2m[36m(pid=43957)[0m Starting run with seed 0 - lr 0.1 - sec_lr 5 - bs 64
[2m[36m(pid=43957)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43957)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43957)[0m GPU available: False, used: False
[2m[36m(pid=43957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43957)[0m 
[2m[36m(pid=43957)[0m   | Name      | Type              | Params
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 12.0 K    Trainable params
[2m[36m(pid=43957)[0m 0         Non-trainable params
[2m[36m(pid=43957)[0m 12.0 K    Total params
[2m[36m(pid=43957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43957)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43957)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43957)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43957)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=8006)[0m time to fit was 226.34066224098206
[2m[36m(pid=8006)[0m GPU available: False, used: False
[2m[36m(pid=8006)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8006)[0m 
[2m[36m(pid=8006)[0m   | Name      | Type              | Params
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8006)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8006)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8006)[0m ------------------------------------------------
[2m[36m(pid=8006)[0m 12.0 K    Trainable params
[2m[36m(pid=8006)[0m 0         Non-trainable params
[2m[36m(pid=8006)[0m 12.0 K    Total params
[2m[36m(pid=43951)[0m time to fit was 75.60631084442139
[2m[36m(pid=43951)[0m GPU available: False, used: False
[2m[36m(pid=43951)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43951)[0m 
[2m[36m(pid=43951)[0m   | Name      | Type              | Params
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43951)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43951)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 12.0 K    Trainable params
[2m[36m(pid=43951)[0m 0         Non-trainable params
[2m[36m(pid=43951)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m time to fit was 123.98783254623413
[2m[36m(pid=8554)[0m GPU available: False, used: False
[2m[36m(pid=8554)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=8554)[0m 
[2m[36m(pid=8554)[0m   | Name      | Type              | Params
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=8554)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=8554)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=8554)[0m ------------------------------------------------
[2m[36m(pid=8554)[0m 12.0 K    Trainable params
[2m[36m(pid=8554)[0m 0         Non-trainable params
[2m[36m(pid=8554)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m time to fit was 89.6600570678711
[2m[36m(pid=43919)[0m GPU available: False, used: False
[2m[36m(pid=43919)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m   | Name      | Type              | Params
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43919)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43919)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 12.0 K    Trainable params
[2m[36m(pid=43919)[0m 0         Non-trainable params
[2m[36m(pid=43919)[0m 12.0 K    Total params
[2m[36m(pid=41807)[0m time to fit was 282.62054347991943
[2m[36m(pid=41807)[0m GPU available: False, used: False
[2m[36m(pid=41807)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41807)[0m 
[2m[36m(pid=41807)[0m   | Name      | Type              | Params
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41807)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41807)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 12.0 K    Trainable params
[2m[36m(pid=41807)[0m 0         Non-trainable params
[2m[36m(pid=41807)[0m 12.0 K    Total params
[2m[36m(pid=20347)[0m time to fit was 425.48779678344727
[2m[36m(pid=20347)[0m GPU available: False, used: False
[2m[36m(pid=20347)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20347)[0m 
[2m[36m(pid=20347)[0m   | Name      | Type              | Params
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20347)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20347)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 12.0 K    Trainable params
[2m[36m(pid=20347)[0m 0         Non-trainable params
[2m[36m(pid=20347)[0m 12.0 K    Total params
[2m[36m(pid=36606)[0m time to fit was 243.56300163269043
[2m[36m(pid=36606)[0m GPU available: False, used: False
[2m[36m(pid=36606)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36606)[0m 
[2m[36m(pid=36606)[0m   | Name      | Type              | Params
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36606)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36606)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 12.0 K    Trainable params
[2m[36m(pid=36606)[0m 0         Non-trainable params
[2m[36m(pid=36606)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m time to fit was 99.08338761329651
[2m[36m(pid=43919)[0m GPU available: False, used: False
[2m[36m(pid=43919)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m   | Name      | Type              | Params
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43919)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43919)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 12.0 K    Trainable params
[2m[36m(pid=43919)[0m 0         Non-trainable params
[2m[36m(pid=43919)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m time to fit was 224.57249927520752
[2m[36m(pid=20802)[0m GPU available: False, used: False
[2m[36m(pid=20802)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20802)[0m 
[2m[36m(pid=20802)[0m   | Name      | Type              | Params
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20802)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20802)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20802)[0m ------------------------------------------------
[2m[36m(pid=20802)[0m 12.0 K    Trainable params
[2m[36m(pid=20802)[0m 0         Non-trainable params
[2m[36m(pid=20802)[0m 12.0 K    Total params
[2m[36m(pid=8554)[0m time to fit was 136.25583958625793
Result for _inner_e98d6_00147:
  auc: 0.5789586186408997
  date: 2021-03-18_02-46-43
  done: false
  experiment_id: 0eb12824c91e4be2b7b2577eb39534db
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 8554
  time_since_restore: 1233.0223407745361
  time_this_iter_s: 1233.0223407745361
  time_total_s: 1233.0223407745361
  timestamp: 1616032003
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00147
  
[2m[36m(pid=8554)[0m Finished run with seed 0 - lr 5 - sec_lr 2 - bs 128 - mean val auc: 0.5789586186408997
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 163/180 (1 PENDING, 26 RUNNING, 136 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00162 | PENDING    |       |          128 |     0 | 0.1   |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 143 more trials not shown (16 RUNNING, 126 TERMINATED)


Result for _inner_e98d6_00147:
  auc: 0.5789586186408997
  date: 2021-03-18_02-46-43
  done: true
  experiment_id: 0eb12824c91e4be2b7b2577eb39534db
  experiment_tag: 147_batch_size=128,eta=0.0,lr=5,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 8554
  time_since_restore: 1233.0223407745361
  time_this_iter_s: 1233.0223407745361
  time_total_s: 1233.0223407745361
  timestamp: 1616032003
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00147
  
[2m[36m(pid=43955)[0m Starting run with seed 0 - lr 0.1 - sec_lr 5 - bs 128
[2m[36m(pid=43955)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43955)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43955)[0m GPU available: False, used: False
[2m[36m(pid=43955)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43955)[0m 
[2m[36m(pid=43955)[0m   | Name      | Type              | Params
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43955)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43955)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 12.0 K    Trainable params
[2m[36m(pid=43955)[0m 0         Non-trainable params
[2m[36m(pid=43955)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43955)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43955)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43955)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43955)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43955)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43957)[0m time to fit was 220.60575699806213
[2m[36m(pid=43957)[0m GPU available: False, used: False
[2m[36m(pid=43957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43957)[0m 
[2m[36m(pid=43957)[0m   | Name      | Type              | Params
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 12.0 K    Trainable params
[2m[36m(pid=43957)[0m 0         Non-trainable params
[2m[36m(pid=43957)[0m 12.0 K    Total params
[2m[36m(pid=41807)[0m time to fit was 133.54512739181519
[2m[36m(pid=41807)[0m GPU available: False, used: False
[2m[36m(pid=41807)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41807)[0m 
[2m[36m(pid=41807)[0m   | Name      | Type              | Params
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41807)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41807)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 12.0 K    Trainable params
[2m[36m(pid=41807)[0m 0         Non-trainable params
[2m[36m(pid=41807)[0m 12.0 K    Total params
[2m[36m(pid=8006)[0m time to fit was 224.7484941482544
Result for _inner_e98d6_00146:
  auc: 0.6007119238376617
  date: 2021-03-18_02-47-48
  done: false
  experiment_id: 996b1dcf815f463798808f2983e8e09b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 8006
  time_since_restore: 1311.2719345092773
  time_this_iter_s: 1311.2719345092773
  time_total_s: 1311.2719345092773
  timestamp: 1616032068
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00146
  
[2m[36m(pid=8006)[0m Finished run with seed 0 - lr 5 - sec_lr 2 - bs 64 - mean val auc: 0.6007119238376617
== Status ==
Memory usage on this node: 11.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 164/180 (1 PENDING, 26 RUNNING, 137 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00163 | PENDING    |       |          256 |     0 | 0.1   |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 144 more trials not shown (16 RUNNING, 127 TERMINATED)


Result for _inner_e98d6_00146:
  auc: 0.6007119238376617
  date: 2021-03-18_02-47-48
  done: true
  experiment_id: 996b1dcf815f463798808f2983e8e09b
  experiment_tag: 146_batch_size=64,eta=0.0,lr=5,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 8006
  time_since_restore: 1311.2719345092773
  time_this_iter_s: 1311.2719345092773
  time_total_s: 1311.2719345092773
  timestamp: 1616032068
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00146
  
[2m[36m(pid=43953)[0m Starting run with seed 0 - lr 0.1 - sec_lr 5 - bs 256
[2m[36m(pid=43953)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43953)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=43953)[0m GPU available: False, used: False
[2m[36m(pid=43953)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43953)[0m 
[2m[36m(pid=43953)[0m   | Name      | Type              | Params
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43953)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43953)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 12.0 K    Trainable params
[2m[36m(pid=43953)[0m 0         Non-trainable params
[2m[36m(pid=43953)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43953)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43953)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=43953)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43953)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=43953)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43402)[0m time to fit was 507.04335379600525
[2m[36m(pid=43402)[0m GPU available: False, used: False
[2m[36m(pid=43402)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43402)[0m 
[2m[36m(pid=43402)[0m   | Name      | Type              | Params
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43402)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43402)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43402)[0m ------------------------------------------------
[2m[36m(pid=43402)[0m 12.0 K    Trainable params
[2m[36m(pid=43402)[0m 0         Non-trainable params
[2m[36m(pid=43402)[0m 12.0 K    Total params
[2m[36m(pid=43993)[0m time to fit was 423.45198249816895
[2m[36m(pid=43993)[0m GPU available: False, used: False
[2m[36m(pid=43993)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43993)[0m 
[2m[36m(pid=43993)[0m   | Name      | Type              | Params
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43993)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43993)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 12.0 K    Trainable params
[2m[36m(pid=43993)[0m 0         Non-trainable params
[2m[36m(pid=43993)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m time to fit was 120.90679883956909
[2m[36m(pid=43955)[0m GPU available: False, used: False
[2m[36m(pid=43955)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43955)[0m 
[2m[36m(pid=43955)[0m   | Name      | Type              | Params
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43955)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43955)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 12.0 K    Trainable params
[2m[36m(pid=43955)[0m 0         Non-trainable params
[2m[36m(pid=43955)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m time to fit was 78.00933122634888
[2m[36m(pid=43953)[0m GPU available: False, used: False
[2m[36m(pid=43953)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43953)[0m 
[2m[36m(pid=43953)[0m   | Name      | Type              | Params
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43953)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43953)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 12.0 K    Trainable params
[2m[36m(pid=43953)[0m 0         Non-trainable params
[2m[36m(pid=43953)[0m 12.0 K    Total params
[2m[36m(pid=32429)[0m time to fit was 426.43005657196045
Result for _inner_e98d6_00135:
  auc: 0.7387313544750214
  date: 2021-03-18_02-49-27
  done: false
  experiment_id: 813a64a3d972468892022f6343558c9f
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 32429
  time_since_restore: 2119.462875843048
  time_this_iter_s: 2119.462875843048
  time_total_s: 2119.462875843048
  timestamp: 1616032167
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00135
  
[2m[36m(pid=32429)[0m Finished run with seed 0 - lr 1 - sec_lr 2 - bs 32 - mean val auc: 0.7387313544750214
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 165/180 (1 PENDING, 26 RUNNING, 138 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00164 | PENDING    |       |          512 |     0 | 0.1   |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 145 more trials not shown (16 RUNNING, 128 TERMINATED)


Result for _inner_e98d6_00135:
  auc: 0.7387313544750214
  date: 2021-03-18_02-49-27
  done: true
  experiment_id: 813a64a3d972468892022f6343558c9f
  experiment_tag: 135_batch_size=32,eta=0.0,lr=1,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 32429
  time_since_restore: 2119.462875843048
  time_this_iter_s: 2119.462875843048
  time_total_s: 2119.462875843048
  timestamp: 1616032167
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00135
  
[2m[36m(pid=9544)[0m Starting run with seed 0 - lr 0.1 - sec_lr 5 - bs 512
[2m[36m(pid=9544)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9544)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=9544)[0m GPU available: False, used: False
[2m[36m(pid=9544)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9544)[0m 
[2m[36m(pid=9544)[0m   | Name      | Type              | Params
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9544)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9544)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 12.0 K    Trainable params
[2m[36m(pid=9544)[0m 0         Non-trainable params
[2m[36m(pid=9544)[0m 12.0 K    Total params
[2m[36m(pid=9544)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9544)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9544)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=9544)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9544)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=9544)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=41807)[0m time to fit was 135.35936880111694
[2m[36m(pid=41807)[0m GPU available: False, used: False
[2m[36m(pid=41807)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41807)[0m 
[2m[36m(pid=41807)[0m   | Name      | Type              | Params
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41807)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41807)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 12.0 K    Trainable params
[2m[36m(pid=41807)[0m 0         Non-trainable params
[2m[36m(pid=41807)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m time to fit was 223.81448769569397
[2m[36m(pid=43919)[0m GPU available: False, used: False
[2m[36m(pid=43919)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43919)[0m 
[2m[36m(pid=43919)[0m   | Name      | Type              | Params
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43919)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43919)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43919)[0m ------------------------------------------------
[2m[36m(pid=43919)[0m 12.0 K    Trainable params
[2m[36m(pid=43919)[0m 0         Non-trainable params
[2m[36m(pid=43919)[0m 12.0 K    Total params
[2m[36m(pid=20802)[0m time to fit was 228.79595637321472
Result for _inner_e98d6_00151:
  auc: 0.5706914365291595
  date: 2021-03-18_02-50-17
  done: false
  experiment_id: 80ee41bd4f994636911f7aecd13e99c1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20802
  time_since_restore: 1120.8043777942657
  time_this_iter_s: 1120.8043777942657
  time_total_s: 1120.8043777942657
  timestamp: 1616032217
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00151
  
[2m[36m(pid=20802)[0m Finished run with seed 0 - lr 0.001 - sec_lr 5 - bs 64 - mean val auc: 0.5706914365291595
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 166/180 (1 PENDING, 26 RUNNING, 139 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00165 | PENDING    |       |           32 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 146 more trials not shown (16 RUNNING, 129 TERMINATED)


Result for _inner_e98d6_00151:
  auc: 0.5706914365291595
  date: 2021-03-18_02-50-17
  done: true
  experiment_id: 80ee41bd4f994636911f7aecd13e99c1
  experiment_tag: 151_batch_size=64,eta=0.0,lr=0.001,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20802
  time_since_restore: 1120.8043777942657
  time_this_iter_s: 1120.8043777942657
  time_total_s: 1120.8043777942657
  timestamp: 1616032217
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00151
  
[2m[36m(pid=11525)[0m Starting run with seed 0 - lr 1 - sec_lr 5 - bs 32
[2m[36m(pid=11525)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11525)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=11525)[0m GPU available: False, used: False
[2m[36m(pid=11525)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11525)[0m 
[2m[36m(pid=11525)[0m   | Name      | Type              | Params
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11525)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11525)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 12.0 K    Trainable params
[2m[36m(pid=11525)[0m 0         Non-trainable params
[2m[36m(pid=11525)[0m 12.0 K    Total params
[2m[36m(pid=11525)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11525)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11525)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=11525)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43951)[0m time to fit was 381.77695083618164
[2m[36m(pid=11525)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=11525)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43951)[0m GPU available: False, used: False
[2m[36m(pid=43951)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43951)[0m 
[2m[36m(pid=43951)[0m   | Name      | Type              | Params
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43951)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43951)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 12.0 K    Trainable params
[2m[36m(pid=43951)[0m 0         Non-trainable params
[2m[36m(pid=43951)[0m 12.0 K    Total params
[2m[36m(pid=36606)[0m time to fit was 286.79358649253845
[2m[36m(pid=36606)[0m GPU available: False, used: False
[2m[36m(pid=36606)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36606)[0m 
[2m[36m(pid=36606)[0m   | Name      | Type              | Params
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36606)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36606)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 12.0 K    Trainable params
[2m[36m(pid=36606)[0m 0         Non-trainable params
[2m[36m(pid=36606)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m time to fit was 81.38050246238708
[2m[36m(pid=43953)[0m GPU available: False, used: False
[2m[36m(pid=43953)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43953)[0m 
[2m[36m(pid=43953)[0m   | Name      | Type              | Params
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43953)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43953)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 12.0 K    Trainable params
[2m[36m(pid=43953)[0m 0         Non-trainable params
[2m[36m(pid=43953)[0m 12.0 K    Total params
[2m[36m(pid=43957)[0m time to fit was 222.93459606170654
[2m[36m(pid=43957)[0m GPU available: False, used: False
[2m[36m(pid=43957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43957)[0m 
[2m[36m(pid=43957)[0m   | Name      | Type              | Params
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 12.0 K    Trainable params
[2m[36m(pid=43957)[0m 0         Non-trainable params
[2m[36m(pid=43957)[0m 12.0 K    Total params
[2m[36m(pid=9544)[0m time to fit was 70.56230282783508
[2m[36m(pid=9544)[0m GPU available: False, used: False
[2m[36m(pid=9544)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9544)[0m 
[2m[36m(pid=9544)[0m   | Name      | Type              | Params
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9544)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9544)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 12.0 K    Trainable params
[2m[36m(pid=9544)[0m 0         Non-trainable params
[2m[36m(pid=9544)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m time to fit was 121.26080346107483
[2m[36m(pid=43955)[0m GPU available: False, used: False
[2m[36m(pid=43955)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43955)[0m 
[2m[36m(pid=43955)[0m   | Name      | Type              | Params
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43955)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43955)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 12.0 K    Trainable params
[2m[36m(pid=43955)[0m 0         Non-trainable params
[2m[36m(pid=43955)[0m 12.0 K    Total params
[2m[36m(pid=43919)[0m time to fit was 94.56966209411621
[2m[36m(pid=43919)[0m Finished run with seed 0 - lr 0.01 - sec_lr 5 - bs 256 - mean val auc: 0.9054993510246276
Result for _inner_e98d6_00158:
  auc: 0.9054993510246276
  date: 2021-03-18_02-51-34
  done: false
  experiment_id: 0da5b16c1f754e0398081b89ccdd37dd
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43919
  time_since_restore: 601.1257903575897
  time_this_iter_s: 601.1257903575897
  time_total_s: 601.1257903575897
  timestamp: 1616032294
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00158
  
== Status ==
Memory usage on this node: 11.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 167/180 (1 PENDING, 26 RUNNING, 140 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00166 | PENDING    |       |           64 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 147 more trials not shown (16 RUNNING, 130 TERMINATED)


Result for _inner_e98d6_00158:
  auc: 0.9054993510246276
  date: 2021-03-18_02-51-34
  done: true
  experiment_id: 0da5b16c1f754e0398081b89ccdd37dd
  experiment_tag: 158_batch_size=256,eta=0.0,lr=0.01,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43919
  time_since_restore: 601.1257903575897
  time_this_iter_s: 601.1257903575897
  time_total_s: 601.1257903575897
  timestamp: 1616032294
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00158
  
[2m[36m(pid=43951)[0m time to fit was 74.09665036201477
[2m[36m(pid=43951)[0m GPU available: False, used: False
[2m[36m(pid=43951)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43951)[0m 
[2m[36m(pid=43951)[0m   | Name      | Type              | Params
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43951)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43951)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43951)[0m ------------------------------------------------
[2m[36m(pid=43951)[0m 12.0 K    Trainable params
[2m[36m(pid=43951)[0m 0         Non-trainable params
[2m[36m(pid=43951)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m Starting run with seed 0 - lr 1 - sec_lr 5 - bs 64
[2m[36m(pid=14655)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=14655)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=14655)[0m GPU available: False, used: False
[2m[36m(pid=14655)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14655)[0m 
[2m[36m(pid=14655)[0m   | Name      | Type              | Params
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14655)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14655)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 12.0 K    Trainable params
[2m[36m(pid=14655)[0m 0         Non-trainable params
[2m[36m(pid=14655)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14655)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14655)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=14655)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14655)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=14655)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9544)[0m time to fit was 61.58288931846619
[2m[36m(pid=9544)[0m GPU available: False, used: False
[2m[36m(pid=9544)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9544)[0m 
[2m[36m(pid=9544)[0m   | Name      | Type              | Params
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9544)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9544)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 12.0 K    Trainable params
[2m[36m(pid=9544)[0m 0         Non-trainable params
[2m[36m(pid=9544)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m time to fit was 81.0474009513855
[2m[36m(pid=43953)[0m GPU available: False, used: False
[2m[36m(pid=43953)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43953)[0m 
[2m[36m(pid=43953)[0m   | Name      | Type              | Params
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43953)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43953)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 12.0 K    Trainable params
[2m[36m(pid=43953)[0m 0         Non-trainable params
[2m[36m(pid=43953)[0m 12.0 K    Total params
[2m[36m(pid=21658)[0m time to fit was 10877.399711608887
[2m[36m(pid=21658)[0m GPU available: False, used: False
[2m[36m(pid=21658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21658)[0m 
[2m[36m(pid=21658)[0m   | Name      | Type              | Params
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 12.0 K    Trainable params
[2m[36m(pid=21658)[0m 0         Non-trainable params
[2m[36m(pid=21658)[0m 12.0 K    Total params
[2m[36m(pid=49412)[0m time to fit was 5689.636837720871
[2m[36m(pid=49412)[0m GPU available: False, used: False
[2m[36m(pid=49412)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=49412)[0m 
[2m[36m(pid=49412)[0m   | Name      | Type              | Params
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=49412)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=49412)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 12.0 K    Trainable params
[2m[36m(pid=49412)[0m 0         Non-trainable params
[2m[36m(pid=49412)[0m 12.0 K    Total params
[2m[36m(pid=41807)[0m time to fit was 149.44994497299194
[2m[36m(pid=41807)[0m GPU available: False, used: False
[2m[36m(pid=41807)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=41807)[0m 
[2m[36m(pid=41807)[0m   | Name      | Type              | Params
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=41807)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=41807)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=41807)[0m ------------------------------------------------
[2m[36m(pid=41807)[0m 12.0 K    Trainable params
[2m[36m(pid=41807)[0m 0         Non-trainable params
[2m[36m(pid=41807)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m time to fit was 887.717452287674
[2m[36m(pid=35505)[0m GPU available: False, used: False
[2m[36m(pid=35505)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35505)[0m 
[2m[36m(pid=35505)[0m   | Name      | Type              | Params
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35505)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35505)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 12.0 K    Trainable params
[2m[36m(pid=35505)[0m 0         Non-trainable params
[2m[36m(pid=35505)[0m 12.0 K    Total params
[2m[36m(pid=20347)[0m time to fit was 425.28310799598694
[2m[36m(pid=20347)[0m GPU available: False, used: False
[2m[36m(pid=20347)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20347)[0m 
[2m[36m(pid=20347)[0m   | Name      | Type              | Params
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20347)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20347)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 12.0 K    Trainable params
[2m[36m(pid=20347)[0m 0         Non-trainable params
[2m[36m(pid=20347)[0m 12.0 K    Total params
[2m[36m(pid=9544)[0m time to fit was 64.43454098701477
[2m[36m(pid=9544)[0m GPU available: False, used: False
[2m[36m(pid=9544)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9544)[0m 
[2m[36m(pid=9544)[0m   | Name      | Type              | Params
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9544)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9544)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 12.0 K    Trainable params
[2m[36m(pid=9544)[0m 0         Non-trainable params
[2m[36m(pid=9544)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m time to fit was 81.24160146713257
[2m[36m(pid=43953)[0m GPU available: False, used: False
[2m[36m(pid=43953)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43953)[0m 
[2m[36m(pid=43953)[0m   | Name      | Type              | Params
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43953)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43953)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43953)[0m ------------------------------------------------
[2m[36m(pid=43953)[0m 12.0 K    Trainable params
[2m[36m(pid=43953)[0m 0         Non-trainable params
[2m[36m(pid=43953)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m time to fit was 157.4117090702057
[2m[36m(pid=43955)[0m GPU available: False, used: False
[2m[36m(pid=43955)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43955)[0m 
[2m[36m(pid=43955)[0m   | Name      | Type              | Params
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43955)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43955)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 12.0 K    Trainable params
[2m[36m(pid=43955)[0m 0         Non-trainable params
[2m[36m(pid=43955)[0m 12.0 K    Total params
[2m[36m(pid=9544)[0m time to fit was 64.6159520149231
[2m[36m(pid=9544)[0m GPU available: False, used: False
[2m[36m(pid=9544)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=9544)[0m 
[2m[36m(pid=9544)[0m   | Name      | Type              | Params
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=9544)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=9544)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=9544)[0m ------------------------------------------------
[2m[36m(pid=9544)[0m 12.0 K    Trainable params
[2m[36m(pid=9544)[0m 0         Non-trainable params
[2m[36m(pid=9544)[0m 12.0 K    Total params
[2m[36m(pid=36606)[0m time to fit was 228.19072151184082
[2m[36m(pid=36606)[0m GPU available: False, used: False
[2m[36m(pid=36606)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=36606)[0m 
[2m[36m(pid=36606)[0m   | Name      | Type              | Params
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=36606)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=36606)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=36606)[0m ------------------------------------------------
[2m[36m(pid=36606)[0m 12.0 K    Trainable params
[2m[36m(pid=36606)[0m 0         Non-trainable params
[2m[36m(pid=36606)[0m 12.0 K    Total params
[2m[36m(pid=43957)[0m time to fit was 226.04304790496826
[2m[36m(pid=43957)[0m GPU available: False, used: False
[2m[36m(pid=43957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43957)[0m 
[2m[36m(pid=43957)[0m   | Name      | Type              | Params
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 12.0 K    Trainable params
[2m[36m(pid=43957)[0m 0         Non-trainable params
[2m[36m(pid=43957)[0m 12.0 K    Total params
[2m[36m(pid=21639)[0m time to fit was 1795.1442399024963
[2m[36m(pid=21639)[0m GPU available: False, used: False
[2m[36m(pid=21639)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21639)[0m 
[2m[36m(pid=21639)[0m   | Name      | Type              | Params
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21639)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21639)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21639)[0m ------------------------------------------------
[2m[36m(pid=21639)[0m 12.0 K    Trainable params
[2m[36m(pid=21639)[0m 0         Non-trainable params
[2m[36m(pid=21639)[0m 12.0 K    Total params
[2m[36m(pid=43953)[0m time to fit was 80.03317713737488
Result for _inner_e98d6_00163:
  auc: 0.9108455777168274
  date: 2021-03-18_02-54-40
  done: false
  experiment_id: 8f95ca54e2054877abba8b554140d44b
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43953
  time_since_restore: 403.10150623321533
  time_this_iter_s: 403.10150623321533
  time_total_s: 403.10150623321533
  timestamp: 1616032480
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00163
  
[2m[36m(pid=43953)[0m Finished run with seed 0 - lr 0.1 - sec_lr 5 - bs 256 - mean val auc: 0.9108455777168274
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 168/180 (1 PENDING, 26 RUNNING, 141 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00167 | PENDING    |       |          128 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 148 more trials not shown (16 RUNNING, 131 TERMINATED)


Result for _inner_e98d6_00163:
  auc: 0.9108455777168274
  date: 2021-03-18_02-54-40
  done: true
  experiment_id: 8f95ca54e2054877abba8b554140d44b
  experiment_tag: 163_batch_size=256,eta=0.0,lr=0.1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43953
  time_since_restore: 403.10150623321533
  time_this_iter_s: 403.10150623321533
  time_total_s: 403.10150623321533
  timestamp: 1616032480
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00163
  
[2m[36m(pid=22202)[0m Starting run with seed 0 - lr 1 - sec_lr 5 - bs 128
[2m[36m(pid=22202)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22202)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=22202)[0m GPU available: False, used: False
[2m[36m(pid=22202)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22202)[0m 
[2m[36m(pid=22202)[0m   | Name      | Type              | Params
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22202)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22202)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 12.0 K    Trainable params
[2m[36m(pid=22202)[0m 0         Non-trainable params
[2m[36m(pid=22202)[0m 12.0 K    Total params
[2m[36m(pid=22202)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22202)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22202)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=22202)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22202)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=22202)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=9544)[0m time to fit was 60.997775077819824
Result for _inner_e98d6_00164:
  auc: 0.9114290952682496
  date: 2021-03-18_02-55-03
  done: false
  experiment_id: 75234e70c18246efa1051e22e36698f2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9544
  time_since_restore: 323.42915964126587
  time_this_iter_s: 323.42915964126587
  time_total_s: 323.42915964126587
  timestamp: 1616032503
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00164
  
[2m[36m(pid=9544)[0m Finished run with seed 0 - lr 0.1 - sec_lr 5 - bs 512 - mean val auc: 0.9114290952682496
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 169/180 (1 PENDING, 26 RUNNING, 142 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00168 | PENDING    |       |          256 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 149 more trials not shown (16 RUNNING, 132 TERMINATED)


Result for _inner_e98d6_00164:
  auc: 0.9114290952682496
  date: 2021-03-18_02-55-03
  done: true
  experiment_id: 75234e70c18246efa1051e22e36698f2
  experiment_tag: 164_batch_size=512,eta=0.0,lr=0.1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 9544
  time_since_restore: 323.42915964126587
  time_this_iter_s: 323.42915964126587
  time_total_s: 323.42915964126587
  timestamp: 1616032503
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00164
  
[2m[36m(pid=23151)[0m Starting run with seed 0 - lr 1 - sec_lr 5 - bs 256
[2m[36m(pid=23151)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=23151)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=23151)[0m GPU available: False, used: False
[2m[36m(pid=23151)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23151)[0m 
[2m[36m(pid=23151)[0m   | Name      | Type              | Params
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23151)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23151)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 12.0 K    Trainable params
[2m[36m(pid=23151)[0m 0         Non-trainable params
[2m[36m(pid=23151)[0m 12.0 K    Total params
[2m[36m(pid=23151)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23151)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23151)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=23151)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23151)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=23151)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=14655)[0m time to fit was 226.21634030342102
[2m[36m(pid=14655)[0m GPU available: False, used: False
[2m[36m(pid=14655)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14655)[0m 
[2m[36m(pid=14655)[0m   | Name      | Type              | Params
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14655)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14655)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 12.0 K    Trainable params
[2m[36m(pid=14655)[0m 0         Non-trainable params
[2m[36m(pid=14655)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m time to fit was 122.69167613983154
[2m[36m(pid=43955)[0m GPU available: False, used: False
[2m[36m(pid=43955)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43955)[0m 
[2m[36m(pid=43955)[0m   | Name      | Type              | Params
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43955)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43955)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43955)[0m ------------------------------------------------
[2m[36m(pid=43955)[0m 12.0 K    Trainable params
[2m[36m(pid=43955)[0m 0         Non-trainable params
[2m[36m(pid=43955)[0m 12.0 K    Total params
[2m[36m(pid=43993)[0m time to fit was 434.0372214317322
[2m[36m(pid=43993)[0m GPU available: False, used: False
[2m[36m(pid=43993)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43993)[0m 
[2m[36m(pid=43993)[0m   | Name      | Type              | Params
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43993)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43993)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 12.0 K    Trainable params
[2m[36m(pid=43993)[0m 0         Non-trainable params
[2m[36m(pid=43993)[0m 12.0 K    Total params
[2m[36m(pid=43402)[0m time to fit was 468.04895067214966
Result for _inner_e98d6_00140:
  auc: 0.655118989944458
  date: 2021-03-18_02-56-21
  done: false
  experiment_id: aef19e8b27bb4e19aa1fff0c10324a38
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43402
  time_since_restore: 2258.7785544395447
  time_this_iter_s: 2258.7785544395447
  time_total_s: 2258.7785544395447
  timestamp: 1616032581
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00140
  
[2m[36m(pid=43402)[0m Finished run with seed 0 - lr 2 - sec_lr 2 - bs 32 - mean val auc: 0.655118989944458
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 170/180 (1 PENDING, 26 RUNNING, 143 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    |       |          256 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00169 | PENDING    |       |          512 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 150 more trials not shown (16 RUNNING, 133 TERMINATED)


Result for _inner_e98d6_00140:
  auc: 0.655118989944458
  date: 2021-03-18_02-56-21
  done: true
  experiment_id: aef19e8b27bb4e19aa1fff0c10324a38
  experiment_tag: 140_batch_size=32,eta=0.0,lr=2,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43402
  time_since_restore: 2258.7785544395447
  time_this_iter_s: 2258.7785544395447
  time_total_s: 2258.7785544395447
  timestamp: 1616032581
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00140
  
[2m[36m(pid=26107)[0m Starting run with seed 0 - lr 1 - sec_lr 5 - bs 512
[2m[36m(pid=26107)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26107)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=26107)[0m GPU available: False, used: False
[2m[36m(pid=26107)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26107)[0m 
[2m[36m(pid=26107)[0m   | Name      | Type              | Params
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26107)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26107)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 12.0 K    Trainable params
[2m[36m(pid=26107)[0m 0         Non-trainable params
[2m[36m(pid=26107)[0m 12.0 K    Total params
[2m[36m(pid=26107)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26107)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26107)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=26107)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26107)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=26107)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=23151)[0m time to fit was 85.63609409332275
[2m[36m(pid=23151)[0m GPU available: False, used: False
[2m[36m(pid=23151)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23151)[0m 
[2m[36m(pid=23151)[0m   | Name      | Type              | Params
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23151)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23151)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 12.0 K    Trainable params
[2m[36m(pid=23151)[0m 0         Non-trainable params
[2m[36m(pid=23151)[0m 12.0 K    Total params
[2m[36m(pid=21741)[0m time to fit was 2397.460370540619
Result for _inner_e98d6_00003:
  auc: 0.9100253820419312
  date: 2021-03-18_02-57-15
  done: false
  experiment_id: 89759172aae541e2887631a401d03429
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21741
  time_since_restore: 13888.385404348373
  time_this_iter_s: 13888.385404348373
  time_total_s: 13888.385404348373
  timestamp: 1616032635
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00003
  
[2m[36m(pid=21741)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 256 - mean val auc: 0.9100253820419312
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 171/180 (1 PENDING, 26 RUNNING, 144 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00003 | RUNNING    | 145.101.32.82:21741 |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |                     |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |                     |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00170 | PENDING    |                     |           32 |     0 | 2     |    5     |        |                  |          |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 151 more trials not shown (16 RUNNING, 134 TERMINATED)


Result for _inner_e98d6_00003:
  auc: 0.9100253820419312
  date: 2021-03-18_02-57-15
  done: true
  experiment_id: 89759172aae541e2887631a401d03429
  experiment_tag: 3_batch_size=256,eta=0.0,lr=0.001,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21741
  time_since_restore: 13888.385404348373
  time_this_iter_s: 13888.385404348373
  time_total_s: 13888.385404348373
  timestamp: 1616032635
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00003
  
[2m[36m(pid=41807)[0m time to fit was 306.5641596317291
Result for _inner_e98d6_00157:
  auc: 0.9064816474914551
  date: 2021-03-18_02-57-19
  done: false
  experiment_id: 98e48be4917a48ba98e41ce080b1b67f
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41807
  time_since_restore: 1008.8843660354614
  time_this_iter_s: 1008.8843660354614
  time_total_s: 1008.8843660354614
  timestamp: 1616032639
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00157
  
[2m[36m(pid=41807)[0m Finished run with seed 0 - lr 0.01 - sec_lr 5 - bs 128 - mean val auc: 0.9064816474914551
Result for _inner_e98d6_00157:
  auc: 0.9064816474914551
  date: 2021-03-18_02-57-19
  done: true
  experiment_id: 98e48be4917a48ba98e41ce080b1b67f
  experiment_tag: 157_batch_size=128,eta=0.0,lr=0.01,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 41807
  time_since_restore: 1008.8843660354614
  time_this_iter_s: 1008.8843660354614
  time_total_s: 1008.8843660354614
  timestamp: 1616032639
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00157
  
[2m[36m(pid=28170)[0m Starting run with seed 0 - lr 2 - sec_lr 5 - bs 32
[2m[36m(pid=28170)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28170)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=28170)[0m GPU available: False, used: False
[2m[36m(pid=28170)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28170)[0m 
[2m[36m(pid=28170)[0m   | Name      | Type              | Params
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28170)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28170)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 12.0 K    Trainable params
[2m[36m(pid=28170)[0m 0         Non-trainable params
[2m[36m(pid=28170)[0m 12.0 K    Total params
[2m[36m(pid=28170)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28170)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28170)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28170)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28170)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=28170)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22202)[0m time to fit was 156.1917428970337
[2m[36m(pid=22202)[0m GPU available: False, used: False
[2m[36m(pid=22202)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22202)[0m 
[2m[36m(pid=22202)[0m   | Name      | Type              | Params
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22202)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22202)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 12.0 K    Trainable params
[2m[36m(pid=22202)[0m 0         Non-trainable params
[2m[36m(pid=22202)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m Starting run with seed 0 - lr 2 - sec_lr 5 - bs 64
[2m[36m(pid=28364)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28364)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=28364)[0m GPU available: False, used: False
[2m[36m(pid=28364)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28364)[0m 
[2m[36m(pid=28364)[0m   | Name      | Type              | Params
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28364)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28364)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 12.0 K    Trainable params
[2m[36m(pid=28364)[0m 0         Non-trainable params
[2m[36m(pid=28364)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28364)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=11525)[0m time to fit was 422.68623542785645
[2m[36m(pid=11525)[0m GPU available: False, used: False
[2m[36m(pid=11525)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11525)[0m 
[2m[36m(pid=11525)[0m   | Name      | Type              | Params
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11525)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11525)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 12.0 K    Trainable params
[2m[36m(pid=11525)[0m 0         Non-trainable params
[2m[36m(pid=11525)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=28364)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=28364)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=28364)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=6614)[0m time to fit was 1093.8994817733765
[2m[36m(pid=6614)[0m GPU available: False, used: False
[2m[36m(pid=6614)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6614)[0m 
[2m[36m(pid=6614)[0m   | Name      | Type              | Params
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6614)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6614)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 12.0 K    Trainable params
[2m[36m(pid=6614)[0m 0         Non-trainable params
[2m[36m(pid=6614)[0m 12.0 K    Total params
[2m[36m(pid=43955)[0m time to fit was 124.72488760948181
[2m[36m(pid=43955)[0m Finished run with seed 0 - lr 0.1 - sec_lr 5 - bs 128 - mean val auc: 0.9104317903518677
Result for _inner_e98d6_00162:
  auc: 0.9104317903518677
  date: 2021-03-18_02-57-41
  done: false
  experiment_id: 5638dff865ca4c08bd9ef0c465881bd1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43955
  time_since_restore: 648.3271987438202
  time_this_iter_s: 648.3271987438202
  time_total_s: 648.3271987438202
  timestamp: 1616032661
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00162
  
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 173/180 (1 PENDING, 26 RUNNING, 146 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00172 | PENDING    |       |          128 |     0 | 2     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 153 more trials not shown (16 RUNNING, 136 TERMINATED)


Result for _inner_e98d6_00162:
  auc: 0.9104317903518677
  date: 2021-03-18_02-57-41
  done: true
  experiment_id: 5638dff865ca4c08bd9ef0c465881bd1
  experiment_tag: 162_batch_size=128,eta=0.0,lr=0.1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43955
  time_since_restore: 648.3271987438202
  time_this_iter_s: 648.3271987438202
  time_total_s: 648.3271987438202
  timestamp: 1616032661
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00162
  
[2m[36m(pid=29219)[0m Starting run with seed 0 - lr 2 - sec_lr 5 - bs 128
[2m[36m(pid=29219)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29219)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=29219)[0m GPU available: False, used: False
[2m[36m(pid=29219)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29219)[0m 
[2m[36m(pid=29219)[0m   | Name      | Type              | Params
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29219)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29219)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 12.0 K    Trainable params
[2m[36m(pid=29219)[0m 0         Non-trainable params
[2m[36m(pid=29219)[0m 12.0 K    Total params
[2m[36m(pid=29219)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=29219)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29219)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=29219)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29219)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=29219)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=26107)[0m time to fit was 83.77842259407043
[2m[36m(pid=26107)[0m GPU available: False, used: False
[2m[36m(pid=26107)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26107)[0m 
[2m[36m(pid=26107)[0m   | Name      | Type              | Params
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26107)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26107)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 12.0 K    Trainable params
[2m[36m(pid=26107)[0m 0         Non-trainable params
[2m[36m(pid=26107)[0m 12.0 K    Total params
[2m[36m(pid=23151)[0m time to fit was 83.9804151058197
[2m[36m(pid=23151)[0m GPU available: False, used: False
[2m[36m(pid=23151)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23151)[0m 
[2m[36m(pid=23151)[0m   | Name      | Type              | Params
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23151)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23151)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 12.0 K    Trainable params
[2m[36m(pid=23151)[0m 0         Non-trainable params
[2m[36m(pid=23151)[0m 12.0 K    Total params
[2m[36m(pid=36606)[0m time to fit was 226.79815816879272
Result for _inner_e98d6_00156:
  auc: 0.9040600061416626
  date: 2021-03-18_02-58-11
  done: false
  experiment_id: f7116436299e4fb7b5fd9ac5d649a2a6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36606
  time_since_restore: 1205.9498624801636
  time_this_iter_s: 1205.9498624801636
  time_total_s: 1205.9498624801636
  timestamp: 1616032691
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00156
  
[2m[36m(pid=36606)[0m Finished run with seed 0 - lr 0.01 - sec_lr 5 - bs 64 - mean val auc: 0.9040600061416626
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 174/180 (1 PENDING, 26 RUNNING, 147 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00173 | PENDING    |       |          256 |     0 | 2     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 154 more trials not shown (16 RUNNING, 137 TERMINATED)


Result for _inner_e98d6_00156:
  auc: 0.9040600061416626
  date: 2021-03-18_02-58-11
  done: true
  experiment_id: f7116436299e4fb7b5fd9ac5d649a2a6
  experiment_tag: 156_batch_size=64,eta=0.0,lr=0.01,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 36606
  time_since_restore: 1205.9498624801636
  time_this_iter_s: 1205.9498624801636
  time_total_s: 1205.9498624801636
  timestamp: 1616032691
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00156
  
[2m[36m(pid=43951)[0m time to fit was 389.4017548561096
Result for _inner_e98d6_00159:
  auc: 0.9064279913902282
  date: 2021-03-18_02-58-14
  done: false
  experiment_id: ea60c47e1e804c04a12d42a27d8da517
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43951
  time_since_restore: 1000.8239476680756
  time_this_iter_s: 1000.8239476680756
  time_total_s: 1000.8239476680756
  timestamp: 1616032694
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00159
  
[2m[36m(pid=43951)[0m Finished run with seed 0 - lr 0.01 - sec_lr 5 - bs 512 - mean val auc: 0.9064279913902282
Result for _inner_e98d6_00159:
  auc: 0.9064279913902282
  date: 2021-03-18_02-58-14
  done: true
  experiment_id: ea60c47e1e804c04a12d42a27d8da517
  experiment_tag: 159_batch_size=512,eta=0.0,lr=0.01,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43951
  time_since_restore: 1000.8239476680756
  time_this_iter_s: 1000.8239476680756
  time_total_s: 1000.8239476680756
  timestamp: 1616032694
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00159
  
[2m[36m(pid=30384)[0m Starting run with seed 0 - lr 2 - sec_lr 5 - bs 256
[2m[36m(pid=30384)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30384)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30384)[0m GPU available: False, used: False
[2m[36m(pid=30384)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30384)[0m 
[2m[36m(pid=30384)[0m   | Name      | Type              | Params
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30384)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30384)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 12.0 K    Trainable params
[2m[36m(pid=30384)[0m 0         Non-trainable params
[2m[36m(pid=30384)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30384)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30384)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30384)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30384)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30384)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30473)[0m Starting run with seed 0 - lr 2 - sec_lr 5 - bs 512
[2m[36m(pid=30473)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30473)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30473)[0m GPU available: False, used: False
[2m[36m(pid=30473)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30473)[0m 
[2m[36m(pid=30473)[0m   | Name      | Type              | Params
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30473)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30473)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 12.0 K    Trainable params
[2m[36m(pid=30473)[0m 0         Non-trainable params
[2m[36m(pid=30473)[0m 12.0 K    Total params
[2m[36m(pid=30473)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30473)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30473)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30473)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30473)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30473)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43957)[0m time to fit was 268.93717312812805
[2m[36m(pid=43957)[0m GPU available: False, used: False
[2m[36m(pid=43957)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43957)[0m 
[2m[36m(pid=43957)[0m   | Name      | Type              | Params
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43957)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43957)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43957)[0m ------------------------------------------------
[2m[36m(pid=43957)[0m 12.0 K    Trainable params
[2m[36m(pid=43957)[0m 0         Non-trainable params
[2m[36m(pid=43957)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m time to fit was 224.6598560810089
[2m[36m(pid=14655)[0m GPU available: False, used: False
[2m[36m(pid=14655)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14655)[0m 
[2m[36m(pid=14655)[0m   | Name      | Type              | Params
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14655)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14655)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 12.0 K    Trainable params
[2m[36m(pid=14655)[0m 0         Non-trainable params
[2m[36m(pid=14655)[0m 12.0 K    Total params
[2m[36m(pid=26107)[0m time to fit was 80.58311247825623
[2m[36m(pid=26107)[0m GPU available: False, used: False
[2m[36m(pid=26107)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26107)[0m 
[2m[36m(pid=26107)[0m   | Name      | Type              | Params
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26107)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26107)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 12.0 K    Trainable params
[2m[36m(pid=26107)[0m 0         Non-trainable params
[2m[36m(pid=26107)[0m 12.0 K    Total params
[2m[36m(pid=23151)[0m time to fit was 78.25136637687683
[2m[36m(pid=23151)[0m GPU available: False, used: False
[2m[36m(pid=23151)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23151)[0m 
[2m[36m(pid=23151)[0m   | Name      | Type              | Params
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23151)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23151)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 12.0 K    Trainable params
[2m[36m(pid=23151)[0m 0         Non-trainable params
[2m[36m(pid=23151)[0m 12.0 K    Total params
[2m[36m(pid=22202)[0m time to fit was 123.14320111274719
[2m[36m(pid=22202)[0m GPU available: False, used: False
[2m[36m(pid=22202)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22202)[0m 
[2m[36m(pid=22202)[0m   | Name      | Type              | Params
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22202)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22202)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 12.0 K    Trainable params
[2m[36m(pid=22202)[0m 0         Non-trainable params
[2m[36m(pid=22202)[0m 12.0 K    Total params
[2m[36m(pid=30473)[0m time to fit was 76.04066896438599
[2m[36m(pid=30473)[0m GPU available: False, used: False
[2m[36m(pid=30473)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30473)[0m 
[2m[36m(pid=30473)[0m   | Name      | Type              | Params
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30473)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30473)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 12.0 K    Trainable params
[2m[36m(pid=30473)[0m 0         Non-trainable params
[2m[36m(pid=30473)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m time to fit was 85.46815466880798
[2m[36m(pid=30384)[0m GPU available: False, used: False
[2m[36m(pid=30384)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30384)[0m 
[2m[36m(pid=30384)[0m   | Name      | Type              | Params
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30384)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30384)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 12.0 K    Trainable params
[2m[36m(pid=30384)[0m 0         Non-trainable params
[2m[36m(pid=30384)[0m 12.0 K    Total params
[2m[36m(pid=29219)[0m time to fit was 125.0572075843811
[2m[36m(pid=29219)[0m GPU available: False, used: False
[2m[36m(pid=29219)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29219)[0m 
[2m[36m(pid=29219)[0m   | Name      | Type              | Params
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29219)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29219)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 12.0 K    Trainable params
[2m[36m(pid=29219)[0m 0         Non-trainable params
[2m[36m(pid=29219)[0m 12.0 K    Total params
[2m[36m(pid=20347)[0m time to fit was 435.44631266593933
[2m[36m(pid=20347)[0m GPU available: False, used: False
[2m[36m(pid=20347)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=20347)[0m 
[2m[36m(pid=20347)[0m   | Name      | Type              | Params
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=20347)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=20347)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=20347)[0m ------------------------------------------------
[2m[36m(pid=20347)[0m 12.0 K    Trainable params
[2m[36m(pid=20347)[0m 0         Non-trainable params
[2m[36m(pid=20347)[0m 12.0 K    Total params
[2m[36m(pid=26107)[0m time to fit was 60.41737985610962
[2m[36m(pid=26107)[0m GPU available: False, used: False
[2m[36m(pid=26107)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26107)[0m 
[2m[36m(pid=26107)[0m   | Name      | Type              | Params
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26107)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26107)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 12.0 K    Trainable params
[2m[36m(pid=26107)[0m 0         Non-trainable params
[2m[36m(pid=26107)[0m 12.0 K    Total params
[2m[36m(pid=23151)[0m time to fit was 71.47146344184875
[2m[36m(pid=23151)[0m GPU available: False, used: False
[2m[36m(pid=23151)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=23151)[0m 
[2m[36m(pid=23151)[0m   | Name      | Type              | Params
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=23151)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=23151)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=23151)[0m ------------------------------------------------
[2m[36m(pid=23151)[0m 12.0 K    Trainable params
[2m[36m(pid=23151)[0m 0         Non-trainable params
[2m[36m(pid=23151)[0m 12.0 K    Total params
[2m[36m(pid=49412)[0m time to fit was 515.4563736915588
[2m[36m(pid=49412)[0m GPU available: False, used: False
[2m[36m(pid=49412)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=49412)[0m 
[2m[36m(pid=49412)[0m   | Name      | Type              | Params
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=49412)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=49412)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 12.0 K    Trainable params
[2m[36m(pid=49412)[0m 0         Non-trainable params
[2m[36m(pid=49412)[0m 12.0 K    Total params
[2m[36m(pid=21729)[0m time to fit was 6219.621476888657
[2m[36m(pid=21729)[0m GPU available: False, used: False
[2m[36m(pid=21729)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21729)[0m 
[2m[36m(pid=21729)[0m   | Name      | Type              | Params
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21729)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21729)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 12.0 K    Trainable params
[2m[36m(pid=21729)[0m 0         Non-trainable params
[2m[36m(pid=21729)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m time to fit was 507.3068506717682
[2m[36m(pid=35505)[0m GPU available: False, used: False
[2m[36m(pid=35505)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35505)[0m 
[2m[36m(pid=35505)[0m   | Name      | Type              | Params
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35505)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35505)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 12.0 K    Trainable params
[2m[36m(pid=35505)[0m 0         Non-trainable params
[2m[36m(pid=35505)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m time to fit was 79.3291871547699
[2m[36m(pid=30384)[0m GPU available: False, used: False
[2m[36m(pid=30384)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30384)[0m 
[2m[36m(pid=30384)[0m   | Name      | Type              | Params
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30384)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30384)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 12.0 K    Trainable params
[2m[36m(pid=30384)[0m 0         Non-trainable params
[2m[36m(pid=30384)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m time to fit was 226.99629521369934
[2m[36m(pid=28364)[0m GPU available: False, used: False
[2m[36m(pid=28364)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28364)[0m 
[2m[36m(pid=28364)[0m   | Name      | Type              | Params
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28364)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28364)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 12.0 K    Trainable params
[2m[36m(pid=28364)[0m 0         Non-trainable params
[2m[36m(pid=28364)[0m 12.0 K    Total params
[2m[36m(pid=26107)[0m time to fit was 60.556562662124634
[2m[36m(pid=26107)[0m GPU available: False, used: False
[2m[36m(pid=26107)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=26107)[0m 
[2m[36m(pid=26107)[0m   | Name      | Type              | Params
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=26107)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=26107)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=26107)[0m ------------------------------------------------
[2m[36m(pid=26107)[0m 12.0 K    Trainable params
[2m[36m(pid=26107)[0m 0         Non-trainable params
[2m[36m(pid=26107)[0m 12.0 K    Total params
[2m[36m(pid=30473)[0m time to fit was 100.2237639427185
[2m[36m(pid=30473)[0m GPU available: False, used: False
[2m[36m(pid=30473)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30473)[0m 
[2m[36m(pid=30473)[0m   | Name      | Type              | Params
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30473)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30473)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 12.0 K    Trainable params
[2m[36m(pid=30473)[0m 0         Non-trainable params
[2m[36m(pid=30473)[0m 12.0 K    Total params
[2m[36m(pid=22202)[0m time to fit was 124.48536562919617
[2m[36m(pid=22202)[0m GPU available: False, used: False
[2m[36m(pid=22202)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22202)[0m 
[2m[36m(pid=22202)[0m   | Name      | Type              | Params
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22202)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22202)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 12.0 K    Trainable params
[2m[36m(pid=22202)[0m 0         Non-trainable params
[2m[36m(pid=22202)[0m 12.0 K    Total params
[2m[36m(pid=26107)[0m time to fit was 63.71327781677246
Result for _inner_e98d6_00169:
  auc: 0.9107329368591308
  date: 2021-03-18_03-02-24
  done: false
  experiment_id: 5c75a8fd4d294fbdb1c9751085120fc9
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26107
  time_since_restore: 350.399747133255
  time_this_iter_s: 350.399747133255
  time_total_s: 350.399747133255
  timestamp: 1616032944
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00169
  
[2m[36m(pid=26107)[0m Finished run with seed 0 - lr 1 - sec_lr 5 - bs 512 - mean val auc: 0.9107329368591308
== Status ==
Memory usage on this node: 11.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 176/180 (1 PENDING, 26 RUNNING, 149 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00175 | PENDING    |       |           32 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 156 more trials not shown (16 RUNNING, 139 TERMINATED)


Result for _inner_e98d6_00169:
  auc: 0.9107329368591308
  date: 2021-03-18_03-02-24
  done: true
  experiment_id: 5c75a8fd4d294fbdb1c9751085120fc9
  experiment_tag: 169_batch_size=512,eta=0.0,lr=1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 26107
  time_since_restore: 350.399747133255
  time_this_iter_s: 350.399747133255
  time_total_s: 350.399747133255
  timestamp: 1616032944
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00169
  
[2m[36m(pid=29219)[0m time to fit was 147.79605770111084
[2m[36m(pid=29219)[0m GPU available: False, used: False
[2m[36m(pid=29219)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29219)[0m 
[2m[36m(pid=29219)[0m   | Name      | Type              | Params
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29219)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29219)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 12.0 K    Trainable params
[2m[36m(pid=29219)[0m 0         Non-trainable params
[2m[36m(pid=29219)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m time to fit was 79.15365052223206
[2m[36m(pid=30384)[0m GPU available: False, used: False
[2m[36m(pid=30384)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30384)[0m 
[2m[36m(pid=30384)[0m   | Name      | Type              | Params
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30384)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30384)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 12.0 K    Trainable params
[2m[36m(pid=30384)[0m 0         Non-trainable params
[2m[36m(pid=30384)[0m 12.0 K    Total params
[2m[36m(pid=30480)[0m Starting run with seed 0 - lr 5 - sec_lr 5 - bs 32
[2m[36m(pid=30480)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30480)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30480)[0m GPU available: False, used: False
[2m[36m(pid=30480)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30480)[0m 
[2m[36m(pid=30480)[0m   | Name      | Type              | Params
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30480)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30480)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 12.0 K    Trainable params
[2m[36m(pid=30480)[0m 0         Non-trainable params
[2m[36m(pid=30480)[0m 12.0 K    Total params
[2m[36m(pid=30480)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30480)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30480)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30480)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30480)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30480)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=49412)[0m time to fit was 122.04569792747498
[2m[36m(pid=49412)[0m GPU available: False, used: False
[2m[36m(pid=49412)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=49412)[0m 
[2m[36m(pid=49412)[0m   | Name      | Type              | Params
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=49412)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=49412)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=49412)[0m ------------------------------------------------
[2m[36m(pid=49412)[0m 12.0 K    Trainable params
[2m[36m(pid=49412)[0m 0         Non-trainable params
[2m[36m(pid=49412)[0m 12.0 K    Total params
[2m[36m(pid=23151)[0m time to fit was 133.04263138771057
Result for _inner_e98d6_00168:
  auc: 0.9096602678298951
  date: 2021-03-18_03-02-48
  done: false
  experiment_id: 8a610f3464204960ab83be63075c6d68
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23151
  time_since_restore: 453.82704973220825
  time_this_iter_s: 453.82704973220825
  time_total_s: 453.82704973220825
  timestamp: 1616032968
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00168
  
[2m[36m(pid=23151)[0m Finished run with seed 0 - lr 1 - sec_lr 5 - bs 256 - mean val auc: 0.9096602678298951
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 177/180 (1 PENDING, 26 RUNNING, 150 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00176 | PENDING    |       |           64 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 157 more trials not shown (16 RUNNING, 140 TERMINATED)


Result for _inner_e98d6_00168:
  auc: 0.9096602678298951
  date: 2021-03-18_03-02-48
  done: true
  experiment_id: 8a610f3464204960ab83be63075c6d68
  experiment_tag: 168_batch_size=256,eta=0.0,lr=1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 23151
  time_since_restore: 453.82704973220825
  time_this_iter_s: 453.82704973220825
  time_total_s: 453.82704973220825
  timestamp: 1616032968
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00168
  
[2m[36m(pid=30458)[0m Starting run with seed 0 - lr 5 - sec_lr 5 - bs 64
[2m[36m(pid=30458)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30458)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30458)[0m GPU available: False, used: False
[2m[36m(pid=30458)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30458)[0m 
[2m[36m(pid=30458)[0m   | Name      | Type              | Params
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30458)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30458)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 12.0 K    Trainable params
[2m[36m(pid=30458)[0m 0         Non-trainable params
[2m[36m(pid=30458)[0m 12.0 K    Total params
[2m[36m(pid=30458)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30458)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30458)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30458)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30458)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30458)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=43957)[0m time to fit was 250.85929083824158
[2m[36m(pid=43957)[0m Finished run with seed 0 - lr 0.1 - sec_lr 5 - bs 64 - mean val auc: 0.8245850026607513
Result for _inner_e98d6_00161:
  auc: 0.8245850026607513
  date: 2021-03-18_03-03-09
  done: false
  experiment_id: 4032b36fd1d842f4ab71d9062e343833
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43957
  time_since_restore: 1190.7156257629395
  time_this_iter_s: 1190.7156257629395
  time_total_s: 1190.7156257629395
  timestamp: 1616032989
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00161
  
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 178/180 (1 PENDING, 26 RUNNING, 151 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00177 | PENDING    |       |          128 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 158 more trials not shown (16 RUNNING, 141 TERMINATED)


Result for _inner_e98d6_00161:
  auc: 0.8245850026607513
  date: 2021-03-18_03-03-09
  done: true
  experiment_id: 4032b36fd1d842f4ab71d9062e343833
  experiment_tag: 161_batch_size=64,eta=0.0,lr=0.1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43957
  time_since_restore: 1190.7156257629395
  time_this_iter_s: 1190.7156257629395
  time_total_s: 1190.7156257629395
  timestamp: 1616032989
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00161
  
[2m[36m(pid=43993)[0m time to fit was 429.3823666572571
[2m[36m(pid=43993)[0m GPU available: False, used: False
[2m[36m(pid=43993)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43993)[0m 
[2m[36m(pid=43993)[0m   | Name      | Type              | Params
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43993)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43993)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 12.0 K    Trainable params
[2m[36m(pid=43993)[0m 0         Non-trainable params
[2m[36m(pid=43993)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m Starting run with seed 0 - lr 5 - sec_lr 5 - bs 128
[2m[36m(pid=30497)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30497)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30497)[0m GPU available: False, used: False
[2m[36m(pid=30497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30497)[0m 
[2m[36m(pid=30497)[0m   | Name      | Type              | Params
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 12.0 K    Trainable params
[2m[36m(pid=30497)[0m 0         Non-trainable params
[2m[36m(pid=30497)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30497)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30497)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30473)[0m time to fit was 118.09525752067566
[2m[36m(pid=30473)[0m GPU available: False, used: False
[2m[36m(pid=30473)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30473)[0m 
[2m[36m(pid=30473)[0m   | Name      | Type              | Params
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30473)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30473)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 12.0 K    Trainable params
[2m[36m(pid=30473)[0m 0         Non-trainable params
[2m[36m(pid=30473)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m time to fit was 85.71552419662476
[2m[36m(pid=30384)[0m GPU available: False, used: False
[2m[36m(pid=30384)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30384)[0m 
[2m[36m(pid=30384)[0m   | Name      | Type              | Params
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30384)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30384)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30384)[0m ------------------------------------------------
[2m[36m(pid=30384)[0m 12.0 K    Trainable params
[2m[36m(pid=30384)[0m 0         Non-trainable params
[2m[36m(pid=30384)[0m 12.0 K    Total params
[2m[36m(pid=22202)[0m time to fit was 144.06318855285645
[2m[36m(pid=22202)[0m GPU available: False, used: False
[2m[36m(pid=22202)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=22202)[0m 
[2m[36m(pid=22202)[0m   | Name      | Type              | Params
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=22202)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=22202)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=22202)[0m ------------------------------------------------
[2m[36m(pid=22202)[0m 12.0 K    Trainable params
[2m[36m(pid=22202)[0m 0         Non-trainable params
[2m[36m(pid=22202)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m time to fit was 290.0476145744324
[2m[36m(pid=14655)[0m GPU available: False, used: False
[2m[36m(pid=14655)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14655)[0m 
[2m[36m(pid=14655)[0m   | Name      | Type              | Params
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14655)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14655)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 12.0 K    Trainable params
[2m[36m(pid=14655)[0m 0         Non-trainable params
[2m[36m(pid=14655)[0m 12.0 K    Total params
[2m[36m(pid=30473)[0m time to fit was 59.061585664749146
[2m[36m(pid=30473)[0m GPU available: False, used: False
[2m[36m(pid=30473)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30473)[0m 
[2m[36m(pid=30473)[0m   | Name      | Type              | Params
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30473)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30473)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30473)[0m ------------------------------------------------
[2m[36m(pid=30473)[0m 12.0 K    Trainable params
[2m[36m(pid=30473)[0m 0         Non-trainable params
[2m[36m(pid=30473)[0m 12.0 K    Total params
[2m[36m(pid=11525)[0m time to fit was 425.6475110054016
[2m[36m(pid=11525)[0m GPU available: False, used: False
[2m[36m(pid=11525)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11525)[0m 
[2m[36m(pid=11525)[0m   | Name      | Type              | Params
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11525)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11525)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 12.0 K    Trainable params
[2m[36m(pid=11525)[0m 0         Non-trainable params
[2m[36m(pid=11525)[0m 12.0 K    Total params
[2m[36m(pid=6614)[0m time to fit was 426.5209586620331
[2m[36m(pid=6614)[0m GPU available: False, used: False
[2m[36m(pid=6614)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=6614)[0m 
[2m[36m(pid=6614)[0m   | Name      | Type              | Params
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=6614)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=6614)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=6614)[0m ------------------------------------------------
[2m[36m(pid=6614)[0m 12.0 K    Trainable params
[2m[36m(pid=6614)[0m 0         Non-trainable params
[2m[36m(pid=6614)[0m 12.0 K    Total params
[2m[36m(pid=21667)[0m time to fit was 2010.0218393802643
[2m[36m(pid=21667)[0m GPU available: False, used: False
[2m[36m(pid=21667)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21667)[0m 
[2m[36m(pid=21667)[0m   | Name      | Type              | Params
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21667)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21667)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21667)[0m ------------------------------------------------
[2m[36m(pid=21667)[0m 12.0 K    Trainable params
[2m[36m(pid=21667)[0m 0         Non-trainable params
[2m[36m(pid=21667)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m time to fit was 223.17100262641907
[2m[36m(pid=28364)[0m GPU available: False, used: False
[2m[36m(pid=28364)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28364)[0m 
[2m[36m(pid=28364)[0m   | Name      | Type              | Params
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28364)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28364)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 12.0 K    Trainable params
[2m[36m(pid=28364)[0m 0         Non-trainable params
[2m[36m(pid=28364)[0m 12.0 K    Total params
[2m[36m(pid=30384)[0m time to fit was 79.9558162689209
Result for _inner_e98d6_00173:
  auc: 0.8967680335044861
  date: 2021-03-18_03-05-13
  done: false
  experiment_id: 7479d37f40f24963baed1e3774bdefae
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30384
  time_since_restore: 411.0087049007416
  time_this_iter_s: 411.0087049007416
  time_total_s: 411.0087049007416
  timestamp: 1616033113
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00173
  
[2m[36m(pid=30384)[0m Finished run with seed 0 - lr 2 - sec_lr 5 - bs 256 - mean val auc: 0.8967680335044861
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 179/180 (1 PENDING, 26 RUNNING, 152 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00178 | PENDING    |       |          256 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 159 more trials not shown (16 RUNNING, 142 TERMINATED)


Result for _inner_e98d6_00173:
  auc: 0.8967680335044861
  date: 2021-03-18_03-05-13
  done: true
  experiment_id: 7479d37f40f24963baed1e3774bdefae
  experiment_tag: 173_batch_size=256,eta=0.0,lr=2,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30384
  time_since_restore: 411.0087049007416
  time_this_iter_s: 411.0087049007416
  time_total_s: 411.0087049007416
  timestamp: 1616033113
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00173
  
[2m[36m(pid=30469)[0m Starting run with seed 0 - lr 5 - sec_lr 5 - bs 256
[2m[36m(pid=30469)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30469)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=30469)[0m GPU available: False, used: False
[2m[36m(pid=30469)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30469)[0m 
[2m[36m(pid=30469)[0m   | Name      | Type              | Params
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30469)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30469)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 12.0 K    Trainable params
[2m[36m(pid=30469)[0m 0         Non-trainable params
[2m[36m(pid=30469)[0m 12.0 K    Total params
[2m[36m(pid=30469)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30469)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30469)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=30469)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=30469)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=30469)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=29219)[0m time to fit was 189.2020058631897
[2m[36m(pid=29219)[0m GPU available: False, used: False
[2m[36m(pid=29219)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29219)[0m 
[2m[36m(pid=29219)[0m   | Name      | Type              | Params
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29219)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29219)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 12.0 K    Trainable params
[2m[36m(pid=29219)[0m 0         Non-trainable params
[2m[36m(pid=29219)[0m 12.0 K    Total params
[2m[36m(pid=30473)[0m time to fit was 90.27347493171692
Result for _inner_e98d6_00174:
  auc: 0.9049837589263916
  date: 2021-03-18_03-05-49
  done: false
  experiment_id: 4b2c3de98e134d9b9f67fe75aa534842
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30473
  time_since_restore: 445.0056240558624
  time_this_iter_s: 445.0056240558624
  time_total_s: 445.0056240558624
  timestamp: 1616033149
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00174
  
[2m[36m(pid=30473)[0m Finished run with seed 0 - lr 2 - sec_lr 5 - bs 512 - mean val auc: 0.9049837589263916
== Status ==
Memory usage on this node: 11.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (1 PENDING, 26 RUNNING, 153 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00179 | PENDING    |       |          512 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (16 RUNNING, 143 TERMINATED)


Result for _inner_e98d6_00174:
  auc: 0.9049837589263916
  date: 2021-03-18_03-05-49
  done: true
  experiment_id: 4b2c3de98e134d9b9f67fe75aa534842
  experiment_tag: 174_batch_size=512,eta=0.0,lr=2,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30473
  time_since_restore: 445.0056240558624
  time_this_iter_s: 445.0056240558624
  time_total_s: 445.0056240558624
  timestamp: 1616033149
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00174
  
[2m[36m(pid=48093)[0m Starting run with seed 0 - lr 5 - sec_lr 5 - bs 512
[2m[36m(pid=48093)[0m /home/nolte/fact-ai/datasets.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48093)[0m   return self.dataset.memberships[self.indices]
[2m[36m(pid=48093)[0m GPU available: False, used: False
[2m[36m(pid=48093)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=48093)[0m 
[2m[36m(pid=48093)[0m   | Name      | Type              | Params
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=48093)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=48093)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 12.0 K    Trainable params
[2m[36m(pid=48093)[0m 0         Non-trainable params
[2m[36m(pid=48093)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=48093)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=48093)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
[2m[36m(pid=48093)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=48093)[0m /home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
[2m[36m(pid=48093)[0m   warnings.warn(*args, **kwargs)
[2m[36m(pid=22202)[0m time to fit was 120.9279797077179
Result for _inner_e98d6_00167:
  auc: 0.9069636344909668
  date: 2021-03-18_03-06-02
  done: false
  experiment_id: 39458e08f2e74ecd8d97173371be576d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22202
  time_since_restore: 670.2162711620331
  time_this_iter_s: 670.2162711620331
  time_total_s: 670.2162711620331
  timestamp: 1616033162
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00167
  
[2m[36m(pid=22202)[0m Finished run with seed 0 - lr 1 - sec_lr 5 - bs 128 - mean val auc: 0.9069636344909668
== Status ==
Memory usage on this node: 11.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 52/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (26 RUNNING, 154 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    |       |          256 |     0 | 0.001 |    1     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (16 RUNNING, 144 TERMINATED)


Result for _inner_e98d6_00167:
  auc: 0.9069636344909668
  date: 2021-03-18_03-06-02
  done: true
  experiment_id: 39458e08f2e74ecd8d97173371be576d
  experiment_tag: 167_batch_size=128,eta=0.0,lr=1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 22202
  time_since_restore: 670.2162711620331
  time_this_iter_s: 670.2162711620331
  time_total_s: 670.2162711620331
  timestamp: 1616033162
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00167
  
[2m[36m(pid=49412)[0m time to fit was 208.75388407707214
Result for _inner_e98d6_00093:
  auc: 0.8748828887939453
  date: 2021-03-18_03-06-12
  done: false
  experiment_id: d491fccfedd84b398a9b877c98ce6b19
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 49412
  time_since_restore: 6729.651462316513
  time_this_iter_s: 6729.651462316513
  time_total_s: 6729.651462316513
  timestamp: 1616033172
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00093
  
[2m[36m(pid=49412)[0m Finished run with seed 0 - lr 0.001 - sec_lr 1 - bs 256 - mean val auc: 0.8748828887939453
== Status ==
Memory usage on this node: 11.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 50/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (25 RUNNING, 155 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |                     |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |                     |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00093 | RUNNING    | 145.101.32.82:49412 |          256 |     0 | 0.001 |    1     |      1 |          6729.65 | 0.874883 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (15 RUNNING, 145 TERMINATED)


Result for _inner_e98d6_00093:
  auc: 0.8748828887939453
  date: 2021-03-18_03-06-12
  done: true
  experiment_id: d491fccfedd84b398a9b877c98ce6b19
  experiment_tag: 93_batch_size=256,eta=0.0,lr=0.001,sec_lr=1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 49412
  time_since_restore: 6729.651462316513
  time_this_iter_s: 6729.651462316513
  time_total_s: 6729.651462316513
  timestamp: 1616033172
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00093
  
[2m[36m(pid=30469)[0m time to fit was 69.21681642532349
[2m[36m(pid=30469)[0m GPU available: False, used: False
[2m[36m(pid=30469)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30469)[0m 
[2m[36m(pid=30469)[0m   | Name      | Type              | Params
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30469)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30469)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 12.0 K    Trainable params
[2m[36m(pid=30469)[0m 0         Non-trainable params
[2m[36m(pid=30469)[0m 12.0 K    Total params
[2m[36m(pid=30458)[0m time to fit was 220.4575755596161
[2m[36m(pid=30458)[0m GPU available: False, used: False
[2m[36m(pid=30458)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30458)[0m 
[2m[36m(pid=30458)[0m   | Name      | Type              | Params
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30458)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30458)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 12.0 K    Trainable params
[2m[36m(pid=30458)[0m 0         Non-trainable params
[2m[36m(pid=30458)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m time to fit was 44.34929037094116
[2m[36m(pid=48093)[0m GPU available: False, used: False
[2m[36m(pid=48093)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=48093)[0m 
[2m[36m(pid=48093)[0m   | Name      | Type              | Params
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=48093)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=48093)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 12.0 K    Trainable params
[2m[36m(pid=48093)[0m 0         Non-trainable params
[2m[36m(pid=48093)[0m 12.0 K    Total params
[2m[36m(pid=20347)[0m time to fit was 423.00436186790466
Result for _inner_e98d6_00150:
  auc: 0.4986472845077515
  date: 2021-03-18_03-07-01
  done: false
  experiment_id: aed07e7aee81416d9cdbb3555ee6f728
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20347
  time_since_restore: 2136.4350624084473
  time_this_iter_s: 2136.4350624084473
  time_total_s: 2136.4350624084473
  timestamp: 1616033221
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00150
  
[2m[36m(pid=20347)[0m Finished run with seed 0 - lr 0.001 - sec_lr 5 - bs 32 - mean val auc: 0.4986472845077515
== Status ==
Memory usage on this node: 11.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 48/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (24 RUNNING, 156 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (14 RUNNING, 146 TERMINATED)


Result for _inner_e98d6_00150:
  auc: 0.4986472845077515
  date: 2021-03-18_03-07-01
  done: true
  experiment_id: aed07e7aee81416d9cdbb3555ee6f728
  experiment_tag: 150_batch_size=32,eta=0.0,lr=0.001,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 20347
  time_since_restore: 2136.4350624084473
  time_this_iter_s: 2136.4350624084473
  time_total_s: 2136.4350624084473
  timestamp: 1616033221
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00150
  
[2m[36m(pid=28170)[0m time to fit was 607.7721855640411
[2m[36m(pid=28170)[0m GPU available: False, used: False
[2m[36m(pid=28170)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28170)[0m 
[2m[36m(pid=28170)[0m   | Name      | Type              | Params
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28170)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28170)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 12.0 K    Trainable params
[2m[36m(pid=28170)[0m 0         Non-trainable params
[2m[36m(pid=28170)[0m 12.0 K    Total params
[2m[36m(pid=29219)[0m time to fit was 128.16549801826477
[2m[36m(pid=29219)[0m GPU available: False, used: False
[2m[36m(pid=29219)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=29219)[0m 
[2m[36m(pid=29219)[0m   | Name      | Type              | Params
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=29219)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=29219)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=29219)[0m ------------------------------------------------
[2m[36m(pid=29219)[0m 12.0 K    Trainable params
[2m[36m(pid=29219)[0m 0         Non-trainable params
[2m[36m(pid=29219)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m time to fit was 220.0728840827942
[2m[36m(pid=14655)[0m GPU available: False, used: False
[2m[36m(pid=14655)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=14655)[0m 
[2m[36m(pid=14655)[0m   | Name      | Type              | Params
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=14655)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=14655)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=14655)[0m ------------------------------------------------
[2m[36m(pid=14655)[0m 12.0 K    Trainable params
[2m[36m(pid=14655)[0m 0         Non-trainable params
[2m[36m(pid=14655)[0m 12.0 K    Total params
[2m[36m(pid=30469)[0m time to fit was 78.72010588645935
[2m[36m(pid=30469)[0m GPU available: False, used: False
[2m[36m(pid=30469)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30469)[0m 
[2m[36m(pid=30469)[0m   | Name      | Type              | Params
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30469)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30469)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 12.0 K    Trainable params
[2m[36m(pid=30469)[0m 0         Non-trainable params
[2m[36m(pid=30469)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m time to fit was 416.7648708820343
[2m[36m(pid=35505)[0m GPU available: False, used: False
[2m[36m(pid=35505)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35505)[0m 
[2m[36m(pid=35505)[0m   | Name      | Type              | Params
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35505)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35505)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 12.0 K    Trainable params
[2m[36m(pid=35505)[0m 0         Non-trainable params
[2m[36m(pid=35505)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m time to fit was 283.9184401035309
[2m[36m(pid=30497)[0m GPU available: False, used: False
[2m[36m(pid=30497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30497)[0m 
[2m[36m(pid=30497)[0m   | Name      | Type              | Params
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 12.0 K    Trainable params
[2m[36m(pid=30497)[0m 0         Non-trainable params
[2m[36m(pid=30497)[0m 12.0 K    Total params
[2m[36m(pid=21740)[0m time to fit was 7011.930565595627
[2m[36m(pid=21740)[0m GPU available: False, used: False
[2m[36m(pid=21740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m 
[2m[36m(pid=21740)[0m   | Name      | Type              | Params
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 12.0 K    Trainable params
[2m[36m(pid=21740)[0m 0         Non-trainable params
[2m[36m(pid=21740)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m time to fit was 236.54871010780334
[2m[36m(pid=28364)[0m GPU available: False, used: False
[2m[36m(pid=28364)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28364)[0m 
[2m[36m(pid=28364)[0m   | Name      | Type              | Params
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28364)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28364)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 12.0 K    Trainable params
[2m[36m(pid=28364)[0m 0         Non-trainable params
[2m[36m(pid=28364)[0m 12.0 K    Total params
[2m[36m(pid=30480)[0m time to fit was 398.4441878795624
[2m[36m(pid=30480)[0m GPU available: False, used: False
[2m[36m(pid=30480)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30480)[0m 
[2m[36m(pid=30480)[0m   | Name      | Type              | Params
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30480)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30480)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 12.0 K    Trainable params
[2m[36m(pid=30480)[0m 0         Non-trainable params
[2m[36m(pid=30480)[0m 12.0 K    Total params
[2m[36m(pid=29219)[0m time to fit was 113.35231924057007
Result for _inner_e98d6_00172:
  auc: 0.8116187810897827
  date: 2021-03-18_03-09-37
  done: false
  experiment_id: ca0aa1f86b7a4de8a4d2e2a9152ba75d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 29219
  time_since_restore: 704.7575025558472
  time_this_iter_s: 704.7575025558472
  time_total_s: 704.7575025558472
  timestamp: 1616033377
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00172
  
[2m[36m(pid=29219)[0m Finished run with seed 0 - lr 2 - sec_lr 5 - bs 128 - mean val auc: 0.8116187810897827
== Status ==
Memory usage on this node: 11.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 46/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (23 RUNNING, 157 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (13 RUNNING, 147 TERMINATED)


Result for _inner_e98d6_00172:
  auc: 0.8116187810897827
  date: 2021-03-18_03-09-37
  done: true
  experiment_id: ca0aa1f86b7a4de8a4d2e2a9152ba75d
  experiment_tag: 172_batch_size=128,eta=0.0,lr=2,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 29219
  time_since_restore: 704.7575025558472
  time_this_iter_s: 704.7575025558472
  time_total_s: 704.7575025558472
  timestamp: 1616033377
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00172
  
[2m[36m(pid=43993)[0m time to fit was 400.3479108810425
[2m[36m(pid=43993)[0m GPU available: False, used: False
[2m[36m(pid=43993)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=43993)[0m 
[2m[36m(pid=43993)[0m   | Name      | Type              | Params
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=43993)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=43993)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=43993)[0m ------------------------------------------------
[2m[36m(pid=43993)[0m 12.0 K    Trainable params
[2m[36m(pid=43993)[0m 0         Non-trainable params
[2m[36m(pid=43993)[0m 12.0 K    Total params
[2m[36m(pid=30458)[0m time to fit was 223.93901443481445
[2m[36m(pid=30458)[0m GPU available: False, used: False
[2m[36m(pid=30458)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30458)[0m 
[2m[36m(pid=30458)[0m   | Name      | Type              | Params
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30458)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30458)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 12.0 K    Trainable params
[2m[36m(pid=30458)[0m 0         Non-trainable params
[2m[36m(pid=30458)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m time to fit was 142.76877760887146
[2m[36m(pid=30497)[0m GPU available: False, used: False
[2m[36m(pid=30497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30497)[0m 
[2m[36m(pid=30497)[0m   | Name      | Type              | Params
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 12.0 K    Trainable params
[2m[36m(pid=30497)[0m 0         Non-trainable params
[2m[36m(pid=30497)[0m 12.0 K    Total params
[2m[36m(pid=11525)[0m time to fit was 391.0771200656891
[2m[36m(pid=11525)[0m GPU available: False, used: False
[2m[36m(pid=11525)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11525)[0m 
[2m[36m(pid=11525)[0m   | Name      | Type              | Params
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11525)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11525)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 12.0 K    Trainable params
[2m[36m(pid=11525)[0m 0         Non-trainable params
[2m[36m(pid=11525)[0m 12.0 K    Total params
[2m[36m(pid=14655)[0m time to fit was 203.5572555065155
Result for _inner_e98d6_00166:
  auc: 0.9032261490821838
  date: 2021-03-18_03-11-12
  done: false
  experiment_id: 143cbaf5949c4e6fa93bce815e7f551e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14655
  time_since_restore: 1165.914116859436
  time_this_iter_s: 1165.914116859436
  time_total_s: 1165.914116859436
  timestamp: 1616033472
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00166
  
[2m[36m(pid=14655)[0m Finished run with seed 0 - lr 1 - sec_lr 5 - bs 64 - mean val auc: 0.9032261490821838
== Status ==
Memory usage on this node: 10.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 44/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (22 RUNNING, 158 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (12 RUNNING, 148 TERMINATED)


Result for _inner_e98d6_00166:
  auc: 0.9032261490821838
  date: 2021-03-18_03-11-12
  done: true
  experiment_id: 143cbaf5949c4e6fa93bce815e7f551e
  experiment_tag: 166_batch_size=64,eta=0.0,lr=1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 14655
  time_since_restore: 1165.914116859436
  time_this_iter_s: 1165.914116859436
  time_total_s: 1165.914116859436
  timestamp: 1616033472
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00166
  
[2m[36m(pid=30497)[0m time to fit was 107.21250915527344
[2m[36m(pid=30497)[0m GPU available: False, used: False
[2m[36m(pid=30497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30497)[0m 
[2m[36m(pid=30497)[0m   | Name      | Type              | Params
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 12.0 K    Trainable params
[2m[36m(pid=30497)[0m 0         Non-trainable params
[2m[36m(pid=30497)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m time to fit was 330.03527092933655
[2m[36m(pid=48093)[0m GPU available: False, used: False
[2m[36m(pid=48093)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=48093)[0m 
[2m[36m(pid=48093)[0m   | Name      | Type              | Params
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=48093)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=48093)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 12.0 K    Trainable params
[2m[36m(pid=48093)[0m 0         Non-trainable params
[2m[36m(pid=48093)[0m 12.0 K    Total params
[2m[36m(pid=28364)[0m time to fit was 216.91171097755432
[2m[36m(pid=28364)[0m GPU available: False, used: False
[2m[36m(pid=28364)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28364)[0m 
[2m[36m(pid=28364)[0m   | Name      | Type              | Params
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28364)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28364)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28364)[0m ------------------------------------------------
[2m[36m(pid=28364)[0m 12.0 K    Trainable params
[2m[36m(pid=28364)[0m 0         Non-trainable params
[2m[36m(pid=28364)[0m 12.0 K    Total params
[2m[36m(pid=30469)[0m time to fit was 285.91432094573975
[2m[36m(pid=30469)[0m GPU available: False, used: False
[2m[36m(pid=30469)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30469)[0m 
[2m[36m(pid=30469)[0m   | Name      | Type              | Params
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30469)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30469)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 12.0 K    Trainable params
[2m[36m(pid=30469)[0m 0         Non-trainable params
[2m[36m(pid=30469)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m time to fit was 38.5916531085968
[2m[36m(pid=48093)[0m GPU available: False, used: False
[2m[36m(pid=48093)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=48093)[0m 
[2m[36m(pid=48093)[0m   | Name      | Type              | Params
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=48093)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=48093)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 12.0 K    Trainable params
[2m[36m(pid=48093)[0m 0         Non-trainable params
[2m[36m(pid=48093)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m time to fit was 37.24376201629639
[2m[36m(pid=48093)[0m GPU available: False, used: False
[2m[36m(pid=48093)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=48093)[0m 
[2m[36m(pid=48093)[0m   | Name      | Type              | Params
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=48093)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=48093)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=48093)[0m ------------------------------------------------
[2m[36m(pid=48093)[0m 12.0 K    Trainable params
[2m[36m(pid=48093)[0m 0         Non-trainable params
[2m[36m(pid=48093)[0m 12.0 K    Total params
[2m[36m(pid=30458)[0m time to fit was 191.76898741722107
[2m[36m(pid=30458)[0m GPU available: False, used: False
[2m[36m(pid=30458)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30458)[0m 
[2m[36m(pid=30458)[0m   | Name      | Type              | Params
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30458)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30458)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 12.0 K    Trainable params
[2m[36m(pid=30458)[0m 0         Non-trainable params
[2m[36m(pid=30458)[0m 12.0 K    Total params
[2m[36m(pid=30469)[0m time to fit was 61.691304445266724
[2m[36m(pid=30469)[0m GPU available: False, used: False
[2m[36m(pid=30469)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30469)[0m 
[2m[36m(pid=30469)[0m   | Name      | Type              | Params
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30469)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30469)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30469)[0m ------------------------------------------------
[2m[36m(pid=30469)[0m 12.0 K    Trainable params
[2m[36m(pid=30469)[0m 0         Non-trainable params
[2m[36m(pid=30469)[0m 12.0 K    Total params
[2m[36m(pid=28170)[0m time to fit was 374.4768719673157
[2m[36m(pid=28170)[0m GPU available: False, used: False
[2m[36m(pid=28170)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28170)[0m 
[2m[36m(pid=28170)[0m   | Name      | Type              | Params
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28170)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28170)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 12.0 K    Trainable params
[2m[36m(pid=28170)[0m 0         Non-trainable params
[2m[36m(pid=28170)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m time to fit was 103.90632510185242
[2m[36m(pid=30497)[0m GPU available: False, used: False
[2m[36m(pid=30497)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30497)[0m 
[2m[36m(pid=30497)[0m   | Name      | Type              | Params
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30497)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30497)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30497)[0m ------------------------------------------------
[2m[36m(pid=30497)[0m 12.0 K    Trainable params
[2m[36m(pid=30497)[0m 0         Non-trainable params
[2m[36m(pid=30497)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m time to fit was 371.7764389514923
[2m[36m(pid=35505)[0m GPU available: False, used: False
[2m[36m(pid=35505)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=35505)[0m 
[2m[36m(pid=35505)[0m   | Name      | Type              | Params
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=35505)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=35505)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=35505)[0m ------------------------------------------------
[2m[36m(pid=35505)[0m 12.0 K    Trainable params
[2m[36m(pid=35505)[0m 0         Non-trainable params
[2m[36m(pid=35505)[0m 12.0 K    Total params
[2m[36m(pid=48093)[0m time to fit was 53.105764865875244
Result for _inner_e98d6_00179:
  auc: 0.5999536156654358
  date: 2021-03-18_03-14-24
  done: false
  experiment_id: 75b65a6e4c25417fa0a0212ceed280de
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 48093
  time_since_restore: 504.3220031261444
  time_this_iter_s: 504.3220031261444
  time_total_s: 504.3220031261444
  timestamp: 1616033664
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00179
  
[2m[36m(pid=48093)[0m Finished run with seed 0 - lr 5 - sec_lr 5 - bs 512 - mean val auc: 0.5999536156654358
== Status ==
Memory usage on this node: 10.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 42/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (21 RUNNING, 159 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (11 RUNNING, 149 TERMINATED)


Result for _inner_e98d6_00179:
  auc: 0.5999536156654358
  date: 2021-03-18_03-14-24
  done: true
  experiment_id: 75b65a6e4c25417fa0a0212ceed280de
  experiment_tag: 179_batch_size=512,eta=0.0,lr=5,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 48093
  time_since_restore: 504.3220031261444
  time_this_iter_s: 504.3220031261444
  time_total_s: 504.3220031261444
  timestamp: 1616033664
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00179
  
[2m[36m(pid=30469)[0m time to fit was 76.17592597007751
Result for _inner_e98d6_00178:
  auc: 0.6222095966339112
  date: 2021-03-18_03-14-56
  done: false
  experiment_id: 34a8cd7349f84f3cad6f0b0978bd5f55
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30469
  time_since_restore: 572.7794754505157
  time_this_iter_s: 572.7794754505157
  time_total_s: 572.7794754505157
  timestamp: 1616033696
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00178
  
[2m[36m(pid=30469)[0m Finished run with seed 0 - lr 5 - sec_lr 5 - bs 256 - mean val auc: 0.6222095966339112
== Status ==
Memory usage on this node: 10.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 40/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (20 RUNNING, 160 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (10 RUNNING, 150 TERMINATED)


Result for _inner_e98d6_00178:
  auc: 0.6222095966339112
  date: 2021-03-18_03-14-56
  done: true
  experiment_id: 34a8cd7349f84f3cad6f0b0978bd5f55
  experiment_tag: 178_batch_size=256,eta=0.0,lr=5,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30469
  time_since_restore: 572.7794754505157
  time_this_iter_s: 572.7794754505157
  time_total_s: 572.7794754505157
  timestamp: 1616033696
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00178
  
[2m[36m(pid=30480)[0m time to fit was 355.36044216156006
[2m[36m(pid=30480)[0m GPU available: False, used: False
[2m[36m(pid=30480)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30480)[0m 
[2m[36m(pid=30480)[0m   | Name      | Type              | Params
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30480)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30480)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 12.0 K    Trainable params
[2m[36m(pid=30480)[0m 0         Non-trainable params
[2m[36m(pid=30480)[0m 12.0 K    Total params
[2m[36m(pid=30497)[0m time to fit was 96.53706622123718
Result for _inner_e98d6_00177:
  auc: 0.5608475565910339
  date: 2021-03-18_03-15-33
  done: false
  experiment_id: 9c60fbff1b704f91a120e9afbcda0d42
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30497
  time_since_restore: 735.4454643726349
  time_this_iter_s: 735.4454643726349
  time_total_s: 735.4454643726349
  timestamp: 1616033733
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00177
  
[2m[36m(pid=30497)[0m Finished run with seed 0 - lr 5 - sec_lr 5 - bs 128 - mean val auc: 0.5608475565910339
== Status ==
Memory usage on this node: 10.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 38/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (19 RUNNING, 161 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (9 RUNNING, 151 TERMINATED)


Result for _inner_e98d6_00177:
  auc: 0.5608475565910339
  date: 2021-03-18_03-15-33
  done: true
  experiment_id: 9c60fbff1b704f91a120e9afbcda0d42
  experiment_tag: 177_batch_size=128,eta=0.0,lr=5,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30497
  time_since_restore: 735.4454643726349
  time_this_iter_s: 735.4454643726349
  time_total_s: 735.4454643726349
  timestamp: 1616033733
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00177
  
[2m[36m(pid=28364)[0m time to fit was 182.48549461364746
Result for _inner_e98d6_00171:
  auc: 0.716403728723526
  date: 2021-03-18_03-15-37
  done: false
  experiment_id: ff3f380eca604436bc4f447005c6c880
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28364
  time_since_restore: 1087.2827532291412
  time_this_iter_s: 1087.2827532291412
  time_total_s: 1087.2827532291412
  timestamp: 1616033737
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00171
  
[2m[36m(pid=28364)[0m Finished run with seed 0 - lr 2 - sec_lr 5 - bs 64 - mean val auc: 0.716403728723526
Result for _inner_e98d6_00171:
  auc: 0.716403728723526
  date: 2021-03-18_03-15-37
  done: true
  experiment_id: ff3f380eca604436bc4f447005c6c880
  experiment_tag: 171_batch_size=64,eta=0.0,lr=2,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28364
  time_since_restore: 1087.2827532291412
  time_this_iter_s: 1087.2827532291412
  time_total_s: 1087.2827532291412
  timestamp: 1616033737
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00171
  
[2m[36m(pid=43993)[0m time to fit was 357.18412494659424
Result for _inner_e98d6_00160:
  auc: 0.6620545804500579
  date: 2021-03-18_03-15-49
  done: false
  experiment_id: 33f9549bf09c47fb9ac3ddc1ef5c73df
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43993
  time_since_restore: 2045.5231549739838
  time_this_iter_s: 2045.5231549739838
  time_total_s: 2045.5231549739838
  timestamp: 1616033749
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00160
  
[2m[36m(pid=43993)[0m Finished run with seed 0 - lr 0.1 - sec_lr 5 - bs 32 - mean val auc: 0.6620545804500579
== Status ==
Memory usage on this node: 10.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 34/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (17 RUNNING, 163 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    |       |          512 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (7 RUNNING, 153 TERMINATED)


Result for _inner_e98d6_00160:
  auc: 0.6620545804500579
  date: 2021-03-18_03-15-49
  done: true
  experiment_id: 33f9549bf09c47fb9ac3ddc1ef5c73df
  experiment_tag: 160_batch_size=32,eta=0.0,lr=0.1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 43993
  time_since_restore: 2045.5231549739838
  time_this_iter_s: 2045.5231549739838
  time_total_s: 2045.5231549739838
  timestamp: 1616033749
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00160
  
[2m[36m(pid=21639)[0m time to fit was 1285.8198328018188
Result for _inner_e98d6_00034:
  auc: 0.9101783633232117
  date: 2021-03-18_03-16-04
  done: false
  experiment_id: aa923d7ae900447b82c4ca6eb570d7c1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21639
  time_since_restore: 13784.382806301117
  time_this_iter_s: 13784.382806301117
  time_total_s: 13784.382806301117
  timestamp: 1616033764
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00034
  
[2m[36m(pid=21639)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 512 - mean val auc: 0.9101783633232117
== Status ==
Memory usage on this node: 9.8/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 32/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (16 RUNNING, 164 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00034 | RUNNING    | 145.101.32.82:21639 |          512 |     0 | 0.001 |    0.01  |      1 |         13784.4  | 0.910178 |
| _inner_e98d6_00063 | RUNNING    |                     |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |                     |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (6 RUNNING, 154 TERMINATED)


Result for _inner_e98d6_00034:
  auc: 0.9101783633232117
  date: 2021-03-18_03-16-04
  done: true
  experiment_id: aa923d7ae900447b82c4ca6eb570d7c1
  experiment_tag: 34_batch_size=512,eta=0.0,lr=0.001,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21639
  time_since_restore: 13784.382806301117
  time_this_iter_s: 13784.382806301117
  time_total_s: 13784.382806301117
  timestamp: 1616033764
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00034
  
[2m[36m(pid=30458)[0m time to fit was 175.68201613426208
[2m[36m(pid=30458)[0m GPU available: False, used: False
[2m[36m(pid=30458)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30458)[0m 
[2m[36m(pid=30458)[0m   | Name      | Type              | Params
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30458)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30458)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30458)[0m ------------------------------------------------
[2m[36m(pid=30458)[0m 12.0 K    Trainable params
[2m[36m(pid=30458)[0m 0         Non-trainable params
[2m[36m(pid=30458)[0m 12.0 K    Total params
[2m[36m(pid=11525)[0m time to fit was 323.0483376979828
[2m[36m(pid=11525)[0m GPU available: False, used: False
[2m[36m(pid=11525)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=11525)[0m 
[2m[36m(pid=11525)[0m   | Name      | Type              | Params
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=11525)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=11525)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=11525)[0m ------------------------------------------------
[2m[36m(pid=11525)[0m 12.0 K    Trainable params
[2m[36m(pid=11525)[0m 0         Non-trainable params
[2m[36m(pid=11525)[0m 12.0 K    Total params
[2m[36m(pid=31069)[0m time to fit was 6242.75247168541
[2m[36m(pid=31069)[0m GPU available: False, used: False
[2m[36m(pid=31069)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31069)[0m 
[2m[36m(pid=31069)[0m   | Name      | Type              | Params
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31069)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31069)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 12.0 K    Trainable params
[2m[36m(pid=31069)[0m 0         Non-trainable params
[2m[36m(pid=31069)[0m 12.0 K    Total params
[2m[36m(pid=31069)[0m time to fit was 57.588106870651245
[2m[36m(pid=31069)[0m GPU available: False, used: False
[2m[36m(pid=31069)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=31069)[0m 
[2m[36m(pid=31069)[0m   | Name      | Type              | Params
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=31069)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=31069)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=31069)[0m ------------------------------------------------
[2m[36m(pid=31069)[0m 12.0 K    Trainable params
[2m[36m(pid=31069)[0m 0         Non-trainable params
[2m[36m(pid=31069)[0m 12.0 K    Total params
[2m[36m(pid=28170)[0m time to fit was 268.8535556793213
[2m[36m(pid=28170)[0m GPU available: False, used: False
[2m[36m(pid=28170)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28170)[0m 
[2m[36m(pid=28170)[0m   | Name      | Type              | Params
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28170)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28170)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 12.0 K    Trainable params
[2m[36m(pid=28170)[0m 0         Non-trainable params
[2m[36m(pid=28170)[0m 12.0 K    Total params
[2m[36m(pid=30458)[0m time to fit was 123.51996397972107
Result for _inner_e98d6_00176:
  auc: 0.5007004320621491
  date: 2021-03-18_03-18-33
  done: false
  experiment_id: e60c3c6b843a4a5eb2ccaa308c40578e
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30458
  time_since_restore: 936.3819732666016
  time_this_iter_s: 936.3819732666016
  time_total_s: 936.3819732666016
  timestamp: 1616033913
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00176
  
[2m[36m(pid=30458)[0m Finished run with seed 0 - lr 5 - sec_lr 5 - bs 64 - mean val auc: 0.5007004320621491
== Status ==
Memory usage on this node: 9.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 30/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (15 RUNNING, 165 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |       |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |       |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |       |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |       |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |       |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |       |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |       |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    |       |          256 |     0 | 0.001 |    0.1   |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |       |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00153 | RUNNING    |       |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (5 RUNNING, 155 TERMINATED)


Result for _inner_e98d6_00176:
  auc: 0.5007004320621491
  date: 2021-03-18_03-18-33
  done: true
  experiment_id: e60c3c6b843a4a5eb2ccaa308c40578e
  experiment_tag: 176_batch_size=64,eta=0.0,lr=5,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30458
  time_since_restore: 936.3819732666016
  time_this_iter_s: 936.3819732666016
  time_total_s: 936.3819732666016
  timestamp: 1616033913
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00176
  
[2m[36m(pid=31069)[0m time to fit was 61.20872449874878
Result for _inner_e98d6_00063:
  auc: 0.8836044073104858
  date: 2021-03-18_03-18-46
  done: false
  experiment_id: 030dbfdf20ff4ffca3f27f5c69638546
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 31069
  time_since_restore: 10801.925246477127
  time_this_iter_s: 10801.925246477127
  time_total_s: 10801.925246477127
  timestamp: 1616033926
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00063
  
[2m[36m(pid=31069)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.1 - bs 256 - mean val auc: 0.8836044073104858
== Status ==
Memory usage on this node: 9.5/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 28/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (14 RUNNING, 166 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00063 | RUNNING    | 145.101.32.82:31069 |          256 |     0 | 0.001 |    0.1   |      1 |         10801.9  | 0.883604 |
| _inner_e98d6_00145 | RUNNING    |                     |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00153 | RUNNING    |                     |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (4 RUNNING, 156 TERMINATED)


Result for _inner_e98d6_00063:
  auc: 0.8836044073104858
  date: 2021-03-18_03-18-46
  done: true
  experiment_id: 030dbfdf20ff4ffca3f27f5c69638546
  experiment_tag: 63_batch_size=256,eta=0.0,lr=0.001,sec_lr=0.1
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 31069
  time_since_restore: 10801.925246477127
  time_this_iter_s: 10801.925246477127
  time_total_s: 10801.925246477127
  timestamp: 1616033926
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00063
  
[2m[36m(pid=30480)[0m time to fit was 236.05905413627625
[2m[36m(pid=30480)[0m GPU available: False, used: False
[2m[36m(pid=30480)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30480)[0m 
[2m[36m(pid=30480)[0m   | Name      | Type              | Params
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30480)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30480)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 12.0 K    Trainable params
[2m[36m(pid=30480)[0m 0         Non-trainable params
[2m[36m(pid=30480)[0m 12.0 K    Total params
[2m[36m(pid=35505)[0m time to fit was 319.5402023792267
Result for _inner_e98d6_00155:
  auc: 0.8238797128200531
  date: 2021-03-18_03-19-24
  done: false
  experiment_id: 2e304adfa12a480bbcd944fa46faebf5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35505
  time_since_restore: 2504.2586126327515
  time_this_iter_s: 2504.2586126327515
  time_total_s: 2504.2586126327515
  timestamp: 1616033964
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00155
  
[2m[36m(pid=35505)[0m Finished run with seed 0 - lr 0.01 - sec_lr 5 - bs 32 - mean val auc: 0.8238797128200531
== Status ==
Memory usage on this node: 9.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 26/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (13 RUNNING, 167 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00145 | RUNNING    |                     |           32 |     0 | 5     |    2     |        |                  |          |
| _inner_e98d6_00153 | RUNNING    |                     |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00155 | RUNNING    | 145.101.32.82:35505 |           32 |     0 | 0.01  |    5     |      1 |          2504.26 | 0.82388  |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (3 RUNNING, 157 TERMINATED)


Result for _inner_e98d6_00155:
  auc: 0.8238797128200531
  date: 2021-03-18_03-19-24
  done: true
  experiment_id: 2e304adfa12a480bbcd944fa46faebf5
  experiment_tag: 155_batch_size=32,eta=0.0,lr=0.01,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 35505
  time_since_restore: 2504.2586126327515
  time_this_iter_s: 2504.2586126327515
  time_total_s: 2504.2586126327515
  timestamp: 1616033964
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00155
  
[2m[36m(pid=6614)[0m time to fit was 896.5763816833496
Result for _inner_e98d6_00145:
  auc: 0.6127939641475677
  date: 2021-03-18_03-19-41
  done: false
  experiment_id: 5fbd63563ead4b22b43b4623aa55cc08
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6614
  time_since_restore: 3260.690302848816
  time_this_iter_s: 3260.690302848816
  time_total_s: 3260.690302848816
  timestamp: 1616033981
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00145
  
[2m[36m(pid=6614)[0m Finished run with seed 0 - lr 5 - sec_lr 2 - bs 32 - mean val auc: 0.6127939641475677
== Status ==
Memory usage on this node: 9.0/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 24/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (12 RUNNING, 168 TERMINATED)
+--------------------+------------+--------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+--------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                    |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                    |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                    |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                    |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                    |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                    |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                    |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00145 | RUNNING    | 145.101.32.82:6614 |           32 |     0 | 5     |    2     |      1 |          3260.69 | 0.612794 |
| _inner_e98d6_00153 | RUNNING    |                    |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00165 | RUNNING    |                    |           32 |     0 | 1     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                    |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                    |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                    |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                    |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                    |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                    |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                    |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                    |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                    |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                    |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+--------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (2 RUNNING, 158 TERMINATED)


Result for _inner_e98d6_00145:
  auc: 0.6127939641475677
  date: 2021-03-18_03-19-41
  done: true
  experiment_id: 5fbd63563ead4b22b43b4623aa55cc08
  experiment_tag: 145_batch_size=32,eta=0.0,lr=5,sec_lr=2
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 6614
  time_since_restore: 3260.690302848816
  time_this_iter_s: 3260.690302848816
  time_total_s: 3260.690302848816
  timestamp: 1616033981
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00145
  
[2m[36m(pid=11525)[0m time to fit was 209.32452034950256
Result for _inner_e98d6_00165:
  auc: 0.5811333656311035
  date: 2021-03-18_03-20-00
  done: false
  experiment_id: e28bda16d66a4bcc9aaee7e0e84b11d9
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11525
  time_since_restore: 1772.8810136318207
  time_this_iter_s: 1772.8810136318207
  time_total_s: 1772.8810136318207
  timestamp: 1616034000
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00165
  
[2m[36m(pid=11525)[0m Finished run with seed 0 - lr 1 - sec_lr 5 - bs 32 - mean val auc: 0.5811333656311035
== Status ==
Memory usage on this node: 8.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 22/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (11 RUNNING, 169 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00153 | RUNNING    |                     |          256 |     0 | 0.001 |    5     |        |                  |          |
| _inner_e98d6_00165 | RUNNING    | 145.101.32.82:11525 |           32 |     0 | 1     |    5     |      1 |          1772.88 | 0.581133 |
| _inner_e98d6_00170 | RUNNING    |                     |           32 |     0 | 2     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (1 RUNNING, 159 TERMINATED)


Result for _inner_e98d6_00165:
  auc: 0.5811333656311035
  date: 2021-03-18_03-20-00
  done: true
  experiment_id: e28bda16d66a4bcc9aaee7e0e84b11d9
  experiment_tag: 165_batch_size=32,eta=0.0,lr=1,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 11525
  time_since_restore: 1772.8810136318207
  time_this_iter_s: 1772.8810136318207
  time_total_s: 1772.8810136318207
  timestamp: 1616034000
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00165
  
[2m[36m(pid=28170)[0m time to fit was 192.0536229610443
[2m[36m(pid=28170)[0m GPU available: False, used: False
[2m[36m(pid=28170)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=28170)[0m 
[2m[36m(pid=28170)[0m   | Name      | Type              | Params
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=28170)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=28170)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=28170)[0m ------------------------------------------------
[2m[36m(pid=28170)[0m 12.0 K    Trainable params
[2m[36m(pid=28170)[0m 0         Non-trainable params
[2m[36m(pid=28170)[0m 12.0 K    Total params
[2m[36m(pid=30480)[0m time to fit was 154.6182610988617
[2m[36m(pid=30480)[0m GPU available: False, used: False
[2m[36m(pid=30480)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=30480)[0m 
[2m[36m(pid=30480)[0m   | Name      | Type              | Params
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=30480)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=30480)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=30480)[0m ------------------------------------------------
[2m[36m(pid=30480)[0m 12.0 K    Trainable params
[2m[36m(pid=30480)[0m 0         Non-trainable params
[2m[36m(pid=30480)[0m 12.0 K    Total params
[2m[36m(pid=25233)[0m time to fit was 2344.237501144409
Result for _inner_e98d6_00153:
  auc: 0.8409902572631835
  date: 2021-03-18_03-21-46
  done: false
  experiment_id: 2ed5af59b06d429d931719204b9c6469
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25233
  time_since_restore: 2900.3382189273834
  time_this_iter_s: 2900.3382189273834
  time_total_s: 2900.3382189273834
  timestamp: 1616034106
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00153
  
[2m[36m(pid=25233)[0m Finished run with seed 0 - lr 0.001 - sec_lr 5 - bs 256 - mean val auc: 0.8409902572631835
== Status ==
Memory usage on this node: 8.6/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 20/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (10 RUNNING, 170 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00153 | RUNNING    | 145.101.32.82:25233 |          256 |     0 | 0.001 |    5     |      1 |          2900.34 | 0.84099  |
| _inner_e98d6_00170 | RUNNING    |                     |           32 |     0 | 2     |    5     |        |                  |          |
| _inner_e98d6_00175 | RUNNING    |                     |           32 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00153:
  auc: 0.8409902572631835
  date: 2021-03-18_03-21-46
  done: true
  experiment_id: 2ed5af59b06d429d931719204b9c6469
  experiment_tag: 153_batch_size=256,eta=0.0,lr=0.001,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 25233
  time_since_restore: 2900.3382189273834
  time_this_iter_s: 2900.3382189273834
  time_total_s: 2900.3382189273834
  timestamp: 1616034106
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00153
  
[2m[36m(pid=28170)[0m time to fit was 122.0664050579071
[2m[36m(pid=28170)[0m Finished run with seed 0 - lr 2 - sec_lr 5 - bs 32 - mean val auc: 0.6580290377140046
Result for _inner_e98d6_00170:
  auc: 0.6580290377140046
  date: 2021-03-18_03-23-32
  done: false
  experiment_id: b5ca21f04a5e477b83d5101f6cdcad77
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28170
  time_since_restore: 1566.0573918819427
  time_this_iter_s: 1566.0573918819427
  time_total_s: 1566.0573918819427
  timestamp: 1616034212
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00170
  
== Status ==
Memory usage on this node: 8.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 18/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (9 RUNNING, 171 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00170 | RUNNING    | 145.101.32.82:28170 |           32 |     0 | 2     |    5     |      1 |          1566.06 | 0.658029 |
| _inner_e98d6_00175 | RUNNING    |                     |           32 |     0 | 5     |    5     |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |         13888.4  | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |         12013.7  | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |          5578.91 | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |          4029.63 | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |          3090.55 | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |          2911.4  | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |          2803.49 | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |          3398    | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |          1865.07 | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |          1223.3  | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |           786.48 | 0.913244 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00170:
  auc: 0.6580290377140046
  date: 2021-03-18_03-23-32
  done: true
  experiment_id: b5ca21f04a5e477b83d5101f6cdcad77
  experiment_tag: 170_batch_size=32,eta=0.0,lr=2,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 28170
  time_since_restore: 1566.0573918819427
  time_this_iter_s: 1566.0573918819427
  time_total_s: 1566.0573918819427
  timestamp: 1616034212
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00170
  
[2m[36m(pid=30480)[0m time to fit was 120.37573838233948
Result for _inner_e98d6_00175:
  auc: 0.4986472845077515
  date: 2021-03-18_03-23-39
  done: false
  experiment_id: f0d3e5965b1f4690bf421ccc67081b7a
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30480
  time_since_restore: 1265.6980230808258
  time_this_iter_s: 1265.6980230808258
  time_total_s: 1265.6980230808258
  timestamp: 1616034219
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00175
  
== Status ==
Memory usage on this node: 8.3/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 16/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (8 RUNNING, 172 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    |                     |          128 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00175 | RUNNING    | 145.101.32.82:30480 |           32 |     0 | 5     |    5     |      1 |         1265.7   | 0.498647 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


[2m[36m(pid=30480)[0m Finished run with seed 0 - lr 5 - sec_lr 5 - bs 32 - mean val auc: 0.4986472845077515
Result for _inner_e98d6_00175:
  auc: 0.4986472845077515
  date: 2021-03-18_03-23-39
  done: true
  experiment_id: f0d3e5965b1f4690bf421ccc67081b7a
  experiment_tag: 175_batch_size=32,eta=0.0,lr=5,sec_lr=5
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 30480
  time_since_restore: 1265.6980230808258
  time_this_iter_s: 1265.6980230808258
  time_total_s: 1265.6980230808258
  timestamp: 1616034219
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00175
  
[2m[36m(pid=21729)[0m time to fit was 1661.0744438171387
[2m[36m(pid=21729)[0m GPU available: False, used: False
[2m[36m(pid=21729)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21729)[0m 
[2m[36m(pid=21729)[0m   | Name      | Type              | Params
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21729)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21729)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21729)[0m ------------------------------------------------
[2m[36m(pid=21729)[0m 12.0 K    Trainable params
[2m[36m(pid=21729)[0m 0         Non-trainable params
[2m[36m(pid=21729)[0m 12.0 K    Total params
[2m[36m(pid=21731)[0m time to fit was 9473.001961708069
[2m[36m(pid=21731)[0m GPU available: False, used: False
[2m[36m(pid=21731)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21731)[0m 
[2m[36m(pid=21731)[0m   | Name      | Type              | Params
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21731)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21731)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 12.0 K    Trainable params
[2m[36m(pid=21731)[0m 0         Non-trainable params
[2m[36m(pid=21731)[0m 12.0 K    Total params
[2m[36m(pid=21661)[0m time to fit was 4139.1078543663025
[2m[36m(pid=21661)[0m GPU available: False, used: False
[2m[36m(pid=21661)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21661)[0m 
[2m[36m(pid=21661)[0m   | Name      | Type              | Params
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21661)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21661)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 12.0 K    Trainable params
[2m[36m(pid=21661)[0m 0         Non-trainable params
[2m[36m(pid=21661)[0m 12.0 K    Total params
[2m[36m(pid=21729)[0m time to fit was 497.25694847106934
Result for _inner_e98d6_00002:
  auc: 0.910818874835968
  date: 2021-03-18_03-36-44
  done: false
  experiment_id: 6f86e9960c3f4b838f92bf5fa0104ff4
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21729
  time_since_restore: 16258.758372068405
  time_this_iter_s: 16258.758372068405
  time_total_s: 16258.758372068405
  timestamp: 1616035004
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00002
  
[2m[36m(pid=21729)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 128 - mean val auc: 0.910818874835968
== Status ==
Memory usage on this node: 8.2/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 14/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (7 RUNNING, 173 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00002 | RUNNING    | 145.101.32.82:21729 |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    |                     |          256 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00002:
  auc: 0.910818874835968
  date: 2021-03-18_03-36-44
  done: true
  experiment_id: 6f86e9960c3f4b838f92bf5fa0104ff4
  experiment_tag: 2_batch_size=128,eta=0.0,lr=0.001,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21729
  time_since_restore: 16258.758372068405
  time_this_iter_s: 16258.758372068405
  time_total_s: 16258.758372068405
  timestamp: 1616035004
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00002
  
Result for _inner_e98d6_00033:
  auc: 0.9100984454154968
  date: 2021-03-18_03-36-56
  done: false
  experiment_id: 848fb47f1f124933883873a2cff65ec6
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21667
  time_since_restore: 15155.03657746315
  time_this_iter_s: 15155.03657746315
  time_total_s: 15155.03657746315
  timestamp: 1616035016
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00033
  
[2m[36m(pid=21667)[0m time to fit was 1929.3683099746704
== Status ==
Memory usage on this node: 7.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 12/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (6 RUNNING, 174 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    |                     |           64 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00033 | RUNNING    | 145.101.32.82:21667 |          256 |     0 | 0.001 |    0.01  |      1 |        15155     | 0.910098 |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00033:
  auc: 0.9100984454154968
  date: 2021-03-18_03-36-56
  done: true
  experiment_id: 848fb47f1f124933883873a2cff65ec6
  experiment_tag: 33_batch_size=256,eta=0.0,lr=0.001,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21667
  time_since_restore: 15155.03657746315
  time_this_iter_s: 15155.03657746315
  time_total_s: 15155.03657746315
  timestamp: 1616035016
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00033
  
[2m[36m(pid=21667)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 256 - mean val auc: 0.9100984454154968
[2m[36m(pid=21672)[0m time to fit was 5689.915897369385
Result for _inner_e98d6_00031:
  auc: 0.9069374322891235
  date: 2021-03-18_03-42-31
  done: false
  experiment_id: 50dfcb0897184104a2df22d14498725d
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21672
  time_since_restore: 15808.634338140488
  time_this_iter_s: 15808.634338140488
  time_total_s: 15808.634338140488
  timestamp: 1616035351
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00031
  
== Status ==
Memory usage on this node: 7.7/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 10/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (5 RUNNING, 175 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00031 | RUNNING    | 145.101.32.82:21672 |           64 |     0 | 0.001 |    0.01  |      1 |        15808.6   | 0.906937 |
| _inner_e98d6_00032 | RUNNING    |                     |          128 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00031:
  auc: 0.9069374322891235
  date: 2021-03-18_03-42-31
  done: true
  experiment_id: 50dfcb0897184104a2df22d14498725d
  experiment_tag: 31_batch_size=64,eta=0.0,lr=0.001,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21672
  time_since_restore: 15808.634338140488
  time_this_iter_s: 15808.634338140488
  time_total_s: 15808.634338140488
  timestamp: 1616035351
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00031
  
[2m[36m(pid=21672)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 64 - mean val auc: 0.9069374322891235
[2m[36m(pid=21661)[0m time to fit was 384.4065282344818
[2m[36m(pid=21661)[0m GPU available: False, used: False
[2m[36m(pid=21661)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21661)[0m 
[2m[36m(pid=21661)[0m   | Name      | Type              | Params
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21661)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21661)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21661)[0m ------------------------------------------------
[2m[36m(pid=21661)[0m 12.0 K    Trainable params
[2m[36m(pid=21661)[0m 0         Non-trainable params
[2m[36m(pid=21661)[0m 12.0 K    Total params
Result for _inner_e98d6_00032:
  auc: 0.9083919882774353
  date: 2021-03-18_03-43-54
  done: false
  experiment_id: 27dcaa0326a447438ba5ea9fb1bd4451
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21661
  time_since_restore: 15619.911890745163
  time_this_iter_s: 15619.911890745163
  time_total_s: 15619.911890745163
  timestamp: 1616035434
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00032
  
== Status ==
Memory usage on this node: 7.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 8/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (4 RUNNING, 176 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    |                     |           64 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00032 | RUNNING    | 145.101.32.82:21661 |          128 |     0 | 0.001 |    0.01  |      1 |        15619.9   | 0.908392 |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00032:
  auc: 0.9083919882774353
  date: 2021-03-18_03-43-54
  done: true
  experiment_id: 27dcaa0326a447438ba5ea9fb1bd4451
  experiment_tag: 32_batch_size=128,eta=0.0,lr=0.001,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21661
  time_since_restore: 15619.911890745163
  time_this_iter_s: 15619.911890745163
  time_total_s: 15619.911890745163
  timestamp: 1616035434
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00032
  
[2m[36m(pid=21661)[0m time to fit was 52.14244246482849
[2m[36m(pid=21661)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 128 - mean val auc: 0.9083919882774353
[2m[36m(pid=21731)[0m time to fit was 907.8846700191498
[2m[36m(pid=21731)[0m GPU available: False, used: False
[2m[36m(pid=21731)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21731)[0m 
[2m[36m(pid=21731)[0m   | Name      | Type              | Params
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21731)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21731)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21731)[0m ------------------------------------------------
[2m[36m(pid=21731)[0m 12.0 K    Trainable params
[2m[36m(pid=21731)[0m 0         Non-trainable params
[2m[36m(pid=21731)[0m 12.0 K    Total params
[2m[36m(pid=21731)[0m time to fit was 244.88561296463013
Result for _inner_e98d6_00001:
  auc: 0.9099042296409607
  date: 2021-03-18_03-49-11
  done: false
  experiment_id: 123d05c236e34cf8904a5de5e5ebbcc0
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21731
  time_since_restore: 17005.13821554184
  time_this_iter_s: 17005.13821554184
  time_total_s: 17005.13821554184
  timestamp: 1616035751
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00001
  
== Status ==
Memory usage on this node: 7.1/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 6/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (3 RUNNING, 177 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    |                     |           32 |     0 | 0.001 |    0.001 |        |                  |          |
| _inner_e98d6_00001 | RUNNING    | 145.101.32.82:21731 |           64 |     0 | 0.001 |    0.001 |      1 |        17005.1   | 0.909904 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00001:
  auc: 0.9099042296409607
  date: 2021-03-18_03-49-11
  done: true
  experiment_id: 123d05c236e34cf8904a5de5e5ebbcc0
  experiment_tag: 1_batch_size=64,eta=0.0,lr=0.001,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21731
  time_since_restore: 17005.13821554184
  time_this_iter_s: 17005.13821554184
  time_total_s: 17005.13821554184
  timestamp: 1616035751
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00001
  
[2m[36m(pid=21731)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 64 - mean val auc: 0.9099042296409607
[2m[36m(pid=21658)[0m time to fit was 4353.470721721649
[2m[36m(pid=21658)[0m GPU available: False, used: False
[2m[36m(pid=21658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21658)[0m 
[2m[36m(pid=21658)[0m   | Name      | Type              | Params
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 12.0 K    Trainable params
[2m[36m(pid=21658)[0m 0         Non-trainable params
[2m[36m(pid=21658)[0m 12.0 K    Total params
[2m[36m(pid=21740)[0m time to fit was 3458.0807161331177
[2m[36m(pid=21740)[0m GPU available: False, used: False
[2m[36m(pid=21740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m 
[2m[36m(pid=21740)[0m   | Name      | Type              | Params
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 12.0 K    Trainable params
[2m[36m(pid=21740)[0m 0         Non-trainable params
[2m[36m(pid=21740)[0m 12.0 K    Total params
[2m[36m(pid=21740)[0m time to fit was 691.5911560058594
[2m[36m(pid=21740)[0m GPU available: False, used: False
[2m[36m(pid=21740)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21740)[0m 
[2m[36m(pid=21740)[0m   | Name      | Type              | Params
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21740)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21740)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21740)[0m ------------------------------------------------
[2m[36m(pid=21740)[0m 12.0 K    Trainable params
[2m[36m(pid=21740)[0m 0         Non-trainable params
[2m[36m(pid=21740)[0m 12.0 K    Total params
Result for _inner_e98d6_00000:
  auc: 0.9099033951759339
  date: 2021-03-18_04-22-53
  done: false
  experiment_id: 042ec47a1dd949b18335279a742cbd25
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21740
  time_since_restore: 19028.13986849785
  time_this_iter_s: 19028.13986849785
  time_total_s: 19028.13986849785
  timestamp: 1616037773
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00000
  
[2m[36m(pid=21740)[0m time to fit was 293.3818726539612
[2m[36m(pid=21740)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.001 - bs 32 - mean val auc: 0.9099033951759339
== Status ==
Memory usage on this node: 6.9/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 4/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (2 RUNNING, 178 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | RUNNING    | 145.101.32.82:21740 |           32 |     0 | 0.001 |    0.001 |      1 |        19028.1   | 0.909903 |
| _inner_e98d6_00030 | RUNNING    |                     |           32 |     0 | 0.001 |    0.01  |        |                  |          |
| _inner_e98d6_00001 | TERMINATED |                     |           64 |     0 | 0.001 |    0.001 |      1 |        17005.1   | 0.909904 |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00000:
  auc: 0.9099033951759339
  date: 2021-03-18_04-22-53
  done: true
  experiment_id: 042ec47a1dd949b18335279a742cbd25
  experiment_tag: 0_batch_size=32,eta=0.0,lr=0.001,sec_lr=0.001
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21740
  time_since_restore: 19028.13986849785
  time_this_iter_s: 19028.13986849785
  time_total_s: 19028.13986849785
  timestamp: 1616037773
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00000
  
[2m[36m(pid=21658)[0m time to fit was 1357.4397313594818
[2m[36m(pid=21658)[0m GPU available: False, used: False
[2m[36m(pid=21658)[0m TPU available: None, using: 0 TPU cores
[2m[36m(pid=21658)[0m 
[2m[36m(pid=21658)[0m   | Name      | Type              | Params
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 0 | learner   | Learner           | 8.6 K 
[2m[36m(pid=21658)[0m 1 | adversary | Adversary         | 3.3 K 
[2m[36m(pid=21658)[0m 2 | loss_fct  | BCEWithLogitsLoss | 0     
[2m[36m(pid=21658)[0m ------------------------------------------------
[2m[36m(pid=21658)[0m 12.0 K    Trainable params
[2m[36m(pid=21658)[0m 0         Non-trainable params
[2m[36m(pid=21658)[0m 12.0 K    Total params
Result for _inner_e98d6_00030:
[2m[36m(pid=21658)[0m time to fit was 1783.6755747795105
  auc: 0.9108035564422607
  date: 2021-03-18_04-56-53
  done: false
  experiment_id: d68d2f76743d42b7959c9a8d871cfcef
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21658
  time_since_restore: 20275.122069597244
  time_this_iter_s: 20275.122069597244
  time_total_s: 20275.122069597244
  timestamp: 1616039813
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00030
  
== Status ==
Memory usage on this node: 6.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 2/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (1 RUNNING, 179 TERMINATED)
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc                 |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00030 | RUNNING    | 145.101.32.82:21658 |           32 |     0 | 0.001 |    0.01  |      1 |        20275.1   | 0.910804 |
| _inner_e98d6_00000 | TERMINATED |                     |           32 |     0 | 0.001 |    0.001 |      1 |        19028.1   | 0.909903 |
| _inner_e98d6_00001 | TERMINATED |                     |           64 |     0 | 0.001 |    0.001 |      1 |        17005.1   | 0.909904 |
| _inner_e98d6_00002 | TERMINATED |                     |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |                     |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |                     |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |                     |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |                     |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |                     |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |                     |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |                     |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |                     |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |                     |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |                     |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |                     |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |                     |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |                     |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |                     |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |                     |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |                     |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
+--------------------+------------+---------------------+--------------+-------+-------+----------+--------+------------------+----------+
... 160 more trials not shown (160 TERMINATED)


Result for _inner_e98d6_00030:
  auc: 0.9108035564422607
  date: 2021-03-18_04-56-53
  done: true
  experiment_id: d68d2f76743d42b7959c9a8d871cfcef
  experiment_tag: 30_batch_size=32,eta=0.0,lr=0.001,sec_lr=0.01
  hostname: r37n1.lisa.surfsara.nl
  iterations_since_restore: 1
  node_ip: 145.101.32.82
  pid: 21658
  time_since_restore: 20275.122069597244
  time_this_iter_s: 20275.122069597244
  time_total_s: 20275.122069597244
  timestamp: 1616039813
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: e98d6_00030
  
[2m[36m(pid=21658)[0m Finished run with seed 0 - lr 0.001 - sec_lr 0.01 - bs 32 - mean val auc: 0.9108035564422607== Status ==
Memory usage on this node: 6.4/376.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/52 CPUs, 0/0 GPUs, 0.0/252.44 GiB heap, 0.0/77.39 GiB objects
Current best trial: e98d6_00049 with auc=0.914304780960083 and parameters={'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
Result logdir: /home/nolte/fact-ai/grid_search/ARL_Adult_version_1616018733
Number of trials: 180/180 (180 TERMINATED)
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+
| Trial name         | status     | loc   |   batch_size |   eta |    lr |   sec_lr |   iter |   total time (s) |      auc |
|--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------|
| _inner_e98d6_00000 | TERMINATED |       |           32 |     0 | 0.001 |    0.001 |      1 |        19028.1   | 0.909903 |
| _inner_e98d6_00001 | TERMINATED |       |           64 |     0 | 0.001 |    0.001 |      1 |        17005.1   | 0.909904 |
| _inner_e98d6_00002 | TERMINATED |       |          128 |     0 | 0.001 |    0.001 |      1 |        16258.8   | 0.910819 |
| _inner_e98d6_00003 | TERMINATED |       |          256 |     0 | 0.001 |    0.001 |      1 |        13888.4   | 0.910025 |
| _inner_e98d6_00004 | TERMINATED |       |          512 |     0 | 0.001 |    0.001 |      1 |        12013.7   | 0.909951 |
| _inner_e98d6_00005 | TERMINATED |       |           32 |     0 | 0.01  |    0.001 |      1 |         5578.91  | 0.912222 |
| _inner_e98d6_00006 | TERMINATED |       |           64 |     0 | 0.01  |    0.001 |      1 |         4029.63  | 0.912796 |
| _inner_e98d6_00007 | TERMINATED |       |          128 |     0 | 0.01  |    0.001 |      1 |         3090.55  | 0.912664 |
| _inner_e98d6_00008 | TERMINATED |       |          256 |     0 | 0.01  |    0.001 |      1 |         2911.4   | 0.912663 |
| _inner_e98d6_00009 | TERMINATED |       |          512 |     0 | 0.01  |    0.001 |      1 |         2803.49  | 0.912396 |
| _inner_e98d6_00010 | TERMINATED |       |           32 |     0 | 0.1   |    0.001 |      1 |         3398     | 0.913772 |
| _inner_e98d6_00011 | TERMINATED |       |           64 |     0 | 0.1   |    0.001 |      1 |         1865.07  | 0.913879 |
| _inner_e98d6_00012 | TERMINATED |       |          128 |     0 | 0.1   |    0.001 |      1 |         1223.3   | 0.913458 |
| _inner_e98d6_00013 | TERMINATED |       |          256 |     0 | 0.1   |    0.001 |      1 |          786.48  | 0.913244 |
| _inner_e98d6_00014 | TERMINATED |       |          512 |     0 | 0.1   |    0.001 |      1 |          591.292 | 0.912953 |
| _inner_e98d6_00015 | TERMINATED |       |           32 |     0 | 1     |    0.001 |      1 |         3649.89  | 0.913091 |
| _inner_e98d6_00016 | TERMINATED |       |           64 |     0 | 1     |    0.001 |      1 |         2183.86  | 0.913398 |
| _inner_e98d6_00017 | TERMINATED |       |          128 |     0 | 1     |    0.001 |      1 |         1055.45  | 0.913333 |
| _inner_e98d6_00018 | TERMINATED |       |          256 |     0 | 1     |    0.001 |      1 |          656.996 | 0.91412  |
| _inner_e98d6_00019 | TERMINATED |       |          512 |     0 | 1     |    0.001 |      1 |          482.859 | 0.913795 |
| _inner_e98d6_00020 | TERMINATED |       |           32 |     0 | 2     |    0.001 |      1 |         3384.51  | 0.829944 |
| _inner_e98d6_00021 | TERMINATED |       |           64 |     0 | 2     |    0.001 |      1 |         2059.79  | 0.830584 |
| _inner_e98d6_00022 | TERMINATED |       |          128 |     0 | 2     |    0.001 |      1 |         1311.16  | 0.828486 |
| _inner_e98d6_00023 | TERMINATED |       |          256 |     0 | 2     |    0.001 |      1 |          779.649 | 0.829721 |
| _inner_e98d6_00024 | TERMINATED |       |          512 |     0 | 2     |    0.001 |      1 |          507.811 | 0.76048  |
| _inner_e98d6_00025 | TERMINATED |       |           32 |     0 | 5     |    0.001 |      1 |         2241.98  | 0.515093 |
| _inner_e98d6_00026 | TERMINATED |       |           64 |     0 | 5     |    0.001 |      1 |         2859.11  | 0.701472 |
| _inner_e98d6_00027 | TERMINATED |       |          128 |     0 | 5     |    0.001 |      1 |         1021.04  | 0.576559 |
| _inner_e98d6_00028 | TERMINATED |       |          256 |     0 | 5     |    0.001 |      1 |         1230.5   | 0.626037 |
| _inner_e98d6_00029 | TERMINATED |       |          512 |     0 | 5     |    0.001 |      1 |          438.826 | 0.66786  |
| _inner_e98d6_00030 | TERMINATED |       |           32 |     0 | 0.001 |    0.01  |      1 |        20275.1   | 0.910804 |
| _inner_e98d6_00031 | TERMINATED |       |           64 |     0 | 0.001 |    0.01  |      1 |        15808.6   | 0.906937 |
| _inner_e98d6_00032 | TERMINATED |       |          128 |     0 | 0.001 |    0.01  |      1 |        15619.9   | 0.908392 |
| _inner_e98d6_00033 | TERMINATED |       |          256 |     0 | 0.001 |    0.01  |      1 |        15155     | 0.910098 |
| _inner_e98d6_00034 | TERMINATED |       |          512 |     0 | 0.001 |    0.01  |      1 |        13784.4   | 0.910178 |
| _inner_e98d6_00035 | TERMINATED |       |           32 |     0 | 0.01  |    0.01  |      1 |         4054.49  | 0.909581 |
| _inner_e98d6_00036 | TERMINATED |       |           64 |     0 | 0.01  |    0.01  |      1 |         2167.57  | 0.910449 |
| _inner_e98d6_00037 | TERMINATED |       |          128 |     0 | 0.01  |    0.01  |      1 |         1416.9   | 0.910037 |
| _inner_e98d6_00038 | TERMINATED |       |          256 |     0 | 0.01  |    0.01  |      1 |         1064.96  | 0.910489 |
| _inner_e98d6_00039 | TERMINATED |       |          512 |     0 | 0.01  |    0.01  |      1 |          900.695 | 0.909714 |
| _inner_e98d6_00040 | TERMINATED |       |           32 |     0 | 0.1   |    0.01  |      1 |         2506.07  | 0.912278 |
| _inner_e98d6_00041 | TERMINATED |       |           64 |     0 | 0.1   |    0.01  |      1 |         1557.83  | 0.912081 |
| _inner_e98d6_00042 | TERMINATED |       |          128 |     0 | 0.1   |    0.01  |      1 |          894.554 | 0.912831 |
| _inner_e98d6_00043 | TERMINATED |       |          256 |     0 | 0.1   |    0.01  |      1 |          622.134 | 0.913089 |
| _inner_e98d6_00044 | TERMINATED |       |          512 |     0 | 0.1   |    0.01  |      1 |          565.688 | 0.913637 |
| _inner_e98d6_00045 | TERMINATED |       |           32 |     0 | 1     |    0.01  |      1 |         2676.46  | 0.91126  |
| _inner_e98d6_00046 | TERMINATED |       |           64 |     0 | 1     |    0.01  |      1 |         1452.56  | 0.911637 |
| _inner_e98d6_00047 | TERMINATED |       |          128 |     0 | 1     |    0.01  |      1 |         1050.55  | 0.912091 |
| _inner_e98d6_00048 | TERMINATED |       |          256 |     0 | 1     |    0.01  |      1 |          541.704 | 0.913722 |
| _inner_e98d6_00049 | TERMINATED |       |          512 |     0 | 1     |    0.01  |      1 |          469.221 | 0.914305 |
| _inner_e98d6_00050 | TERMINATED |       |           32 |     0 | 2     |    0.01  |      1 |         3211.19  | 0.826948 |
| _inner_e98d6_00051 | TERMINATED |       |           64 |     0 | 2     |    0.01  |      1 |         2330.1   | 0.910055 |
| _inner_e98d6_00052 | TERMINATED |       |          128 |     0 | 2     |    0.01  |      1 |         1212.5   | 0.909    |
| _inner_e98d6_00053 | TERMINATED |       |          256 |     0 | 2     |    0.01  |      1 |          579.315 | 0.911428 |
| _inner_e98d6_00054 | TERMINATED |       |          512 |     0 | 2     |    0.01  |      1 |          525.34  | 0.766717 |
| _inner_e98d6_00055 | TERMINATED |       |           32 |     0 | 5     |    0.01  |      1 |         2407.04  | 0.537509 |
| _inner_e98d6_00056 | TERMINATED |       |           64 |     0 | 5     |    0.01  |      1 |         3908.54  | 0.732702 |
| _inner_e98d6_00057 | TERMINATED |       |          128 |     0 | 5     |    0.01  |      1 |         1494.86  | 0.697387 |
| _inner_e98d6_00058 | TERMINATED |       |          256 |     0 | 5     |    0.01  |      1 |         1322.1   | 0.654402 |
| _inner_e98d6_00059 | TERMINATED |       |          512 |     0 | 5     |    0.01  |      1 |          324.136 | 0.582464 |
| _inner_e98d6_00060 | TERMINATED |       |           32 |     0 | 0.001 |    0.1   |      1 |         2658.76  | 0.882341 |
| _inner_e98d6_00061 | TERMINATED |       |           64 |     0 | 0.001 |    0.1   |      1 |         4448.78  | 0.889038 |
| _inner_e98d6_00062 | TERMINATED |       |          128 |     0 | 0.001 |    0.1   |      1 |         1407.29  | 0.880821 |
| _inner_e98d6_00063 | TERMINATED |       |          256 |     0 | 0.001 |    0.1   |      1 |        10801.9   | 0.883604 |
| _inner_e98d6_00064 | TERMINATED |       |          512 |     0 | 0.001 |    0.1   |      1 |          581.461 | 0.857609 |
| _inner_e98d6_00065 | TERMINATED |       |           32 |     0 | 0.01  |    0.1   |      1 |         3454.8   | 0.91012  |
| _inner_e98d6_00066 | TERMINATED |       |           64 |     0 | 0.01  |    0.1   |      1 |         1650.26  | 0.905213 |
| _inner_e98d6_00067 | TERMINATED |       |          128 |     0 | 0.01  |    0.1   |      1 |         1223.71  | 0.909869 |
| _inner_e98d6_00068 | TERMINATED |       |          256 |     0 | 0.01  |    0.1   |      1 |         1067.88  | 0.906419 |
| _inner_e98d6_00069 | TERMINATED |       |          512 |     0 | 0.01  |    0.1   |      1 |          614.674 | 0.907193 |
| _inner_e98d6_00070 | TERMINATED |       |           32 |     0 | 0.1   |    0.1   |      1 |         2480.18  | 0.902045 |
| _inner_e98d6_00071 | TERMINATED |       |           64 |     0 | 0.1   |    0.1   |      1 |         1181.45  | 0.904797 |
| _inner_e98d6_00072 | TERMINATED |       |          128 |     0 | 0.1   |    0.1   |      1 |          670.669 | 0.909143 |
| _inner_e98d6_00073 | TERMINATED |       |          256 |     0 | 0.1   |    0.1   |      1 |          411.117 | 0.911567 |
| _inner_e98d6_00074 | TERMINATED |       |          512 |     0 | 0.1   |    0.1   |      1 |          341.781 | 0.911692 |
| _inner_e98d6_00075 | TERMINATED |       |           32 |     0 | 1     |    0.1   |      1 |         2395.29  | 0.8899   |
| _inner_e98d6_00076 | TERMINATED |       |           64 |     0 | 1     |    0.1   |      1 |         1332.31  | 0.907417 |
| _inner_e98d6_00077 | TERMINATED |       |          128 |     0 | 1     |    0.1   |      1 |          822.014 | 0.909696 |
| _inner_e98d6_00078 | TERMINATED |       |          256 |     0 | 1     |    0.1   |      1 |          400.083 | 0.91096  |
| _inner_e98d6_00079 | TERMINATED |       |          512 |     0 | 1     |    0.1   |      1 |          341.57  | 0.912828 |
| _inner_e98d6_00080 | TERMINATED |       |           32 |     0 | 2     |    0.1   |      1 |         2363.76  | 0.762013 |
| _inner_e98d6_00081 | TERMINATED |       |           64 |     0 | 2     |    0.1   |      1 |         1288.89  | 0.817521 |
| _inner_e98d6_00082 | TERMINATED |       |          128 |     0 | 2     |    0.1   |      1 |          751.15  | 0.901546 |
| _inner_e98d6_00083 | TERMINATED |       |          256 |     0 | 2     |    0.1   |      1 |          523.196 | 0.826002 |
| _inner_e98d6_00084 | TERMINATED |       |          512 |     0 | 2     |    0.1   |      1 |          431.881 | 0.825761 |
| _inner_e98d6_00085 | TERMINATED |       |           32 |     0 | 5     |    0.1   |      1 |         3576.05  | 0.651221 |
| _inner_e98d6_00086 | TERMINATED |       |           64 |     0 | 5     |    0.1   |      1 |         2767.13  | 0.632598 |
| _inner_e98d6_00087 | TERMINATED |       |          128 |     0 | 5     |    0.1   |      1 |         1252.15  | 0.694349 |
| _inner_e98d6_00088 | TERMINATED |       |          256 |     0 | 5     |    0.1   |      1 |          786.076 | 0.675889 |
| _inner_e98d6_00089 | TERMINATED |       |          512 |     0 | 5     |    0.1   |      1 |          630.134 | 0.663074 |
| _inner_e98d6_00090 | TERMINATED |       |           32 |     0 | 0.001 |    1     |      1 |         2470.66  | 0.873608 |
| _inner_e98d6_00091 | TERMINATED |       |           64 |     0 | 0.001 |    1     |      1 |         1500.45  | 0.867126 |
| _inner_e98d6_00092 | TERMINATED |       |          128 |     0 | 0.001 |    1     |      1 |         1230.28  | 0.873279 |
| _inner_e98d6_00093 | TERMINATED |       |          256 |     0 | 0.001 |    1     |      1 |         6729.65  | 0.874883 |
| _inner_e98d6_00094 | TERMINATED |       |          512 |     0 | 0.001 |    1     |      1 |          633.543 | 0.847909 |
| _inner_e98d6_00095 | TERMINATED |       |           32 |     0 | 0.01  |    1     |      1 |         2442.44  | 0.820687 |
| _inner_e98d6_00096 | TERMINATED |       |           64 |     0 | 0.01  |    1     |      1 |         1214.73  | 0.905727 |
| _inner_e98d6_00097 | TERMINATED |       |          128 |     0 | 0.01  |    1     |      1 |          820.738 | 0.907381 |
| _inner_e98d6_00098 | TERMINATED |       |          256 |     0 | 0.01  |    1     |      1 |          848.512 | 0.907051 |
| _inner_e98d6_00099 | TERMINATED |       |          512 |     0 | 0.01  |    1     |      1 |          781.121 | 0.907104 |
| _inner_e98d6_00100 | TERMINATED |       |           32 |     0 | 0.1   |    1     |      1 |         2157.04  | 0.886154 |
| _inner_e98d6_00101 | TERMINATED |       |           64 |     0 | 0.1   |    1     |      1 |         1128.76  | 0.882491 |
| _inner_e98d6_00102 | TERMINATED |       |          128 |     0 | 0.1   |    1     |      1 |          685.035 | 0.909947 |
| _inner_e98d6_00103 | TERMINATED |       |          256 |     0 | 0.1   |    1     |      1 |          409.893 | 0.911067 |
| _inner_e98d6_00104 | TERMINATED |       |          512 |     0 | 0.1   |    1     |      1 |          322.104 | 0.911359 |
| _inner_e98d6_00105 | TERMINATED |       |           32 |     0 | 1     |    1     |      1 |         2300.77  | 0.884258 |
| _inner_e98d6_00106 | TERMINATED |       |           64 |     0 | 1     |    1     |      1 |         1146.31  | 0.889999 |
| _inner_e98d6_00107 | TERMINATED |       |          128 |     0 | 1     |    1     |      1 |          673.045 | 0.907372 |
| _inner_e98d6_00108 | TERMINATED |       |          256 |     0 | 1     |    1     |      1 |          386.554 | 0.909922 |
| _inner_e98d6_00109 | TERMINATED |       |          512 |     0 | 1     |    1     |      1 |          311.258 | 0.912297 |
| _inner_e98d6_00110 | TERMINATED |       |           32 |     0 | 2     |    1     |      1 |         2245.23  | 0.804092 |
| _inner_e98d6_00111 | TERMINATED |       |           64 |     0 | 2     |    1     |      1 |         1985.07  | 0.803975 |
| _inner_e98d6_00112 | TERMINATED |       |          128 |     0 | 2     |    1     |      1 |          958.039 | 0.819861 |
| _inner_e98d6_00113 | TERMINATED |       |          256 |     0 | 2     |    1     |      1 |          423.231 | 0.894132 |
| _inner_e98d6_00114 | TERMINATED |       |          512 |     0 | 2     |    1     |      1 |          294.045 | 0.825512 |
| _inner_e98d6_00115 | TERMINATED |       |           32 |     0 | 5     |    1     |      1 |         2782.94  | 0.609278 |
| _inner_e98d6_00116 | TERMINATED |       |           64 |     0 | 5     |    1     |      1 |         2401.8   | 0.622899 |
| _inner_e98d6_00117 | TERMINATED |       |          128 |     0 | 5     |    1     |      1 |         1005.64  | 0.705167 |
| _inner_e98d6_00118 | TERMINATED |       |          256 |     0 | 5     |    1     |      1 |          509.044 | 0.6606   |
| _inner_e98d6_00119 | TERMINATED |       |          512 |     0 | 5     |    1     |      1 |          278.401 | 0.502316 |
| _inner_e98d6_00120 | TERMINATED |       |           32 |     0 | 0.001 |    2     |      1 |         2153.64  | 0.498647 |
| _inner_e98d6_00121 | TERMINATED |       |           64 |     0 | 0.001 |    2     |      1 |         1190.72  | 0.831293 |
| _inner_e98d6_00122 | TERMINATED |       |          128 |     0 | 0.001 |    2     |      1 |          778.954 | 0.795739 |
| _inner_e98d6_00123 | TERMINATED |       |          256 |     0 | 0.001 |    2     |      1 |         1138.83  | 0.862536 |
| _inner_e98d6_00124 | TERMINATED |       |          512 |     0 | 0.001 |    2     |      1 |          558.086 | 0.833342 |
| _inner_e98d6_00125 | TERMINATED |       |           32 |     0 | 0.01  |    2     |      1 |         2114.14  | 0.498647 |
| _inner_e98d6_00126 | TERMINATED |       |           64 |     0 | 0.01  |    2     |      1 |         1491.27  | 0.906413 |
| _inner_e98d6_00127 | TERMINATED |       |          128 |     0 | 0.01  |    2     |      1 |          985.355 | 0.906385 |
| _inner_e98d6_00128 | TERMINATED |       |          256 |     0 | 0.01  |    2     |      1 |          748.279 | 0.907544 |
| _inner_e98d6_00129 | TERMINATED |       |          512 |     0 | 0.01  |    2     |      1 |          478.619 | 0.902322 |
| _inner_e98d6_00130 | TERMINATED |       |           32 |     0 | 0.1   |    2     |      1 |         2138.24  | 0.745391 |
| _inner_e98d6_00131 | TERMINATED |       |           64 |     0 | 0.1   |    2     |      1 |         1165.79  | 0.902899 |
| _inner_e98d6_00132 | TERMINATED |       |          128 |     0 | 0.1   |    2     |      1 |          629.484 | 0.909241 |
| _inner_e98d6_00133 | TERMINATED |       |          256 |     0 | 0.1   |    2     |      1 |          429.381 | 0.911535 |
| _inner_e98d6_00134 | TERMINATED |       |          512 |     0 | 0.1   |    2     |      1 |          309.451 | 0.912338 |
| _inner_e98d6_00135 | TERMINATED |       |           32 |     0 | 1     |    2     |      1 |         2119.46  | 0.738731 |
| _inner_e98d6_00136 | TERMINATED |       |           64 |     0 | 1     |    2     |      1 |         1154.13  | 0.880261 |
| _inner_e98d6_00137 | TERMINATED |       |          128 |     0 | 1     |    2     |      1 |          640.902 | 0.908003 |
| _inner_e98d6_00138 | TERMINATED |       |          256 |     0 | 1     |    2     |      1 |          404.579 | 0.910011 |
| _inner_e98d6_00139 | TERMINATED |       |          512 |     0 | 1     |    2     |      1 |          309.36  | 0.911429 |
| _inner_e98d6_00140 | TERMINATED |       |           32 |     0 | 2     |    2     |      1 |         2258.78  | 0.655119 |
| _inner_e98d6_00141 | TERMINATED |       |           64 |     0 | 2     |    2     |      1 |         1201.36  | 0.75092  |
| _inner_e98d6_00142 | TERMINATED |       |          128 |     0 | 2     |    2     |      1 |         1102.95  | 0.905019 |
| _inner_e98d6_00143 | TERMINATED |       |          256 |     0 | 2     |    2     |      1 |          556.545 | 0.821348 |
| _inner_e98d6_00144 | TERMINATED |       |          512 |     0 | 2     |    2     |      1 |          382.639 | 0.826671 |
| _inner_e98d6_00145 | TERMINATED |       |           32 |     0 | 5     |    2     |      1 |         3260.69  | 0.612794 |
| _inner_e98d6_00146 | TERMINATED |       |           64 |     0 | 5     |    2     |      1 |         1311.27  | 0.600712 |
| _inner_e98d6_00147 | TERMINATED |       |          128 |     0 | 5     |    2     |      1 |         1233.02  | 0.578959 |
| _inner_e98d6_00148 | TERMINATED |       |          256 |     0 | 5     |    2     |      1 |          620.552 | 0.676678 |
| _inner_e98d6_00149 | TERMINATED |       |          512 |     0 | 5     |    2     |      1 |          513.634 | 0.62987  |
| _inner_e98d6_00150 | TERMINATED |       |           32 |     0 | 0.001 |    5     |      1 |         2136.44  | 0.498647 |
| _inner_e98d6_00151 | TERMINATED |       |           64 |     0 | 0.001 |    5     |      1 |         1120.8   | 0.570691 |
| _inner_e98d6_00152 | TERMINATED |       |          128 |     0 | 0.001 |    5     |      1 |          653.361 | 0.756667 |
| _inner_e98d6_00153 | TERMINATED |       |          256 |     0 | 0.001 |    5     |      1 |         2900.34  | 0.84099  |
| _inner_e98d6_00154 | TERMINATED |       |          512 |     0 | 0.001 |    5     |      1 |          372.797 | 0.792346 |
| _inner_e98d6_00155 | TERMINATED |       |           32 |     0 | 0.01  |    5     |      1 |         2504.26  | 0.82388  |
| _inner_e98d6_00156 | TERMINATED |       |           64 |     0 | 0.01  |    5     |      1 |         1205.95  | 0.90406  |
| _inner_e98d6_00157 | TERMINATED |       |          128 |     0 | 0.01  |    5     |      1 |         1008.88  | 0.906482 |
| _inner_e98d6_00158 | TERMINATED |       |          256 |     0 | 0.01  |    5     |      1 |          601.126 | 0.905499 |
| _inner_e98d6_00159 | TERMINATED |       |          512 |     0 | 0.01  |    5     |      1 |         1000.82  | 0.906428 |
| _inner_e98d6_00160 | TERMINATED |       |           32 |     0 | 0.1   |    5     |      1 |         2045.52  | 0.662055 |
| _inner_e98d6_00161 | TERMINATED |       |           64 |     0 | 0.1   |    5     |      1 |         1190.72  | 0.824585 |
| _inner_e98d6_00162 | TERMINATED |       |          128 |     0 | 0.1   |    5     |      1 |          648.327 | 0.910432 |
| _inner_e98d6_00163 | TERMINATED |       |          256 |     0 | 0.1   |    5     |      1 |          403.102 | 0.910846 |
| _inner_e98d6_00164 | TERMINATED |       |          512 |     0 | 0.1   |    5     |      1 |          323.429 | 0.911429 |
| _inner_e98d6_00165 | TERMINATED |       |           32 |     0 | 1     |    5     |      1 |         1772.88  | 0.581133 |
| _inner_e98d6_00166 | TERMINATED |       |           64 |     0 | 1     |    5     |      1 |         1165.91  | 0.903226 |
| _inner_e98d6_00167 | TERMINATED |       |          128 |     0 | 1     |    5     |      1 |          670.216 | 0.906964 |
| _inner_e98d6_00168 | TERMINATED |       |          256 |     0 | 1     |    5     |      1 |          453.827 | 0.90966  |
| _inner_e98d6_00169 | TERMINATED |       |          512 |     0 | 1     |    5     |      1 |          350.4   | 0.910733 |
| _inner_e98d6_00170 | TERMINATED |       |           32 |     0 | 2     |    5     |      1 |         1566.06  | 0.658029 |
| _inner_e98d6_00171 | TERMINATED |       |           64 |     0 | 2     |    5     |      1 |         1087.28  | 0.716404 |
| _inner_e98d6_00172 | TERMINATED |       |          128 |     0 | 2     |    5     |      1 |          704.758 | 0.811619 |
| _inner_e98d6_00173 | TERMINATED |       |          256 |     0 | 2     |    5     |      1 |          411.009 | 0.896768 |
| _inner_e98d6_00174 | TERMINATED |       |          512 |     0 | 2     |    5     |      1 |          445.006 | 0.904984 |
| _inner_e98d6_00175 | TERMINATED |       |           32 |     0 | 5     |    5     |      1 |         1265.7   | 0.498647 |
| _inner_e98d6_00176 | TERMINATED |       |           64 |     0 | 5     |    5     |      1 |          936.382 | 0.5007   |
| _inner_e98d6_00177 | TERMINATED |       |          128 |     0 | 5     |    5     |      1 |          735.445 | 0.560848 |
| _inner_e98d6_00178 | TERMINATED |       |          256 |     0 | 5     |    5     |      1 |          572.779 | 0.62221  |
| _inner_e98d6_00179 | TERMINATED |       |          512 |     0 | 5     |    5     |      1 |          504.322 | 0.599954 |
+--------------------+------------+-------+--------------+-------+-------+----------+--------+------------------+----------+



2021-03-18 04:56:53,489	INFO tune.py:448 -- Total run time: 21077.11 seconds (21072.41 seconds for the tuning loop).
Best hyperparameters found were:  {'lr': 1, 'sec_lr': 0.01, 'batch_size': 512, 'eta': 0.0}
GPU available: False, used: False
TPU available: None, using: 0 TPU cores

  | Name      | Type              | Params
------------------------------------------------
0 | learner   | Learner           | 8.6 K 
1 | adversary | Adversary         | 3.3 K 
2 | loss_fct  | BCEWithLogitsLoss | 0     
------------------------------------------------
12.0 K    Trainable params
0         Non-trainable params
12.0 K    Total params
/home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
/home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 52 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
/home/nolte/.conda/envs/fact-ai-lisa/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: training_step returned None if it was on purpose, ignore this warning...
  warnings.warn(*args, **kwargs)
time to fit was 19.426871299743652
Results = {'min_auc': 0.8857223391532898, 'macro_avg_auc': 0.9223517626523972, 'micro_avg_auc': 0.9112187623977661, 'minority_auc': 0.9467885494232178, 'accuracy': 0.856519877910614}
